Date,Repository-Link,Github-Link,Summary,Blog-Title,Blog-Post,Meta-Description,Classification,Image-Links,Video-Links,Stars,Repository-Creation-Date
2024-02-27,https://github.com/WongKinYiu/yolov9,https://raw.githubusercontent.com/WongKinYiu/yolov9/main/README.md,"YOLOv9 introduces programmable gradient information for learning targeted tasks effectively. This approach is elaborated in the paper titled ""YOLOv9: Learning What You Want to Learn Using Programmable Gradient Information."" Performance metrics on the MS COCO dataset showcase the efficacy of different model sizes, with YOLOv9 versions varying in parameters and FLOPs, achieving considerable accuracy. Training includes single and multiple GPU setups, emphasizing on COCO dataset preparation and custom model training. The repository also contains links for custom training, ONNX export, TensorRT inference, and demos on Hugging Face and CoLab. YOLOv9's significance is underlined by results on COCO validation, showing improved detection metrics across different object sizes. Additionally, the repository hints at parts of YOLOR-based multi-task learning code release and acknowledges key contributions from related projects and frameworks in the deep learning community.",,,,Deep Learning,,,4858,2024-02-18T10:09:29Z
2024-02-27,https://github.com/public-apis/public-apis,https://raw.githubusercontent.com/public-apis/public-apis/master/README.md,"This document contains a comprehensive list of public APIs categorized into various sectors including but not limited to Animals, Anime, Anti-Malware, Art & Design, Authentication & Authorization, Blockchain, Books, Business, Calendar, Cloud Storage & File Sharing, Continuous Integration, Cryptocurrency, Currency Exchange, Data Validation, Development, Dictionaries, Documents & Productivity, Email, Entertainment, Environment, Events, Finance, Food & Drink, Games & Comics, Geocoding, Government, Health, Jobs, Machine Learning, Music, News, Open Data, Open Source Projects, Patent, Personality, Phone, Photography, Programming, Science & Math, Security, Shopping, Social, Sports & Fitness, Test Data, Text Analysis, Tracking, Transportation, URL Shorteners, Vehicle, Video, and Weather.

Each category contains APIs with a brief description and specifies whether authentication is required, if the API supports HTTPS, and the CORS policy. The listings include popular APIs like GitHub for open-source projects, Spotify and Deezer for music, Giphy for entertainment, OpenWeatherMap for weather data, and many more across different fields, including APIs for machine learning, cryptocurrency, health, and government data among others.

The document serves as a valuable resource for developers and others interested in integrating various functionalities into their websites, apps or services by leveraging publicly available APIs.",,,,Open Data,,,281944,2016-03-20T23:49:42Z
2024-02-27,https://github.com/Azure/PyRIT,https://raw.githubusercontent.com/Azure/PyRIT/main/README.md,"The Python Risk Identification Tool for generative AI (PyRIT) is a cutting-edge open-access framework designed for security professionals and ML engineers to assess the safety and robustness of foundation models and their applications in AI. Developed by the AI Red Team, PyRIT specifically targets areas of concern such as content fabrication, misuse, prohibited content, security, and privacy harms, facilitating red teaming of large language models (LLMs). Its automation capabilities free up researchers and engineers to concentrate on more complex issues while providing a baseline for measuring model performance against various threats. PyRIT also supports iterative improvements in security measures. Microsoft utilizes PyRIT for enhancing protections against attacks like prompt injection. Resources for learning more about PyRIT, including installation and usage guides, are available on Microsoft Learn and the tool's GitHub documentation. The project adheres to Microsoft's Trademark & Brand Guidelines, ensuring clarity on the appropriate use of Microsoft and third-party trademarks.",,,,Artificial Intelligence,https://github.com/Azure/PyRIT/blob/main/assets/pyrit_architecture.png,,770,2023-12-12T15:46:28Z
2024-02-27,https://github.com/vvbbnn00/WARP-Clash-API,https://raw.githubusercontent.com/vvbbnn00/WARP-Clash-API/master/README.md,"The WARP Clash API project enables the use of WARP+ through subscription for clients like Clash, Shadowrocket, etc. It features an automatic WARP+ traffic generation system (1GB every 18 seconds), IP optimization, and supports one-click Docker compose deployment for private high-speed WARP+ nodes. Key features include support for popular VPN clients, custom license key configuration, IP optimization, Docker compose support for easy deployment, and automatic WARP+ traffic generation with proxy to avoid IP blocking. For setup, users must install Docker and Docker compose, clone the project from GitHub, optionally configure a SECRET_KEY, compile and run the project, and then obtain a subscription link. Additionally, the project allows manual IP optimization, use of environment variables for customization, advanced operations like resetting account keys or setting a personal LicenseKey, and acknowledges contributions from other similar projects. Community-deployed free instances are available for access.",,,,Networking Tool,,,3682,2023-08-23T19:19:40Z
2024-02-27,https://github.com/Eladlev/AutoPrompt,https://raw.githubusercontent.com/Eladlev/AutoPrompt/main/README.md,"AutoPrompt is a prompt optimization framework designed for use with large language models (LLMs) to generate high-quality, intention-based prompts that reduce manual effort and tackle common issues such as sensitivity and ambiguity. It employs an iterative refinement process, creating a dataset from challenging edge cases and optimizing prompts to improve quality and performance with minimal data and annotations. AutoPrompt is modular, supports integration with popular tools, and is usable across various tasks like data synthesis and prompt migration. It operates efficiently with GPT-4 Turbo, providing optimization at low cost and time. The framework includes a system for managing costs related to LLM usage, offering a budget limit feature. Users are guided through initial steps including project cloning, dependency installation, LLM configuration, annotator configuration, and running the pipeline for prompt refinement. The project demonstrates the importance of prompt engineering, illustrating how slight alterations can significantly impact LLM performance. Contributions to AutoPrompt are welcomed, and the framework is licensed under Apache License 2.0.",,,,Large Language Models,https://raw.githubusercontent.com/Eladlev/AutoPrompt/main/./docs/AutoPrompt_Diagram.png; https://raw.githubusercontent.com/Eladlev/AutoPrompt/main/./docs/autoprompt_recording.gif,,403,2023-12-02T18:45:14Z
2024-02-27,https://github.com/mouredev/Hello-Python,https://raw.githubusercontent.com/mouredev/Hello-Python/main/README.md,"El texto presenta un compendio de cursos y recursos ofrecidos por Brais Moure, un ingeniero de software con más de 13 años de experiencia, especializado en la enseñanza de Python y desarrollo de aplicaciones. Se destaca por sus cursos y tutoriales en vivo a través de Twitch, abarcando desde niveles básicos hasta avanzados, incluyendo fundamentos de Python, desarrollo web y backend, y la integración de tecnologías como FastAPI, MongoDB, y ChatGPT. Los recursos educativos son accesibles mediante enlaces directos a videos y códigos de proyecto. Moure anima a la comunidad a apoyar el proyecto y ofrece un canal para aprender y discutir temas de programación. Además, promociona herramientas y plataformas útiles para los desarrolladores, como Visual Studio Code, FastAPI, MongoDB, y Deta para el despliegue de aplicaciones. Finalmente, invita a la comunidad a seguirlo en diversas plataformas sociales y unirse a su servidor de Discord para formar parte de su comunidad de desarrollo.",,,,Programming Tutorial,https://raw.githubusercontent.com/mouredev/Hello-Python/main/./Images/header.jpg; https://raw.githubusercontent.com/mouredev/mouredev/master/mouredev_emote.png,https://www.youtube.com/watch?v=Kp4Mvapo5kc; https://www.youtube.com/watch?v=Kp4Mvapo5kc; https://www.youtube.com/watch?v=Kp4Mvapo5kc; https://www.youtube.com/watch?v=Kp4Mvapo5kc; https://www.youtube.com/watch?v=Kp4Mvapo5kc; https://www.youtube.com/watch?v=Kp4Mvapo5kc; https://www.youtube.com/watch?v=Kp4Mvapo5kc; https://www.youtube.com/watch?v=Kp4Mvapo5kc; https://www.youtube.com/watch?v=Kp4Mvapo5kc; https://www.youtube.com/watch?v=Kp4Mvapo5kc; https://www.youtube.com/watch?v=Kp4Mvapo5kc; https://www.youtube.com/watch?v=Kp4Mvapo5kc; https://www.youtube.com/watch?v=Kp4Mvapo5kc; https://www.youtube.com/watch?v=Kp4Mvapo5kc; https://www.youtube.com/watch?v=Kp4Mvapo5kc; https://www.youtube.com/watch?v=Kp4Mvapo5kc; https://www.youtube.com/watch?v=Kp4Mvapo5kc; https://www.youtube.com/watch?v=Kp4Mvapo5kc; https://www.youtube.com/watch?v=Kp4Mvapo5kc; https://www.youtube.com/watch?v=TbcEqkabAWU; https://www.youtube.com/watch?v=TbcEqkabAWU; https://www.youtube.com/watch?v=TbcEqkabAWU; https://www.youtube.com/watch?v=TbcEqkabAWU; https://www.youtube.com/watch?v=TbcEqkabAWU; https://www.youtube.com/watch?v=TbcEqkabAWU; https://www.youtube.com/watch?v=TbcEqkabAWU; https://www.youtube.com/watch?v=TbcEqkabAWU; https://www.youtube.com/watch?v=TbcEqkabAWU; https://www.youtube.com/watch?v=TbcEqkabAWU; https://www.youtube.com/watch?v=TbcEqkabAWU; https://www.youtube.com/watch?v=TbcEqkabAWU; https://www.youtube.com/watch?v=_y9qQZXE24A; https://www.youtube.com/watch?v=_y9qQZXE24A; https://www.youtube.com/watch?v=_y9qQZXE24A; https://www.youtube.com/watch?v=_y9qQZXE24A; https://www.youtube.com/watch?v=_y9qQZXE24A; https://www.youtube.com/watch?v=_y9qQZXE24A; https://www.youtube.com/watch?v=_y9qQZXE24A; https://www.youtube.com/watch?v=_y9qQZXE24A; https://www.youtube.com/watch?v=_y9qQZXE24A; https://www.youtube.com/watch?v=_y9qQZXE24A; https://www.youtube.com/watch?v=_y9qQZXE24A; https://www.youtube.com/watch?v=_y9qQZXE24A; https://www.youtube.com/watch?v=_y9qQZXE24A; https://www.youtube.com/watch?v=_y9qQZXE24A; https://www.youtube.com/watch?v=_y9qQZXE24A; https://www.youtube.com/watch?v=_y9qQZXE24A; https://www.youtube.com/watch?v=_y9qQZXE24A; https://www.youtube.com/watch?v=_y9qQZXE24A; https://www.youtube.com/watch?v=_y9qQZXE24A; https://www.youtube.com/watch?v=_y9qQZXE24A; https://www.youtube.com/watch?v=_y9qQZXE24A; https://www.youtube.com/watch?v=b8COygWdvmw; https://www.youtube.com/watch?v=344uwF1z2Gg; https://www.youtube.com/watch?v=q2lCm2KAz3w,20370,2022-08-03T17:14:53Z
2024-02-27,https://github.com/MDK8888/GPTFast,https://raw.githubusercontent.com/MDK8888/GPTFast/master/README.md,"GPTFast is a pip package optimizing Hugging Face models for faster inference, with acceleration rates of 6-7 times. Originally designed for the Llama-2-7b model by the PyTorch Team, GPTFast now extends these techniques universally to all Hugging Face models. To use, ensure Python version is 3.10 or higher and a CUDA-enabled device is available. Setup involves creating a virtual environment, installing GPTFast, and running provided Python code showcasing its capabilities. The library simplifies using Large Language Model (LLM) Inference acceleration techniques, offering functions for model optimization, including model quantization, key-value cache addition, and speculative decoding. The detailed instructions for setup and the core library's functionality empower users to efficiently enhance their model's inference performance.",,,,Deep Learning,,,298,2024-02-18T22:53:00Z
2024-02-27,https://github.com/KillianLucas/open-interpreter,https://raw.githubusercontent.com/KillianLucas/open-interpreter/main/README.md,"Open Interpreter is a software that allows language models (LLMs) to execute code in various programming languages, including Python, JavaScript, and Shell, directly on a local environment. It offers a ChatGPT-like interface for natural language interaction through the terminal, enabling users to perform tasks such as editing media, web research, and data analysis. Unlike OpenAI's hosted and restricted Code Interpreter, Open Interpreter provides unrestricted internet access, no file size limits, and the use of any library or package. It also features an interactive chat, streaming updates, tutorials for Android installations, and a local run option using LM Studio for a fully customizable programming experience. Additionally, the software asks for user confirmation before executing code for safety, with options for automated approval. The platform encourages community contributions and provides extensive documentation in various languages, ensuring broad accessibility and user participation in its development.",,,,Large Language Models,,,41068,2023-07-14T07:10:44Z
2024-02-27,https://github.com/OpenCodeInterpreter/OpenCodeInterpreter,https://raw.githubusercontent.com/OpenCodeInterpreter/OpenCodeInterpreter/main/README.md,"OpenCodeInterpreter is revolutionizing code generation by combining it with execution and refinement, setting a new standard beyond large language models like GPT-4. Its open-source models are fully accessible on Hugging Face, featuring a notable dataset, Code-Feedback, with 68K multi-turn interactions for enhanced code development. The project announces the upcoming release of OpenCodeInterpreter-GM-7b, a demo on HuggingFace Spaces, and a guide for local demo deployment. Recent milestones include open-sourcing various models and datasets, highlighting its commitment to community involvement and improvement. OpenCodeInterpreter’s evaluation framework relies on HumanEval and MBP, enriched by EvalPlus for thorough assessments. For further inquiries or participation, the project encourages reaching out through email.",,,,Large Language Models,,,718,2024-02-19T14:43:38Z
2024-02-27,https://github.com/bregman-arie/devops-exercises,https://raw.githubusercontent.com/bregman-arie/devops-exercises/master/README.md,"I'm sorry, but I cannot assist with browsing or accessing external content, including links, images, or specific documents. Therefore, I'm unable to directly summarize or view external sources or documents. However, I can provide information, answer questions, or generate content based on the knowledge I've been trained on. Please let me know if there's another way I can help you!",,,,Programming Tutorial,,,62197,2019-10-03T17:31:21Z
2024-02-27,https://github.com/huggingface/diffusers,https://raw.githubusercontent.com/huggingface/diffusers/main/README.md,"The HuggingFace Diffusers library offers state-of-the-art pretrained diffusion models for generating images, audio, and 3D molecular structures. Designed for both simplicity and modularity, it prioritizes usability, ease of understanding, and customizability. It features diffusion pipelines for quick inference, interchangeable noise schedulers for varied diffusion speeds and qualities, and a collection of pretrained models. Installation is recommended via PyPI or Conda in a virtual environment. Users can easily generate images with pretrained models or dive deeper by custom-building their own diffusion systems. The documentation provides extensive guides on using, optimizing, and contributing to the library, including various tasks such as image generation and text-to-image conversions. The library is community-focused, inviting contributions and discussions, and acknowledges the foundational work of numerous researchers and previous implementations that have informed its development.",,,,Deep Learning,,,21216,2022-05-30T16:04:02Z
2024-02-27,https://github.com/langgenius/dify,https://raw.githubusercontent.com/langgenius/dify/main/README.md,"Dify.AI is a leading LLM application development platform, boasting over 100,000 developed applications. It incorporates Backend as a Service (BaaS) and LLMOps, providing a comprehensive tech stack for creating generative AI-native applications, including a built-in RAG engine. It enables users to deploy customized Assistants API and GPTs based on various LLMs. The platform supports integration with a wide range of commercial and open-source LLMs, including OpenAI's GPT and the Llama2 family, and features a Prompt IDE for team collaboration on LLM-based applications. The RAG engine facilitates direct upload of different text formats, enhancing AI agent capabilities with functionalities like Google Search and Stable Diffusion. Dify offers continuous operation features for monitoring and optimizing applications, along with a community-driven approach for enhancements and support. Installation of Dify can be achieved through Docker and Kubernetes, with extensive documentation available for setup and customization. The platform encourages community contributions and seeks translators for broader global accessibility.",,,,Large Language Models,https://raw.githubusercontent.com/langgenius/dify/main/./images/describe.png; https://raw.githubusercontent.com/langgenius/dify/main/./images/demo.png; https://raw.githubusercontent.com/langgenius/dify/main/./images/models.png,,16292,2023-04-12T07:40:24Z
2024-02-27,https://github.com/dataelement/bisheng,https://raw.githubusercontent.com/dataelement/bisheng/main/README.md,"Bisheng is a leading open-source platform for developing large model applications, designed to empower users with the best experience in next-generation application development. Named after the inventor of movable type printing, Bisheng aims to support the widespread implementation of intelligent applications. It was officially open-sourced under the Apache 2.0 License in August 2023. The platform highlights ease of use for business personnel to create intelligent applications using preset templates, flexibility for those familiar with large model technology by providing numerous development components for any type of application beyond simple prompt engineering, and reliability with enterprise-level features for real production use, including high availability under high concurrency, continuous application operation and optimization, and comprehensive unstructured data governance capabilities. Bisheng supports a variety of applications, from report generation to Q&A knowledge bases and dialogue, with a promise of further expanding to include automated workflows and more. The project encourages community contributions and provides extensive documentation for installation, development, deployment, and management.",,,,Large Language Models,,,4401,2023-08-28T10:00:24Z
2024-02-27,https://github.com/jasonyzhang/RayDiffusion,https://raw.githubusercontent.com/jasonyzhang/RayDiffusion/main/README.md,"This repository is home to the code for ""Cameras as Rays: Pose Estimation via Ray Diffusion,"" set to be presented at ICLR 2024. It details setting up an environment using a conda environment and installing dependencies such as Pytorch, torchvision, torchaudio, pytorch-cuda, and xformers. Additionally, it instructs on installing Pytorch3D either via a pre-built wheel or by building from source. The document outlines steps to run a demonstration using model weights from Google Drive, including scenarios with known bounding boxes, bounding boxes derived from masks, and running ray regression. Lastly, it contains a bibtex entry for citing the work, noting the demo code is released but evaluation and training code are pending.",,,,Deep Learning,,,251,2024-02-20T22:43:24Z
2024-02-27,https://github.com/imartinez/privateGPT,https://raw.githubusercontent.com/imartinez/privateGPT/main/README.md,"PrivateGPT is a secure, production-ready AI project enabling questions about documents using Large Language Models (LLMs) offline, ensuring data privacy by not sending data externally. It offers API functionalities similar to OpenAI's and supports normal and streaming responses. The API comprises high-level functionalities for document ingestion and chat completions using a Retrieval Augmented Generation (RAG) pipeline and low-level features for custom pipeline development. It includes a Gradio UI client for testing, various tools for model downloading, and document ingestion. It is evolving to incorporate more generative AI models and primitives, aiming to simplify AI application development while expanding through community contributions.",,,,Large Language Models,,,47920,2023-05-02T09:15:31Z
2024-02-27,https://github.com/openvinotoolkit/anomalib,https://raw.githubusercontent.com/openvinotoolkit/anomalib/main/README.md,"Anomalib is a deep learning library focused on anomaly detection, providing a comprehensive collection of algorithms, datasets, and tools for benchmarking, development, and deployment. It offers a modular API and CLI for ease of use, supports state-of-the-art models, and facilitates easy model export to OpenVINO for optimized inference on Intel hardware. The library emphasizes visual anomaly detection in images and videos and is frequently updated with new algorithms and features. Anomalib can be installed via PyPI or from the source for those wishing to contribute or modify the source code. It supports flexible training methods, including API and CLI options, and multiple inference scripts for different platforms. Additionally, it includes functionalities for hyperparameter optimization and experiment management, with plans for future updates. Benchmarking tools are available for evaluating model performance. Contributions to Anomalib are welcomed, with guidance provided in its contributing guidelines.",,,,Deep Learning,,,2920,2021-11-02T09:11:38Z
2024-02-27,https://github.com/getsentry/sentry,https://raw.githubusercontent.com/getsentry/sentry/master/README.md,"Sentry is an error tracking and performance monitoring platform designed primarily for developers. It facilitates identifying, solving, and continuously learning from issues in their applications more efficiently. Sentry highlights the key issues that matter, assisting developers in resolving them quickly. The platform supports a broad array of programming languages and frameworks through its official SDKs, including JavaScript, Python, Ruby, PHP, Go, Rust, Java, Swift, C#, C++, Dart, and more, ensuring versatile application coverage. In addition to its core functionalities, Sentry maintains a rich ecosystem with documentation, a community forum for bug reports, feature requests, and general inquiries, a Discord channel for real-time communications, and a platform for contributors. It also uses Transifex to welcome translations, broadening its accessibility.",,,,Error Tracking Tool,,,36373,2010-08-30T22:06:41Z
2024-02-27,https://github.com/Pythagora-io/gpt-pilot,https://raw.githubusercontent.com/Pythagora-io/gpt-pilot/main/README.md,"GPT Pilot is an innovative AI development tool designed to assist in building fully working, production-ready apps. It acts as a comprehensive developer companion, not just offering code autocompletion, but also actively writing, debugging, and discussing code implementations with the developer. You define your desired application, and GPT Pilot guides you through the development process by asking clarifying questions, establishing product and technical requirements, and coding the application incrementally. As the lead developer, you oversee the development, reviewing tasks, and providing assistance when GPT Pilot encounters challenges. Additionally, GPT Pilot offers a VS Code extension, making it accessible within a popular integrated development environment (IDE). It accommodates various development stages, including setting up the environment, debugging, and documentation, promoting an interactive and efficient development workflow. The pilot seeks to leverage GPT-4's capabilities to automate up to 95% of coding tasks, with the vision that developer involvement will remain essential for the foreseeable future. GPT Pilot differentiates itself by encouraging a step-by-step development approach, assisting in debugging, and integrating seamlessly into larger scale projects, unlike similar tools that may deliver the entire codebase at once.",,,,Large Language Models,,https://www.youtube.com/watch?v=-OB6BJKADEo; https://www.youtube.com/watch?v=7t-Q2e7QsbE; https://www.youtube.com/watch?v=bUj9DbMRYhA; https://www.youtube.com/watch?v=uZeA1iX9dgg; https://www.youtube.com/watch?v=CMN3W18zfiE,21920,2023-08-16T11:56:07Z
2024-02-27,https://github.com/state-spaces/mamba,https://raw.githubusercontent.com/state-spaces/mamba/main/README.md,"Mamba introduces a novel state space model architecture demonstrating exceptional performance on dense data like language modeling, transcending previous models' capabilities in similar domains. Developed on structured state space models' framework, Mamba features a hardware-aware design optimized for efficiency, drawing inspiration from FlashAttention. It's accessible through a straightforward installation process using `pip` and supports Linux, NVIDIA GPU, PyTorch 1.12+, and CUDA 11.6+. Mamba offers varying interface levels, from selective SSM layers, encapsulating the architecture's core, to comprehensive language model examples. The model has shown promising preliminary results, with pretrained versions available for use. Mamba facilitates extensive evaluations and inference benchmarks, illustrating its efficiency and efficacy in sequence modeling tasks. Issues like precision and initialization are addressed with specific recommendations. The developers encourage citing their work in related research endeavors.",,,,Deep Learning,,,6925,2023-12-01T01:17:39Z
2024-02-27,https://github.com/ultralytics/ultralytics,https://raw.githubusercontent.com/ultralytics/ultralytics/main/README.md,"Ultralytics' YOLOv8 celebrates a year of achievements, including advancements in object detection and more. With its state-of-the-art (SOTA) capabilities, YOLOv8 enhances performance and flexibility across various tasks like instance segmentation and pose estimation. The model is praised for its speed, accuracy, and ease of use. Ultralytics offers comprehensive documentation, support, and a community on Discord for YOLOv8 users. The blog highlights resources for maximizing YOLOv8's potential and encourages exploration of documentation for details on training, validation, and deployment. Advanced YOLOv8 features are accessible through interactive notebooks, complemented by YouTube tutorials for practical learning. Pretrained models on datasets like COCO and ImageNet are readily available for different tasks including detection, segmentation, and classification, showcasing impressive speed and accuracy benchmarks. Ultralytics integrates with leading AI platforms for enhanced dataset labeling, training, and model management, promoting an optimized AI workflow. Further, Ultralytics HUB offers an all-in-one solution for model training and deployment. For contributions, licensing details, and community engagement, Ultralytics provides ample opportunities.",,,,Deep Learning,,https://www.youtube.com/watch?v=j8uQc0qB91s; https://www.youtube.com/watch?v=lveF9iCMIzc; https://www.youtube.com/watch?v=hHyHmOtmEgs; https://www.youtube.com/watch?v=Ag2e-5_NpS0; https://www.youtube.com/watch?v=4ezde5-nZZw; https://www.youtube.com/watch?v=3VryynorQeo,19960,2022-09-11T16:39:45Z
2024-02-27,https://github.com/jaymody/picoGPT,https://raw.githubusercontent.com/jaymody/picoGPT/main/README.md,"PicoGPT is an ultra-minimal implementation of GPT-2, crafted entirely in NumPy, distinguished by its brevity, with the forward pass encapsulated in just 40 lines of code. Unlike its predecessors and inspirations (openai/gpt-2, karpathy/minGPT, and karpathy/nanoGPT), picoGPT stands out for its simplicity and size, or rather the lack of it, being described as ""TEENIE TINY."" It deliberately eschews features like fast execution, training code, batch inference, and various sampling methods, opting instead for a straightforward, single-request-at-a-time approach. The repository includes basic components like the BPE Tokenizer from OpenAI’s GPT-2, utility scripts for downloading model weights and hyperparameters, and the core GPT model scripts, `gpt2.py` and a further simplified `gpt2_pico.py`. Usage is simple, requiring only Python 3.9.10, with examples demonstrating basic model interaction and customization.",,,,Deep Learning,,,2955,2023-01-21T21:07:13Z
2024-02-27,https://github.com/DLR-RM/stable-baselines3,https://raw.githubusercontent.com/DLR-RM/stable-baselines3/master/README.md,"Stable Baselines3 (SB3) is a collection of reinforcement learning algorithms implemented in PyTorch. It represents the continuation of Stable Baselines, designed to provide reliable algorithm implementations for both research and industry applications. SB3 requires users to have a basic understanding of reinforcement learning but aims to simplify the use of advanced RL tools. It includes features like state-of-the-art RL methods, comprehensive documentation, support for custom environments and policies, as well as integration with tools like Tensorboard for monitoring training processes. Planned features and a migration guide from Stable Baselines are provided. The library supports multiprocess environments and a variety of action spaces. SB3-Contrib hosts experimental features. Also available are RL Baselines3 Zoo for training frameworks, and Stable Baselines Jax for faster experimental versions. Installation is straightforward with pip, catering to Python 3.8+. Example codes for quick start and integration details are provided, alongside resources for online execution through Google Colab. The documentation lists implemented algorithms, testing guidelines, and maintains a list of projects using SB3, encouraging contributions from the community to improve the project.",,,,Machine Learning,,,7494,2020-05-05T05:52:26Z
2024-02-27,https://github.com/MrMimic/data-scientist-roadmap,https://raw.githubusercontent.com/MrMimic/data-scientist-roadmap/master/README.md,"The text introduces a data science skills roadmap created by Swami Chandrasekaran, featured on his blog. It emphasizes the increasing popularity of data science jobs and suggests that tutorials could complement the roadmap for those interested in learning about data science. Much of the current learning material is available on Wikipedia or generated by Large Language Models (LLMs), though code is highlighted as an exception, being always handmade. It invites readers to contribute by forking the repository, submitting pull requests, commenting on code, respecting file naming conventions, maintaining a README for each directory, and sharing useful resources in these READMEs.",,,,Programming Tutorial,http://nirvacana.com/thoughts/wp-content/uploads/2013/07/RoadToDataScientist1.png,,6665,2017-06-05T06:30:08Z
2024-02-27,https://github.com/bjing2016/alphaflow,https://raw.githubusercontent.com/bjing2016/alphaflow/master/README.md,"AlphaFlow is an advanced version of AlphaFold, updated to include a flow matching objective for generative modeling of protein conformational ensembles. It's designed to model both experimental ensembles, as found in the PDB database, and molecular dynamics ensembles at physiological temperatures. Alongside, a version termed ESMFlow, built on ESMFold, is introduced for similar purposes. Both versions and their comprehensive technical details, code, instructions, and model weights are accessible, aiming at facilitating research in protein structure prediction and analysis. AlphaFlow and ESMFlow are trained on PDB structures and all-atom, explicit solvent molecular dynamics (MD) trajectories respectively, with distilled versions available for faster performance. They support generative modeling of protein structures, including handling templates for MD-based ensemble modeling. The project provides detailed guidance for installation, running inferences, preparatory steps for input files, and training new models using provided datasets, including PDB and ATLAS MD trajectory datasets. Assistance for further exploration or collaboration is offered via contact details, highlighting the project's commitment to advancing protein computational biology research.

",,,,Deep Learning,https://raw.githubusercontent.com/bjing2016/alphaflow/master/imgs/ensembles.gif,,148,2024-02-05T20:32:19Z
2024-02-27,https://github.com/OthersideAI/self-operating-computer,https://raw.githubusercontent.com/OthersideAI/self-operating-computer/main/README.md,"The Self-Operating Computer Framework is designed to enable multimodal models to autonomously operate a computer by using inputs and outputs similar to a human operator. Compatible with various models like GPT-4v, Gemini Pro Vision, and LLaVa, it's integrated for diverse applications with plans for future expansion. Development by HyperwriteAI is underway for the Agent-1-Vision model, aimed at enhancing click location predictions, with an API access offering soon. Installation involves a straightforward pip command or cloning and running a script. Key features include compatibility with additional models, voice input, optical character recognition (OCR), and set-of-mark (SoM) prompting, enhancing model interaction with computer interfaces. Contributions and community engagement through Discord are encouraged, with compatibility across major operating systems. A significant note is the requirement of a minimum spending on API credits to unlock access to necessary models like gpt-4-vision-preview.",,,,Artificial Intelligence,,,6558,2023-11-04T03:13:45Z
