Date,Repository-Link,Github-Link,Summary,Readme-Text,Classification,Image-Links,Video-Links,Stars,Suitable-Image-Links,Suitable-Video-Links,Repository-Creation-Date
2024-02-25,https://github.com/karpathy/minbpe,https://raw.githubusercontent.com/karpathy/minbpe/master/README.md,"Minbpe is a minimalist codebase for Byte Pair Encoding (BPE), a tokenization method essential for training large language models (LLMs) like GPT. Originally introduced in the GPT-2 publication by OpenAI, BPE operates on UTF-8 strings, enhancing NLP applications like those seen in GPT, Llama, and Mistral. The repository includes two Tokenizers capable of training vocabulary, encoding text to tokens, and decoding tokens back to text. It features a basic implementation directly working with text, and a regex-based version that preprocesses text into categories to prevent cross-category merges, aligning with GPT-4's approach. Additionally, a GPT4Tokenizer replicates GPT-4's tokenization, emphasizing recoverability of exact merges and handling specific token permutations. Furthermore, the codebase offers the ability to train custom tokenizers and introduces potential enhancements like optimized versions and broader model support. The files are thoroughly documented with examples, and the project is licensed under MIT, making it accessible and modifiable.",,NLP-Tokenization,,https://www.youtube.com/watch?v=zduSFxRajkE,0,,,
2024-02-25,https://github.com/LargeWorldModel/LWM,https://raw.githubusercontent.com/LargeWorldModel/LWM/main/README.md,"The Large World Model (LWM) is a cutting-edge, general-purpose, large-context, multimodal autoregressive model designed for expansive language, image, and video understanding and generation. It surpasses current models by effectively training on extensive datasets of long videos and books with a novel technique called RingAttention, addressing the challenges of memory constraints and computational complexity in handling multimodal sequences exceeding millions of tokens. LWM sets new benchmarks in retrieval tasks and video understanding, provides solutions for vision-language training difficulties, and is fully open-sourced with a 7B parameter capacity. Its remarkable capabilities include high-accuracy fact retrieval across 1M contexts, answering questions from over an hour of video, chatting using images, and generating videos and images from text. The setup recommends TPUs for optimal performance, though GPUs are supported. The codebase supports various context sizes for language-only and vision-language models, and is optimized for large-scale training and inference tasks, paving the way for a deeper understanding of human knowledge and the multimodal world.",,Multimodal-Autoregressive,,,0,,,
2024-02-25,https://github.com/google/magika,https://raw.githubusercontent.com/google/magika/main/README.md,"Magika is an innovative AI-powered tool developed for precise file type detection, leveraging deep learning for high accuracy. It features a compact, efficient Keras model that performs detections swiftly on minimal computing resources. Tested across over a million files and more than 100 content types, Magika showcases remarkable precision and recall rates exceeding 99%. This tool enhances user safety on Google platforms like Gmail and Drive by facilitating the accurate routing of files to appropriate security scans. Magika is available in various formats including a Python command line tool, a Python API, and an experimental web version, ensuring broad accessibility. It supports batching for large scale use, offers high compatibility with existing file types, and allows customization of prediction preferences. Moreover, it is open source, inviting contributions and further development from the community. For those interested, Magika can be explored through an interactive web demo and is documented extensively online for both Python and JavaScript implementations.",,File-Type-Detection,,,0,,,
2024-02-25,https://github.com/sherlock-project/sherlock,https://raw.githubusercontent.com/sherlock-project/sherlock/master/README.md,"The Sherlock Project provides a tool for tracking down social media accounts by username across multiple networks. It offers detailed guides for installation and usage, including options for searching with various filters, handling output, and customizing requests through proxies or Tor for anonymous searching. Installation involves cloning the repository, navigating to the Sherlock directory, and installing requirements with Python. Usage is flexible, allowing searches for single or multiple usernames, with results optionally saved to files or folders. The tool supports Docker, enabling it to run in containers, and even offers a docker-compose option for easier usage. Contributions are encouraged, especially in adding new sites or improving site support. Testing is important for contributing developers, with guidance provided for running tests and managing test coverage. Sherlock operates under the MIT license, inviting open collaboration and development.",,Username-Search,,,0,,,
2024-02-25,https://github.com/chatchat-space/Langchain-Chatchat,https://raw.githubusercontent.com/chatchat-space/Langchain-Chatchat/master/README.md,"LangChain-Chatchat, previously known as Langchain-ChatGLM, is an open-source project built on ChatGLM and other large language models (LLMs), utilizing the Langchain framework. It offers a Retrieval-Augmented Generation (RAG) large model knowledge base that can be deployed offline. The project aims to establish a Chinese-friendly, open-source model support system that can operate offline. Inspired by various projects and using models like Vicuna, Alpaca, LLaMA, and others, it enables offline deployment using open-source models while supporting OpenAI GPT API calls for further enhancement. Version 0.2.10 marks the end of the 0.2.x series, with future efforts focusing on developing the more application-oriented Langchain-Chatchat 0.3.x. The project achieves local inference for knowledge bases, addressing data security and privacy concerns for businesses. It includes instructions for environment setup, model downloading, database initialization, and starting the project, along with Docker deployment options. Significant milestones include the release of early versions, rebranding, and achievements in hackathons, with over 20K GitHub stars. The project invites contributions and discussions through its Telegram group, WeChat group, and official WeChat public account.",,Knowledge-Retrieval-Chatbot,https://raw.githubusercontent.com/chatchat-space/Langchain-Chatchat/master/img/logo-long-chatchat-trans-v2.png; https://raw.githubusercontent.com/chatchat-space/Langchain-Chatchat/master/img/langchain+chatglm.png; https://raw.githubusercontent.com/chatchat-space/Langchain-Chatchat/master/img/langchain+chatglm2.png; https://raw.githubusercontent.com/chatchat-space/Langchain-Chatchat/master/img/fastapi_docs_026.png; https://raw.githubusercontent.com/chatchat-space/Langchain-Chatchat/master/img/LLM_success.png; https://raw.githubusercontent.com/chatchat-space/Langchain-Chatchat/master/img/init_knowledge_base.jpg,,0,https://raw.githubusercontent.com/chatchat-space/Langchain-Chatchat/master/img/logo-long-chatchat-trans-v2.png; https://raw.githubusercontent.com/chatchat-space/Langchain-Chatchat/master/img/langchain+chatglm.png; https://raw.githubusercontent.com/chatchat-space/Langchain-Chatchat/master/img/langchain+chatglm2.png; https://raw.githubusercontent.com/chatchat-space/Langchain-Chatchat/master/img/fastapi_docs_026.png; https://raw.githubusercontent.com/chatchat-space/Langchain-Chatchat/master/img/LLM_success.png; https://raw.githubusercontent.com/chatchat-space/Langchain-Chatchat/master/img/init_knowledge_base.jpg,,
2024-02-25,https://github.com/lllyasviel/stable-diffusion-webui-forge,https://raw.githubusercontent.com/lllyasviel/stable-diffusion-webui-forge/main/README.md,"Stable Diffusion WebUI Forge is an enhancement over the original WebUI for Stable Diffusion, offering improved development ease, optimized resource management, and faster inference speeds. Inspired by Minecraft Forge, it targets to serve as the developmental core for SD WebUI, supporting a variety of GPUs with significant speed ups in inference times and better GPU memory utilization. It introduces the Unet Patcher making it easier to implement methods like Self-Attention Guidance and Kohya High Res Fix in fewer lines of code, avoiding the need to modify UNet directly. Forge also adds several samplers and maintains a 100% compatibility with Automatic1111 WebUI, ensuring no unnecessary changes to the interface. Installation options include Git for experienced users or a one-click installation package. Additionally, Forge redefines backend operations for better efficiency and supports new functionalities like SVD, Z123, and masked control networks through an easier development process for extensions, ensuring comprehensive resource management and compatibility with existing extensions.",,AI-Optimization-Toolkit,,,0,,,
2024-02-25,https://github.com/OS-Copilot/FRIDAY,https://raw.githubusercontent.com/OS-Copilot/FRIDAY/main/README.md,"OS-Copilot introduces a framework for creating generalist computer agents, like FRIDAY, aimed at automating tasks in Linux and MacOS environments. This framework simplifies app interactions across diverse operating systems, enhancing productivity and efficiency. Users can quickly start with FRIDAY by cloning the GitHub repository, setting up a Python environment, installing dependencies, and configuring an OpenAI API key. For expanding FRIDAY's capabilities, a library of tools (FRIDAY-Gizmos) is maintained, where users can add or remove tools as needed. The project also offers an intuitive user interface for easy agent control and supports the deployment of custom API tools using FastAPI. A critical note is that OS-Copilot is provided without any warranty, and users are responsible for any risks. The community is encouraged to engage and share tools and ideas via Slack. The project is open for contact and further discussion, aiming to foster the development of intelligent, self-improving computer agents.",,AI-Assistant-System,,,0,,,
2024-02-25,https://github.com/WongKinYiu/yolov9,https://raw.githubusercontent.com/WongKinYiu/yolov9/main/README.md,"YOLOv9 introduces advancements in object detection with its implementation as detailed in ""YOLOv9: Learning What You Want to Learn Using Programmable Gradient Information."" It offers a range of models (YOLOv9-S, M, C, E) showing varied performance metrics on the MS COCO dataset, with the YOLOv9-E model achieving the highest accuracy. A variety of resources, including demo links, Docker installation guide, and evaluation/training instructions, support users in implementing YOLOv9. The paper also mentions the release of small and medium models post-acceptance and publication. The citation section provides references for academic use. Additionally, it links to a multi-task learning approach based on YOLOR, suggesting integration with YOLOv9 for extended functionalities. Acknowledgements credit relevant repositories and projects contributing to the development of YOLOv9.",,Object-Detection,,,0,,,
2024-02-25,https://github.com/vvbbnn00/WARP-Clash-API,https://raw.githubusercontent.com/vvbbnn00/WARP-Clash-API/master/README.md,"The WARP Clash API project enables subscription-based use of WARP+ with support for clients like Clash and Shadowrocket. It features an automatic WARP+ traffic refresh system providing 1GB every 18 seconds, an IP optimization tool, and easy deployment via Docker compose for private high-speed WARP+ nodes. Key features include support for multiple clients, setting your own LicenseKey, IP optimization, Docker compose deployment, automated WARP+ traffic acquisition, and subscription updates with random nodes for a ""gacha"" experience. The project emphasizes non-commercial, educational use and warns against illegal applications. Installation involves setting up Docker and Docker compose, downloading the project, optional configuration of a SECRET_KEY for public deployment, compiling, and running to obtain a subscription link. Additionally, manual IP optimization and various environment variables allow for customization of the project's functionality. Advanced operations include resetting account keys and setting a LicenseKey. The project acknowledges several open-source initiatives it builds upon and lists a community-deployed free instance available for use.",,VPN-Management-API,,,0,,,
2024-02-25,https://github.com/jackfrued/Python-100-Days,https://raw.githubusercontent.com/jackfrued/Python-100-Days/master/README.md,骆昊的《Python - 100天从新手到大师》是一本全面介绍Python语言学习和实践的书籍，旨在帮助新手通过100天的学习成为Python大师。自项目上线后，骆昊收到反馈指出基础部分对新手较难，因此推出了简化的“Python-Core-50-Courses”项目，配有视频讲解，帮助初学者更好地学习Python基础。书中不仅涵盖了Python的基础知识，如变量、数据结构、控制流等，还深入讲解了面向对象编程、文件操作、网络编程等高级主题。此外，还介绍了Python在Web开发、数据分析、人工智能等领域的应用，为读者提供了丰富的项目实践机会。通过系统学习，读者可以掌握Python编程技巧，理解Python在各领域的应用，并有能力独立完成项目开发。,,Python编程教程,https://raw.githubusercontent.com/jackfrued/Python-100-Days/master/./res/agile-scrum-sprint-cycle.png; https://raw.githubusercontent.com/jackfrued/Python-100-Days/master/./res/company_architecture.png; https://raw.githubusercontent.com/jackfrued/Python-100-Days/master/./res/pylint.png; https://raw.githubusercontent.com/jackfrued/Python-100-Days/master/./res/requirements_by_xmind.png; https://raw.githubusercontent.com/jackfrued/Python-100-Days/master/./res/uml-class-diagram.png; https://raw.githubusercontent.com/jackfrued/Python-100-Days/master/./res/power-designer-pdm.png,,0,https://raw.githubusercontent.com/jackfrued/Python-100-Days/master/./res/agile-scrum-sprint-cycle.png; https://raw.githubusercontent.com/jackfrued/Python-100-Days/master/./res/company_architecture.png; https://raw.githubusercontent.com/jackfrued/Python-100-Days/master/./res/pylint.png; https://raw.githubusercontent.com/jackfrued/Python-100-Days/master/./res/requirements_by_xmind.png; https://raw.githubusercontent.com/jackfrued/Python-100-Days/master/./res/uml-class-diagram.png; https://raw.githubusercontent.com/jackfrued/Python-100-Days/master/./res/power-designer-pdm.png,,
2024-02-27,https://github.com/public-apis/public-apis,https://raw.githubusercontent.com/public-apis/public-apis/master/README.md,"This document provides a comprehensive list of publicly available APIs categorized by various topics such as Animals, Anime, Anti-Malware, Art & Design, Authentication & Authorization, Blockchain, Books, Business, Calendar, Cloud Storage & File Sharing, Continuous Integration, Cryptocurrency, Currency Exchange, Data Validation, Development, Dictionaries, Documents & Productivity, Email, Entertainment, Environment, Events, Finance, Food & Drink, Games & Comics, Geocoding, Government, Health, Jobs, Machine Learning, Music, News, Open Data, Open Source Projects, Patent, Personality, Phone, Photography, Programming, Science & Math, Security, Shopping, Social, Sports & Fitness, Test Data, Text Analysis, Tracking, Transportation, URL Shorteners, Vehicle, Video, and Weather. Each category includes a brief description of the API, information about authentication, HTTPS support, and CORS (Cross-Origin Resource Sharing) availability. This document provides developers with a wealth of resources for integrating external services into their applications, ranging from data about animals and books to complex functionalities like blockchain and artificial intelligence.",,"I'm sorry, but I cannot fulfill this request.",,,281196,,,2016-03-20T23:49:42Z
2024-02-27,https://github.com/KillianLucas/open-interpreter,https://raw.githubusercontent.com/KillianLucas/open-interpreter/main/README.md,"Open Interpreter is a software that allows language models to run code (e.g., Python, JavaScript, Shell) locally on machines. It offers a natural-language interface, enabling users to perform a wide range of tasks such as editing media, controlling web browsers for research, and manipulating large datasets through simple text commands. The software provides benefits over OpenAI's Code Interpreter by running locally, thus removing restrictions related to internet access, package limitations, file size, runtime limits, and state persistence. Open Interpreter is easily installable and comes with documentation in multiple languages. It introduces a ""New Computer Update"" featuring an `--os` option and a ""Computer API,"" among other enhancements. Installation instructions, demo links, interactive chat, and programming interfaces are included, along with comparisons to similar services, indicating Open Interpreter's advantages in terms of flexibility and lack of operational restrictions. Additional features include streaming output, saving/restoring chats, and system message customization. Open Interpreter supports changing language models, running in local mode, and provides verbose debugging insights. It can be configured via `yaml` files for different profiles and includes instructions for pushing its functionalities over HTTP REST endpoints and implementation on Android devices. Safety measures are highlighted due to the potential risks of executing code locally.",,AI-Assistant-System,,,41000,,,2023-07-14T07:10:44Z
2024-02-27,https://github.com/mouredev/Hello-Python,https://raw.githubusercontent.com/mouredev/Hello-Python/main/README.md,"Este texto presenta un curso completo sobre Python para principiantes, ofrecido por Brais Moure a través de Twitch y GitHub, abarcando desde los fundamentos hasta el desarrollo de backend con FastAPI y MongoDB, y la integración de ChatGPT. Además, se ofrece un curso intermedio, tutoriales sobre desarrollo web con Python, y una introducción al Testing junto con curiosidades sobre Python. El curso está actualmente en pausa, habiendo cubierto las secciones básica, intermedia y de backend. Se incluyen también enlaces de interés, como al sitio oficial de Python y recursos para el despliegue en la nube con Deta. Moure agradece el apoyo recibido y proporciona enlaces para seguir su trabajo y unirse a la comunidad de desarrollo a través de Twitch y Discord.",,Python编程教程,https://raw.githubusercontent.com/mouredev/Hello-Python/main/./Images/header.jpg; https://raw.githubusercontent.com/mouredev/mouredev/master/mouredev_emote.png,https://www.youtube.com/watch?v=Kp4Mvapo5kc; https://www.youtube.com/watch?v=Kp4Mvapo5kc; https://www.youtube.com/watch?v=Kp4Mvapo5kc; https://www.youtube.com/watch?v=Kp4Mvapo5kc; https://www.youtube.com/watch?v=Kp4Mvapo5kc; https://www.youtube.com/watch?v=Kp4Mvapo5kc; https://www.youtube.com/watch?v=Kp4Mvapo5kc; https://www.youtube.com/watch?v=Kp4Mvapo5kc; https://www.youtube.com/watch?v=Kp4Mvapo5kc; https://www.youtube.com/watch?v=Kp4Mvapo5kc; https://www.youtube.com/watch?v=Kp4Mvapo5kc; https://www.youtube.com/watch?v=Kp4Mvapo5kc; https://www.youtube.com/watch?v=Kp4Mvapo5kc; https://www.youtube.com/watch?v=Kp4Mvapo5kc; https://www.youtube.com/watch?v=Kp4Mvapo5kc; https://www.youtube.com/watch?v=Kp4Mvapo5kc; https://www.youtube.com/watch?v=Kp4Mvapo5kc; https://www.youtube.com/watch?v=Kp4Mvapo5kc; https://www.youtube.com/watch?v=Kp4Mvapo5kc; https://www.youtube.com/watch?v=TbcEqkabAWU; https://www.youtube.com/watch?v=TbcEqkabAWU; https://www.youtube.com/watch?v=TbcEqkabAWU; https://www.youtube.com/watch?v=TbcEqkabAWU; https://www.youtube.com/watch?v=TbcEqkabAWU; https://www.youtube.com/watch?v=TbcEqkabAWU; https://www.youtube.com/watch?v=TbcEqkabAWU; https://www.youtube.com/watch?v=TbcEqkabAWU; https://www.youtube.com/watch?v=TbcEqkabAWU; https://www.youtube.com/watch?v=TbcEqkabAWU; https://www.youtube.com/watch?v=TbcEqkabAWU; https://www.youtube.com/watch?v=TbcEqkabAWU; https://www.youtube.com/watch?v=_y9qQZXE24A; https://www.youtube.com/watch?v=_y9qQZXE24A; https://www.youtube.com/watch?v=_y9qQZXE24A; https://www.youtube.com/watch?v=_y9qQZXE24A; https://www.youtube.com/watch?v=_y9qQZXE24A; https://www.youtube.com/watch?v=_y9qQZXE24A; https://www.youtube.com/watch?v=_y9qQZXE24A; https://www.youtube.com/watch?v=_y9qQZXE24A; https://www.youtube.com/watch?v=_y9qQZXE24A; https://www.youtube.com/watch?v=_y9qQZXE24A; https://www.youtube.com/watch?v=_y9qQZXE24A; https://www.youtube.com/watch?v=_y9qQZXE24A; https://www.youtube.com/watch?v=_y9qQZXE24A; https://www.youtube.com/watch?v=_y9qQZXE24A; https://www.youtube.com/watch?v=_y9qQZXE24A; https://www.youtube.com/watch?v=_y9qQZXE24A; https://www.youtube.com/watch?v=_y9qQZXE24A; https://www.youtube.com/watch?v=_y9qQZXE24A; https://www.youtube.com/watch?v=_y9qQZXE24A; https://www.youtube.com/watch?v=_y9qQZXE24A; https://www.youtube.com/watch?v=_y9qQZXE24A; https://www.youtube.com/watch?v=b8COygWdvmw; https://www.youtube.com/watch?v=344uwF1z2Gg; https://www.youtube.com/watch?v=q2lCm2KAz3w,20318,https://raw.githubusercontent.com/mouredev/Hello-Python/main/./Images/header.jpg; https://raw.githubusercontent.com/mouredev/mouredev/master/mouredev_emote.png,,2022-08-03T17:14:53Z
2024-02-27,https://github.com/state-spaces/mamba,https://raw.githubusercontent.com/state-spaces/mamba/main/README.md,"Mamba introduces a novel state space model architecture designed for processing information-dense data, outperforming subquadratic models and comparable with Transformers in language modeling tasks. This model is a progression from structured state space models, optimized for efficient hardware utilization. It requires specific Python, PyTorch, and CUDA versions, along with an NVIDIA GPU for installation. Mamba's architecture features a selective SSM layer, efficient convolution layers, and can be integrated into a complete language model. Pretrained models, trained on extensive token datasets, show promising performance in zero-shot evaluations. The model supports inference with various sampling strategies and has a troubleshooting guide for precision and initialization issues. To cite Mamba in your work, use the provided citation format.",,AI-Optimization-Toolkit,,,6902,,,2023-12-01T01:17:39Z
2024-02-27,https://github.com/OpenCodeInterpreter/OpenCodeInterpreter,https://raw.githubusercontent.com/OpenCodeInterpreter/OpenCodeInterpreter/main/README.md,"OpenCodeInterpreter is an open-source code generation initiative designed to enhance coding by integrating execution and iterative refinement, aiming to rival sophisticated systems like GPT-4 Code Interpreter. It has recently made several strides forward, including the open-sourcing of its OpenCodeInterpreter-DS-1.3b model, the CodeFeedback-Filtered-Instruction dataset, and the entire datasets under Code-Feedback. It also announced its future plans to open-source the OpenCodeInterpreter-GM-7b Model, deploy a demo on HuggingFace Spaces, and provide local deployment code with a setup guide. All models in the series are accessible via Hugging Face, supported by the Code-Feedback dataset comprising 68K multi-turn interactions for dynamic code refinement. The project employs HumanEval and MBP for evaluation, enhanced by their extended versions for thorough analysis. Contact details are provided for further inquiries.",,AI-Assistant-System,,,669,,,2024-02-19T14:43:38Z
2024-02-27,https://github.com/Azure/PyRIT,https://raw.githubusercontent.com/Azure/PyRIT/main/README.md,"The Python Risk Identification Tool for generative AI (PyRIT) is an open-access framework designed to assist security professionals and ML engineers in evaluating the security of foundation models and their applications. Developed by the AI Red Team, PyRIT allows for the automated assessment of large language model (LLM) endpoints against various harm categories like fabrication, misuse, and prohibited content. This tool facilitates AI Red Teaming by automating tasks, thereby allowing operators to concentrate on more complex challenges. It also highlights security and privacy harms including malware generation and identity theft. PyRIT's primary objective is to provide empirical data to researchers, enabling a comparison of their model's current performance against future iterations, and to aid in the development of mitigations against identified harms. Microsoft utilizes this tool to refine products against prompt injection attacks. Further information, installation guides, and demonstrations are available on Microsoft Learn and the PyRIT GitHub page.",,AI-Optimization-Toolkit,https://github.com/Azure/PyRIT/blob/main/assets/pyrit_architecture.png,,685,,,2023-12-12T15:46:28Z
2024-02-27,https://github.com/Pythagora-io/gpt-pilot,https://raw.githubusercontent.com/Pythagora-io/gpt-pilot/main/README.md,"GPT Pilot is an innovative AI developer tool that assists in the entire development process of building apps. After a user specifies the type of application they want to create, GPT Pilot engages in a conversational manner, asking for clarifications and creating product and technical requirements. It takes charge of setting up the development environment and codes the application step by step, involving the user for code reviews and problem-solving as needed. Essentially, with GPT Pilot, the user acts as a lead developer, guiding the AI in its coding tasks. This tool is designed to be a comprehensive AI developer companion beyond merely providing code autocompletion or assistance with pull request messages. It aims to handle writing full features, debugging, and engaging with the developer on code review and issues, making it a groundbreaking step towards utilizing AI in real-world application development. The process is meant to cover most coding aspects (around 95%), with the anticipation that a human developer's insight will be necessary for the remainder, underscoring the current limitations and future potential of AI in software development.",,AI-Assistant-System,,https://www.youtube.com/watch?v=-OB6BJKADEo; https://www.youtube.com/watch?v=7t-Q2e7QsbE; https://www.youtube.com/watch?v=bUj9DbMRYhA; https://www.youtube.com/watch?v=uZeA1iX9dgg; https://www.youtube.com/watch?v=CMN3W18zfiE,21902,,,2023-08-16T11:56:07Z
2024-02-27,https://github.com/czbag/scroll,https://raw.githubusercontent.com/czbag/scroll/main/README.md,"Scroll Soft is software designed to simplify wallet management on the Scroll network, offering a plethora of features and increased security through high randomization. It supports functions such as deposits and withdrawals via various bridges (official, Orbiter, LayerSwap, Nitro), wrapping and unwrapping ETH, multiple swapping options (SkyDrome, SyncSwap, Zebra, XySwap with a referral code), and lending protocols (LayerBank, Aave). Users can mint and bridge NFTs across chains, vote with RubyScore, create Gnosis Safe, deploy contracts, and more, with custom sequential or random actions. Installation involves cloning the repository, installing dependencies, and configuring necessary modules. Basic and module-specific settings are adjusted in settings.py and modules_settings.py, with private keys stored in accounts.txt and RPC configurations in rpc.json. Further updates and information are shared via a Telegram blog link provided.",,Wallet-Management,,,147,,,2023-10-18T13:07:25Z
2024-02-27,https://github.com/jackfrued/Python-100-Days,https://raw.githubusercontent.com/joaomdmoura/crewAI/main/README.md,"crewAI is a state-of-the-art framework designed to orchestrate role-playing, autonomous AI agents, allowing them to collaborate effectively on complex tasks. It enables AI agents to assume specific roles, share goals, and operate cohesively, making it ideal for creating smart assistant platforms, automated customer services, and multi-agent research teams. The framework supports role-based agent design, autonomous inter-agent delegation, flexible task management, and works with open-source models. Installation is straightforward via pip, and it offers a variety of examples, such as trip planners and stock analysis. CrewAI also allows for dynamic and adaptable processes, improving over the limitations of other frameworks like Autogen and ChatDev by combining their strengths without inheriting their rigidity. It is open-source, inviting contributions from the developer community. CrewAI also collects anonymous telemetry to improve user experience but ensures sensitive data like API calls and agent backstories remain private. It is licensed under the MIT License, encouraging wide adoption and modification.",,AI-Assistant-System,https://raw.githubusercontent.com/joaomdmoura/crewAI/main/./docs/crewai_logo.png; https://img.youtube.com/vi/tnejrr-0a94/maxresdefault.jpg; https://img.youtube.com/vi/xis7rWp-hjs/maxresdefault.jpg; https://img.youtube.com/vi/e0Uj4yWdaAg/maxresdefault.jpg,https://www.youtube.com/watch?v=tnejrr-0a94; https://www.youtube.com/watch?v=xis7rWp-hjs; https://www.youtube.com/watch?v=e0Uj4yWdaAg,8237,https://raw.githubusercontent.com/joaomdmoura/crewAI/main/./docs/crewai_logo.png; https://img.youtube.com/vi/tnejrr-0a94/maxresdefault.jpg; https://img.youtube.com/vi/xis7rWp-hjs/maxresdefault.jpg; https://img.youtube.com/vi/e0Uj4yWdaAg/maxresdefault.jpg,,2018-03-01T16:05:52Z
2024-02-27,https://github.com/joaomdmoura/crewAI,https://raw.githubusercontent.com/joaomdmoura/crewAI-examples/main/README.md,"crewAI is a framework developed to enhance the collaboration between role-playing AI agents. Authored by [@joaomdmoura](https://x.com/joaomdmoura), it offers a variety of examples on how to utilize this framework for automating different tasks. Examples include creating job postings, planning trips, making Instagram posts, validating Markdown, generating games, and using the Azure OpenAI API for various projects. For beginners, there's a Starter Template available to kickstart their own projects. More advanced examples cover stock analysis, generating landing pages, and integrating CrewAI with LangGraph. These examples are aimed at demonstrating the versatility and potential of crewAI in facilitating complex automated workflows.",,AI-Assistant-System,,,824,,,2023-10-27T03:26:59Z
2024-02-27,https://github.com/joaomdmoura/crewAI-examples,https://raw.githubusercontent.com/paul-gauthier/aider/main/README.md,"Aider is an AI-driven command line tool designed for pair programming alongside GPT-3.5 or GPT-4, specifically tailoring to the needs of modifying code in local git repositories. It enables direct editing of code files and commits changes with descriptive messages, making it suited for both new projects and existing repositories. A unique feature of Aider is its ability to handle changes within large pre-existing codebases. The tool also supports GPT-4 Turbo with a 128k context window for improved speed and coding accuracy, along with a unified diff editing format to enhance code quality. Users can interact with Aider using simple command-line inputs, benefitting from several in-chat commands for a more intuitive coding session. Additionally, Aider facilitates multitasking with coding by allowing voice inputs. It's highlighted for significantly boosting coding productivity and being praised as a top-tier AI coding assistant by various users. Installation and detailed use cases are accessible through Aider's documentation and support channels.",,AI-Assistant-System,,https://www.youtube.com/watch?v=df8afeb1FY8; https://www.youtube.com/watch?v=MPYFPvxfGZs,6505,,,2023-12-19T11:46:48Z
2024-02-27,https://github.com/paul-gauthier/aider,https://raw.githubusercontent.com/Lightning-AI/lit-gpt/main/README.md,"Lit-GPT is an open-source project released under the Apache 2.0 license, focusing on hackable implementations of state-of-the-art large language models (LLMs). It supports a diverse array of model checkpoints from various organizations and extends foundational works like Lit-LLaMA and nanoGPT. This implementation is designed to be simple, correct, optimized for performance, and fully open-source, emphasizing readability and hackability over avoiding code duplication. Additionally, Lit-GPT served as the official starter kit for the NeurIPS 2023 LLM Efficiency Challenge, focusing on fine-tuning LLMs efficiently on limited hardware. The project encourages community involvement, offering detailed guides for using, fine-tuning, pretraining, and even contributing to further development. It includes support for a variety of datasets and offers optimization through quantization and other techniques, aiming to democratize AI development by providing tools that are accessible and efficient on consumer-grade hardware.",,AI-Assistant-System,,,5116,,,2023-05-09T18:57:49Z
2024-02-27,https://github.com/Lightning-AI/lit-gpt,https://raw.githubusercontent.com/vinta/awesome-python/master/README.md,"This comprehensive list curated by @VintaChen on GitHub (also available on Twitter as @VintaChen) is an extensive collection of awesome Python frameworks, libraries, resources, and tools for developers. The categories covered range from web development frameworks like Django and Flask to data visualization, machine learning, and testing. It aims to be a go-to resource for Python developers seeking to find tools for specific tasks, with each section meticulously organized into subcategories for easier navigation. The list also emphasizes community contributions and encourages developers to suggest additions or improvements. For those looking to keep up with the latest in Python development, links to newsletters and podcasts are provided, offering avenues for continuous learning and engagement with the Python community.",,Python编程教程,,,199167,,,2023-05-04T17:46:11Z
2024-02-27,https://github.com/vinta/awesome-python,https://raw.githubusercontent.com/Frimkron/mud-pi/master/README.md,"MUD Pi is a basic text-based Multi-User Dungeon (MUD) game designed to run on low-end servers like the Raspberry Pi. It requires Python (2.7+ or 3.3+) and internet connectivity for remote player access. Users need a telnet client to connect, with installation guides provided for different operating systems. Instructions for running the server include using the `simplemud.py` script on Windows, Mac OSX, Linux, and via SSH with tools like `screen` to keep the script running in the background. Setting up the server requires forwarding port 1234 and knowing the server's external IP address. MUD Pi encourages expanding the game by adding features or using it as a foundation for new projects. The game, being open-source, invites tweaking and learning from its Python-based codebase. Various MUD-Pi-based projects showcase its adaptability. MUD Pi's creator, Mark Frimston, provides his contact information for feedback and further discussion.",,MUD-Game,,,322,,,2014-06-27T21:00:06Z
2024-02-27,https://github.com/Frimkron/mud-pi,https://raw.githubusercontent.com/donnemartin/system-design-primer/master/README.md,"This text presents a comprehensive guide designed to enhance the reader's understanding of system design, offering resources for learning how to design scalable systems, prepare for system design interviews, and gain insights from the open-source community. It emphasizes the importance of mastering scalable system design for career advancement and provides a structured compilation of resources covering various system design principles. The guide actively encourages contributions from the community to keep the material current and relevant. Moreover, it includes dedicated sections for preparing for system design interviews, featuring common interview questions with solutions and additional learning topics. Notably, the text introduces the use of Anki flashcards as a tool for reinforcing key concepts through spaced repetition, suggesting decks for both system design and coding interviews. Further, the guide delves into specific system design topics, elucidating on performance vs. scalability, latency vs. throughput, and availability vs. consistency, including detailed discussions on consistency and availability patterns, databases, caches, and asynchronism. The document also addresses communication protocols, security considerations, and offers an appendix for quick reference on powers of two and latency numbers crucial for system design planning. Lastly, it provides links to real-world architectures, engineering blogs, and additional system design questions, serving as a valuable resource for anyone looking to deepen their understanding of system design or prepare for technical interviews.",,System Design Primer,https://raw.githubusercontent.com/donnemartin/system-design-primer/master/images/OfVllex.png; https://raw.githubusercontent.com/donnemartin/system-design-primer/master/images/4edXG0T.png; https://raw.githubusercontent.com/donnemartin/system-design-primer/master/images/jrUBAF7.png; https://raw.githubusercontent.com/donnemartin/system-design-primer/master/images/bWxPtQA.png; https://raw.githubusercontent.com/donnemartin/system-design-primer/master/images/V5q57vU.png; https://raw.githubusercontent.com/donnemartin/system-design-primer/master/images/cdCv5g7.png; https://raw.githubusercontent.com/donnemartin/system-design-primer/master/images/4j99mhe.png; https://raw.githubusercontent.com/donnemartin/system-design-primer/master/images/MzExP06.png; https://raw.githubusercontent.com/donnemartin/system-design-primer/master/images/jj3A5N8.png,https://www.youtube.com/watch?v=ZgdS0EUmn70; https://www.youtube.com/watch?v=-W9F__D3oY4; https://www.youtube.com/watch?v=k-Yaq8AHlFA; https://www.youtube.com/watch?v=kKjm4ehYiMs; https://www.youtube.com/watch?v=kKjm4ehYiMs; https://www.youtube.com/watch?v=kKjm4ehYiMs; https://www.youtube.com/watch?v=qI_g07C_Q5I; https://www.youtube.com/watch?v=kKjm4ehYiMs; https://www.youtube.com/watch?v=1KRYH75wgy4; https://www.youtube.com/watch?v=PE4gwstWhmc; https://www.youtube.com/watch?v=b1e4t2k2KJY; https://www.youtube.com/watch?v=PE4gwstWhmc; https://www.youtube.com/watch?v=5cKTP36HVgI; https://www.youtube.com/watch?v=z8LU0Cj6BOU; https://www.youtube.com/watch?v=w5WVu624fY8,247564,https://raw.githubusercontent.com/donnemartin/system-design-primer/master/images/OfVllex.png; https://raw.githubusercontent.com/donnemartin/system-design-primer/master/images/4edXG0T.png; https://raw.githubusercontent.com/donnemartin/system-design-primer/master/images/jrUBAF7.png; https://raw.githubusercontent.com/donnemartin/system-design-primer/master/images/bWxPtQA.png; https://raw.githubusercontent.com/donnemartin/system-design-primer/master/images/V5q57vU.png; https://raw.githubusercontent.com/donnemartin/system-design-primer/master/images/cdCv5g7.png; https://raw.githubusercontent.com/donnemartin/system-design-primer/master/images/4j99mhe.png; https://raw.githubusercontent.com/donnemartin/system-design-primer/master/images/MzExP06.png; https://raw.githubusercontent.com/donnemartin/system-design-primer/master/images/jj3A5N8.png,,2013-05-13T01:30:49Z
2024-02-27,https://github.com/donnemartin/system-design-primer,https://raw.githubusercontent.com/Eladlev/AutoPrompt/main/README.md,"Auto Prompt is a framework designed to improve the crafting of prompts for use with large language models (LLMs), tackling challenges like prompt sensitivity and ambiguity. It automates the generation of detailed prompts, refining them through an iterative process that builds a dataset of challenging edge cases. The intent is to reduce manual effort and efficiently address common issues, enhancing prompt reliability and performance with minimal data input.

Developed with modularity, it integrates easily with various tools and adapts to different tasks, including moderation and content generation. The framework's method involves generating synthetic data samples, annotating them, and evaluating prompt performance to suggest improvements. This process aims at producing robust, high-quality prompts swiftly and affordably.

Auto Prompt supports setting a budget for optimization, monitors usage to manage costs, and encourages continuous refinement to achieve the best results. Contributions are welcomed, with a community on Discord for collaboration. The project is provided as-is, with a focus on enhancing LLM prompt efficiency without guaranteeing absolute correctness or bias elimination. It's licensed under Apache 2.0, with a paper providing further details on its methodology.",,AI-Optimization-Toolkit,https://raw.githubusercontent.com/Eladlev/AutoPrompt/main/./docs/AutoPrompt_Diagram.png; https://raw.githubusercontent.com/Eladlev/AutoPrompt/main/./docs/autoprompt_recording.gif,,340,https://raw.githubusercontent.com/Eladlev/AutoPrompt/main/./docs/AutoPrompt_Diagram.png; https://raw.githubusercontent.com/Eladlev/AutoPrompt/main/./docs/autoprompt_recording.gif,,2017-02-26T16:15:28Z
2024-02-27,https://github.com/Eladlev/AutoPrompt,https://raw.githubusercontent.com/dnakov/r2d2/main/README.md,"The r2d2 project introduces a plugin for radare2 that integrates GPT-4, enabling it to execute and interpret radare2 (r2) commands autonomously. This collaboration aims to leverage the advanced capabilities of GPT-4 in understanding and interacting with binary analysis tasks through radare2, a well-known reverse engineering framework. Users interested in utilizing this plugin need to first install radare2 from its source repository. Following this, the installation of the plugin is straightforward, requiring only two commands to add both the necessary Python language support and the r2d2 plugin itself. Usage involves launching radare2 with the r2d2 plugin enabled, passing the binary file to be analyzed as an argument. This innovation represents a significant step forward in making binary analysis more interactive and automated by combining the strengths of radare2 and GPT-4.",,AI-Assistant-System,,,179,,,2023-12-02T18:45:14Z
2024-02-27,https://github.com/dnakov/r2d2,https://raw.githubusercontent.com/Textualize/rich/master/README.md,"Rich is a versatile Python library designed to enhance terminal output with rich text and beautiful formatting, including colors, styles, tables, progress bars, markdown, syntax-highlighted code, tracebacks, and more. Its API simplifies adding visually appealing elements to terminal applications. Rich is compatible with Linux, OSX, Windows, and supports True color and emojis on modern terminals. It requires Python 3.7 or later and integrates effortlessly with Jupyter notebooks. Installation is straightforward using `pip`. Rich enhances the Python REPL and standard output with features like pretty printing, advanced logging, and rich content rendering such as tables, progress bars, and syntax highlighting. Additionally, it offers functionalities like interactive trees, columns layouts, markdown rendering, and customizable tracebacks for better error inspection. Rich aims to make CLI applications more interactive and user-friendly, and also powers the Rich CLI tool for performing various terminal tasks with rich formatting. It works closely with its sister project, Textual, to build sophisticated terminal UIs.",,Python-Library,https://github.com/textualize/rich/raw/master/imgs/features.png; https://github.com/textualize/rich/raw/master/imgs/print.png; https://github.com/textualize/rich/raw/master/imgs/repl.png; https://github.com/textualize/rich/raw/master/imgs/hello_world.png; https://github.com/textualize/rich/raw/master/imgs/where_there_is_a_will.png; https://github.com/textualize/rich/raw/master/imgs/inspect.png; https://github.com/textualize/rich/raw/master/imgs/log.png; https://github.com/textualize/rich/raw/master/imgs/logging.png; https://github.com/textualize/rich/raw/master/imgs/table_movie.gif; https://github.com/textualize/rich/raw/master/imgs/table.png; https://github.com/textualize/rich/raw/master/imgs/table2.png; https://github.com/textualize/rich/raw/master/imgs/progress.gif; https://github.com/textualize/rich/raw/master/imgs/downloader.gif; https://github.com/textualize/rich/raw/master/imgs/status.gif; https://github.com/textualize/rich/raw/master/imgs/spinners.gif; https://github.com/textualize/rich/raw/master/imgs/tree.png; https://github.com/textualize/rich/raw/master/imgs/columns.png; https://github.com/textualize/rich/raw/master/imgs/markdown.png; https://github.com/textualize/rich/raw/master/imgs/syntax.png; https://github.com/textualize/rich/raw/master/imgs/traceback.png; https://raw.githubusercontent.com/Textualize/rich-cli/main/imgs/rich-cli-splash.jpg; https://raw.githubusercontent.com/Textualize/textual/main/imgs/textual.png,,46528,https://github.com/textualize/rich/raw/master/imgs/features.png; https://github.com/textualize/rich/raw/master/imgs/print.png; https://github.com/textualize/rich/raw/master/imgs/repl.png; https://github.com/textualize/rich/raw/master/imgs/hello_world.png; https://github.com/textualize/rich/raw/master/imgs/where_there_is_a_will.png; https://github.com/textualize/rich/raw/master/imgs/inspect.png; https://github.com/textualize/rich/raw/master/imgs/log.png; https://github.com/textualize/rich/raw/master/imgs/logging.png; https://github.com/textualize/rich/raw/master/imgs/table_movie.gif; https://github.com/textualize/rich/raw/master/imgs/table.png; https://github.com/textualize/rich/raw/master/imgs/table2.png; https://github.com/textualize/rich/raw/master/imgs/progress.gif; https://github.com/textualize/rich/raw/master/imgs/downloader.gif; https://github.com/textualize/rich/raw/master/imgs/status.gif; https://github.com/textualize/rich/raw/master/imgs/spinners.gif; https://github.com/textualize/rich/raw/master/imgs/tree.png; https://github.com/textualize/rich/raw/master/imgs/columns.png; https://github.com/textualize/rich/raw/master/imgs/markdown.png; https://github.com/textualize/rich/raw/master/imgs/syntax.png; https://github.com/textualize/rich/raw/master/imgs/traceback.png; https://raw.githubusercontent.com/Textualize/rich-cli/main/imgs/rich-cli-splash.jpg; https://raw.githubusercontent.com/Textualize/textual/main/imgs/textual.png,,2024-02-09T00:21:06Z
2024-02-27,https://github.com/Textualize/rich,https://raw.githubusercontent.com/bregman-arie/devops-exercises/master/README.md,"I'm sorry, but I cannot provide the requested information without the content of the text or images you are referring to. If you provide the actual content or details, I'd be happy to help summarize it.",,"I'm sorry, but I cannot fulfill this request.",,,62173,,,2019-11-10T15:28:09Z
2024-02-27,https://github.com/bregman-arie/devops-exercises,https://raw.githubusercontent.com/frappe/frappe/master/README.md,"Frappe is a full-stack web application framework, integrating a server side powered by Python and MariaDB, and a client side library that work closely together. It is designed for building and running applications like ERPNext, a notable implementation. It is pronounced ""fra-pay"" and comes with a comprehensive set of ""batteries included"" to help developers. For installation, Frappe recommends using the Frappe Bench method. The community is encouraged to contribute through pull requests, adhering to specific guidelines, and translating project documents. Further information, documentation, and a detailed guide on how to use Frappe are available on their [website](https://frappe.io). The project is open-source, licensed under the MIT License.",,Web-Framework,,https://www.youtube.com/watch?v=LOjk3m0wTwg,6283,,,2019-10-03T17:31:21Z
2024-02-27,https://github.com/frappe/frappe,https://raw.githubusercontent.com/blakeblackshear/frigate/master/README.md,"Frigate is a fully complete, local Network Video Recorder (NVR) system designed for integration with Home Assistant, providing AI-driven realtime object detection for IP cameras. It utilizes OpenCV and TensorFlow for local object detection, significantly enhancing efficiency and responsiveness. Frigate supports the optional use of a Google Coral Accelerator to further boost performance, capable of handling 100+ FPS with minimal overhead. Key features include tight Home Assistant integration, minimal resource usage, strategic object detection to maximize performance, multiprocessing for real-time processing, low overhead motion detection, separate processes for object detection using TensorFlow, MQTT communication for broad system compatibility, video recording with smart retention based on detected objects, 24/7 recording, and re-streaming capabilities to alleviate camera connection loads. Additionally, it offers WebRTC & MSE for low-latency live viewing. Frigate's documentation is accessible online, and the project accepts donations via Github Sponsors. The system also features a user interface for easy interaction and monitoring.",,Object-Detection,https://raw.githubusercontent.com/blakeblackshear/frigate/master/docs/static/img/events-ui.png,,13785,https://raw.githubusercontent.com/blakeblackshear/frigate/master/docs/static/img/events-ui.png,,2011-06-08T08:14:16Z
