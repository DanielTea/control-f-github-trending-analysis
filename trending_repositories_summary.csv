Date,Repository-Link,Github-Link,Summary,Classification,Image-Links,Video-Links,Stars,Suitable-Image-Links,Suitable-Video-Links,Repository-Creation-Date
2024-02-21,https://github.com/charlax/professional-programming,https://raw.githubusercontent.com/charlax/professional-programming/master/README.md,"This comprehensive guide, titled ""Professional Programming,"" serves as an extensive resource aimed at helping developers become more proficient. It covers a wide range of topics, including principles for keeping the list concise and opinionated, contributions, must-read books like ""The Pragmatic Programmer"" and ""Code Complete,"" and seminal articles offering practical advice to new software engineers and insights into career growth. The list emphasizes resources like books, articles, and courses across various subjects such as algorithms, API design, automation, and data structures, among others. It also addresses developer habits, mindset, debugging, design principles, documentation, and more, underlining the importance of contributing to this list to maintain its relevance and usefulness. The domains it touches upon are vast, including but not limited to coding quality, communication, compilers, cloud services, and system architecture, reflecting the multidimensional nature of software development.",Resource compilation,https://raw.githubusercontent.com/charlax/professional-programming/master/./images/amazon_writing_rules.jpeg,https://www.youtube.com/watch?v=kPRA0W1kECg; https://www.youtube.com/watch?v=zkTf0LmDqKI; https://www.youtube.com/watch?v=mVVNJKv9esE; https://www.youtube.com/watch?v=LnX3B9oaKzw; https://www.youtube.com/watch?v=FKTxC9pl-WM; https://www.youtube.com/watch?v=f84n5oFoZBc; https://www.youtube.com/watch?v=2V1FtfBDsLU; https://www.youtube.com/watch?v=E7Fbf7R3x6I; https://www.youtube.com/watch?v=y8OnoxKotPQ; https://www.youtube.com/watch?v=Oj8bfBlwHAg,36217,https://raw.githubusercontent.com/charlax/professional-programming/master/./images/amazon_writing_rules.jpeg,,2015-11-07T05:07:52Z
2024-02-21,https://github.com/chatchat-space/Langchain-Chatchat,https://raw.githubusercontent.com/chatchat-space/Langchain-Chatchat/master/README.md,"LangChain-Chatchat is an open-source, offline-deployable knowledge base project that enhances retrieval generation (RAG) using ChatGLM and other large language models with frameworks like Langchain. The project, transitioning from Langchain-ChatGLM, will see its last update in the 0.2.x series with version 0.2.10, shifting focus towards the more application-rich 0.3.x series. It aims to provide a supportive, offline-operable knowledge base question-answering solution for Chinese scenarios using open-source models. Inspired by projects like document.ai and contributions to ChatGLM-6B, it utilizes various models such as Vicuna, Alpaca, LLaMA, Koala, RWKV, accessible through FastAPI or a Streamlit-based WebUI. It supports fully localized inference, addressing data security and private deployment issues, with support for major local language and embedding models, and open-source local vector databases. Setup involves environment configuration, model downloading, initializing the knowledge base and configuration files, and a one-click startup. The project has reached significant milestones, including a transition to Langchain-Chatchat, and aims for enhancements in the upcoming 0.3.x series.",Knowledge base project,https://raw.githubusercontent.com/chatchat-space/Langchain-Chatchat/master/img/logo-long-chatchat-trans-v2.png; https://raw.githubusercontent.com/chatchat-space/Langchain-Chatchat/master/img/langchain+chatglm.png; https://raw.githubusercontent.com/chatchat-space/Langchain-Chatchat/master/img/langchain+chatglm2.png; https://raw.githubusercontent.com/chatchat-space/Langchain-Chatchat/master/img/fastapi_docs_026.png; https://raw.githubusercontent.com/chatchat-space/Langchain-Chatchat/master/img/LLM_success.png; https://raw.githubusercontent.com/chatchat-space/Langchain-Chatchat/master/img/init_knowledge_base.jpg,,22591,https://raw.githubusercontent.com/chatchat-space/Langchain-Chatchat/master/img/logo-long-chatchat-trans-v2.png; https://raw.githubusercontent.com/chatchat-space/Langchain-Chatchat/master/img/langchain+chatglm.png; https://raw.githubusercontent.com/chatchat-space/Langchain-Chatchat/master/img/langchain+chatglm2.png; https://raw.githubusercontent.com/chatchat-space/Langchain-Chatchat/master/img/fastapi_docs_026.png; https://raw.githubusercontent.com/chatchat-space/Langchain-Chatchat/master/img/LLM_success.png; https://raw.githubusercontent.com/chatchat-space/Langchain-Chatchat/master/img/init_knowledge_base.jpg,,2023-03-31T12:12:45Z
2024-02-21,https://github.com/zhayujie/chatgpt-on-wechat,https://raw.githubusercontent.com/zhayujie/chatgpt-on-wechat/master/README.md,"This project is an intelligent dialogue robot based on large models, supporting integration with various platforms like WeChat, WeCom, public accounts, Feishu, DingTalk, etc. It supports multiple AI engines such as GPT3.5/GPT4.0/Claude/WenxinYiyan/Xunfei Xinghuo/Tongyi Qianwen/Gemini/LinkAI/ZhipuAI for text, voice, and image processing. The robot can access external resources via plugins, customize enterprise AI applications with a knowledge base, and has capabilities for multi-round dialogues, voice and image recognition, and generation. The latest version extends functionalities with support for new models, image recognition dialogs, and more interactive plugins.

It offers an AI application platform for businesses with knowledge management, plugin agents, application management, and supports a variety of deployment styles including SaaS and private cloud. Having been applied across several industries, it aims to help SMEs embrace AI technology efficiently.

For developers and businesses looking for customization, the project provides detailed setup and usage documentation, along with support for Docker deployment for ease of installation. Continuous updates and a vibrant community on GitHub ensure the project remains cutting-edge.

Demo and commercial support details are provided, alongside open-source community engagement invitations. Regular updates enrich its capabilities and integration options, making it a versatile tool for creating personalized chatbots or AI assistants across various platforms and use cases.",Conversational AI Toolkit,,,21726,,,2022-08-07T08:33:41Z
2024-02-21,https://github.com/FujiwaraChoki/MoneyPrinterV2,https://raw.githubusercontent.com/FujiwaraChoki/MoneyPrinterV2/main/README.md,"MoneyPrinter V2 (MPV2) is an advanced automated tool designed to facilitate making money online. This second iteration builds upon its predecessor with a wider scope of features and a modular design. For optimal performance, it requires Python 3.9. Its functionalities include a Twitter bot, a YouTube Shorts automater, affiliate marketing through Amazon and Twitter, and tools for finding and reaching out to local businesses. Before installation, which involves cloning from GitHub, setting up a virtual environment, and installing dependencies, users must install Microsoft Visual C++ build tools and possibly the Go Programming Language for email outreach. MPV2 comes with scripts for easy access to core functions without user interaction. Contributions to the project are welcomed, with guidelines provided in CONTRIBUTING.md. It's licensed under the Affero General Public License v3.0. The project is for educational purposes and the creator is not liable for its misuse or any potential damages from its use.",Online Money-Making Automation,,https://www.youtube.com/watch?v=wAZ_ZSuIqfk,419,,,2024-02-12T11:20:42Z
2024-02-21,https://github.com/karpathy/minbpe,https://raw.githubusercontent.com/karpathy/minbpe/master/README.md,"Minbpe offers a minimal, clean codebase for Byte Pair Encoding (BPE), crucial for tokenization in large language models (LLMs) like GPT and Llama. Originating from the GPT-2 paper by OpenAI, BPE operates at the byte-level on UTF-8 strings. The repository contains two main tokenizer classes capable of training vocabularies, encoding text into tokens, and decoding tokens back into text. It introduces the BasicTokenizer for direct text application, and the RegexTokenizer, which adds preprocessing by splitting input text into categories. Furthermore, it includes a GPT4Tokenizer, aligning closely with GPT-4's tokenization standards. The project allows for easy training and handling of special tokens, aiming for clean, readable, and hackable code. It also suggests the development of optimized versions and future enhancements, like a potential LlamaTokenizer, underlining its utility and extensibility for LLM development. The software is licensed under MIT, ensuring open access to developers.",Tokenizer Library,,,6205,,,2024-02-16T16:18:15Z
2024-02-21,https://github.com/sherlock-project/sherlock,https://raw.githubusercontent.com/sherlock-project/sherlock/master/README.md,"Sherlock is a tool designed to trace social media accounts using a username across different social networks. The tool requires cloning from its GitHub repository and installing necessary requirements via Python3. Usage includes a range of commands allowing for verbose output, output saving, Tor and proxy usage, and specifying social media sites for targeted searches. It supports single or multiple username searches, with found accounts' results saved in individual text files. Docker support is included for running Sherlock within a container, offering a streamlined setup. Additionally, the project welcomes contributions, especially in adding new site supports or restoring previously removed sites. Contributors are encouraged to run tests before making pull requests to ensure functionality. Sherlock, under the MIT license, aims for collaborative improvement and broader site coverage, demonstrated by its call for community contributions and development guidance provided in its documentation.",Social Media Search Tool,,,48411,,,2018-12-24T14:30:48Z
2024-02-21,https://github.com/LargeWorldModel/LWM,https://raw.githubusercontent.com/LargeWorldModel/LWM/main/README.md,"The Large World Model (LWM) is a groundbreaking, versatile multimodal autoregressive model capable of understanding and generating language, images, and video content. Trained on an extensive collection of long videos and books via the innovative RingAttention mechanism, LWM sets new standards for neural networks by tackling the largest context sizes to date, thus enhancing AI's grasp of both human knowledge and the physical realm. This model surpasses existing limitations in language models by incorporating video sequences for a superior temporal understanding, addressing memory, computational complexity, and dataset challenges through a carefully curated dataset and progressive context size expansion from 4K to 1M tokens. LWM not only accomplishes remarkable feats in long video understanding and sophisticated retrieval tasks but also introduces efficient solutions for vision-language training dilemmas. Available in a fully open-sourced, 7B parameter suite, LWM offers models specialized for text and video across varying context sizes. Its capabilities include highly accurate fact retrieval across extensive contexts, engaging in conversations based on images, answering questions from lengthy videos, and creative generation of videos and images from text. Optimized for TPU with support for GPU, LWM welcomes contributions and applications to further advance AI's multimodal understanding and generative potential.",Multimodal AI Model,,,5306,,,2024-02-08T04:16:42Z
