Date,Repository-Link,Github-Link,Summary,Blog-Title,Blog-Post,Meta-Description,Classification,Star-Count-Delta,Image-Links,Video-Links,Stars,Repository-Creation-Date
2024-02-28,https://github.com/charlax/professional-programming,https://raw.githubusercontent.com/charlax/professional-programming/master/README.md,"The text you provided is a comprehensive guide covering various aspects of professional programming. It includes principles, must-read books, articles, general material, resources, and topics related to software development. The guide aims to help developers become more proficient by sharing inspiring resources and timeless classics. It covers a wide array of topics like algorithm and data structures, API design & development, authentication/authorization, automation, biases, career growth, coding & code quality, communication, compilers, configuration, continuous integration, databases, and more. It also includes valuable insights on career advice, code reviews, mindset, productivity, and personal growth in the software engineering field.","Professional Programming Resources: Must-read Books, Articles, and More","Discover a curated collection of full-stack resources tailored to make you a proficient developer. From must-read books like 'The Pragmatic Programmer' to insightful articles sharing hard-earned lessons in software development, this blogpost offers valuable guidance and resources carefully selected to enhance your programming journey. Whether you are seeking tips on career growth, best practices for code reviews, or recommendations for continuous learning, this comprehensive list covers a wide array of topics essential for every professional programmer.","Explore a comprehensive list of resources for professional programmers, including must-read books, insightful articles, and essential guidelines for career growth and code reviews. Enhance your programming journey with carefully curated advice and valuable resources to become a more proficient developer.",Software Development,"9,321 stars this week",https://raw.githubusercontent.com/charlax/professional-programming/master/./images/amazon_writing_rules.jpeg,https://www.youtube.com/watch?v=kPRA0W1kECg; https://www.youtube.com/watch?v=zkTf0LmDqKI; https://www.youtube.com/watch?v=mVVNJKv9esE; https://www.youtube.com/watch?v=LnX3B9oaKzw; https://www.youtube.com/watch?v=FKTxC9pl-WM; https://www.youtube.com/watch?v=f84n5oFoZBc; https://www.youtube.com/watch?v=2V1FtfBDsLU; https://www.youtube.com/watch?v=E7Fbf7R3x6I; https://www.youtube.com/watch?v=y8OnoxKotPQ; https://www.youtube.com/watch?v=Oj8bfBlwHAg,43213,2015-11-07T05:07:52Z
2024-02-28,https://github.com/sherlock-project/sherlock,https://raw.githubusercontent.com/sherlock-project/sherlock/master/README.md,"The text provides information about a tool called Sherlock, which allows users to search for social media accounts by username across different platforms. The document includes details on installation steps, how to use the tool for single or multiple usernames, and additional notes for Windows users and Docker installation. It also mentions contribution guidelines and testing information for developers, as well as provides links to the project's repository, wiki, and license. The tool is open-source under the MIT license and was created by Siddharth Dushantha. There is also a visualization of the project's stargazers over time.","Hunt Down Social Media Accounts with Sherlock: Installation, Usage, and Docker Notes","Learn how to use Sherlock to hunt down social media accounts by username. This blog post covers the installation process, how to use Sherlock for searching user accounts, and tips on running Sherlock in a Docker container. Discover how to search for single or multiple users, handle Anaconda notes in Windows, and contribute to Sherlock's development. Make the most of Sherlock by understanding its features and running tests to ensure smooth functionality.","Discover how to effectively hunt down social media accounts with Sherlock. This blog post covers the installation process, usage guide, and Docker notes for using Sherlock. Learn how to search for user accounts, handle Anaconda notes, contribute to Sherlock's development, and run tests to ensure reliable results.",Open Source Tool,"1,709 stars this week",,,49598,2018-12-24T14:30:48Z
2024-02-28,https://github.com/karpathy/minbpe,https://raw.githubusercontent.com/karpathy/minbpe/master/README.md,"The text describes a Python repository, ""minbpe,"" that implements the Byte Pair Encoding (BPE) algorithm used for Language Model tokenization. It provides Tokenizer classes for training vocabulary, encoding text to tokens, and decoding tokens to text. The repository includes classes like BasicTokenizer, RegexTokenizer, and GPT4Tokenizer, with different functionalities. The code also allows training custom tokenizers, handling special tokens, and ensuring feature parity with the GPT-4 tokenizer from tiktoken. The text suggests paths for training tokenizers and includes examples, tests, an exercise for studying BPE, and mentions future improvements like optimized Python versions. The code is open source under the MIT license.",Byte Pair Encoding (BPE) Algorithm: A Comprehensive Guide for Tokenization,"Minimal, clean code for the (byte-level) Byte Pair Encoding (BPE) algorithm commonly used in LLM tokenization. The BPE algorithm is 'byte-level' because it runs on UTF-8 encoded strings. This algorithm was popularized for LLMs by the GPT-2 paper and the associated GPT-2 code release from OpenAI. Sennrich et al. 2015 is cited as the original reference for the use of BPE in NLP applications. Today, all modern LLMs use this algorithm to train their tokenizers.","Learn about the Byte Pair Encoding (BPE) algorithm, its significance in tokenization for language models, and its role in popular LLMs like GPT series. Understand the implementation through examples and comparisons with GPT-4. Find out how to train your own tokenizer and explore the potential paths for development. Discover special token handling and ways to optimize the BPE algorithm. Dive into tests, exercises, and lectures on BPE. MIT License.",Language Models,"2,238 stars this week",,https://www.youtube.com/watch?v=zduSFxRajkE,7308,2024-02-16T16:18:15Z
2024-02-28,https://github.com/chatchat-space/Langchain-Chatchat,https://raw.githubusercontent.com/chatchat-space/Langchain-Chatchat/master/README.md,"LangChain-Chatchat is an open-source project that implements a retriever-augmented generator (RAG) large model knowledge base using ChatGLM and Langchain frameworks. Version `0.2.10` marks the end of the `0.2.x` series with no more updates, focusing on developing a more practical `Langchain-Chatchat 0.3.x`. The project aims to provide a user-friendly, offline-capable knowledge base question-answering solution tailored for the Chinese scene using open-source models. By leveraging FastChat, LangChain-Chatchat integrates various models like Vicuna, Alpaca, LLaMA, Koala, RWKV via FastAPI API or Streamlit WebUI. It supports private deployment using open LLM and Embedding models, and plans to expand integration with different models and APIs.",,,,Language Models,"1,590 stars this week",https://raw.githubusercontent.com/chatchat-space/Langchain-Chatchat/master/img/logo-long-chatchat-trans-v2.png; https://raw.githubusercontent.com/chatchat-space/Langchain-Chatchat/master/img/langchain+chatglm.png; https://raw.githubusercontent.com/chatchat-space/Langchain-Chatchat/master/img/langchain+chatglm2.png; https://raw.githubusercontent.com/chatchat-space/Langchain-Chatchat/master/img/fastapi_docs_026.png; https://raw.githubusercontent.com/chatchat-space/Langchain-Chatchat/master/img/LLM_success.png; https://raw.githubusercontent.com/chatchat-space/Langchain-Chatchat/master/img/init_knowledge_base.jpg,,23991,2023-03-31T12:12:45Z
2024-02-28,https://github.com/facebookresearch/DiT,https://raw.githubusercontent.com/facebookresearch/DiT/main/README.md,"The text introduces ""Scalable Diffusion Models with Transformers (DiT)"" implemented in PyTorch. The authors analyze the scalability and performance of DiTs compared to U-Net backbones using transformer models. They achieved state-of-the-art results on ImageNet benchmarks and provide pre-trained models for sampling. The repository includes PyTorch implementations, pre-trained models, training scripts, as well as sampling utilities. The impact of training on PyTorch versus JAX is discussed, showing similar performances. Additionally, tips for speeding up training and features to add are suggested. The text includes links to the paper, project page, implementation, and sampling resources and presents BibTeX for citation.",Scalable Diffusion Models with Transformers (DiT) - Official PyTorch Implementation,"This blog post presents the official PyTorch implementation of Scalable Diffusion Models with Transformers (DiT). The training process, model definitions, pre-trained weights, and sampling code are provided for DiTs. The post highlights the scalability of DiTs, their performance on ImageNet benchmarks, and the comparison with prior diffusion models. It also covers the setup, sampling, training, evaluation, and differences from JAX of the models.","Explore the official PyTorch implementation of Scalable Diffusion Models with Transformers (DiT). Learn about the scalability and performance of DiTs on ImageNet benchmarks. Discover the setup, sampling, training, evaluation, and differences from JAX of these models.",Language Models,"1,025 stars this week",https://raw.githubusercontent.com/facebookresearch/DiT/main/visuals/sample_grid_0.png; https://raw.githubusercontent.com/facebookresearch/DiT/main/visuals/sample_grid_1.png,,4046,2022-12-16T01:00:34Z
2024-02-28,https://github.com/jackfrued/Python-100-Days,https://raw.githubusercontent.com/jackfrued/Python-100-Days/master/README.md,"The text discusses a 100-day journey to go from a beginner to an expert in Python. It includes content revision and video tutorials for beginners to grasp foundational concepts easily. The author also emphasizes the application areas of Python and career development opportunities in fields like backend development, DevOps, data science, machine learning, and more. The text covers various topics such as basic Python language elements, branching and looping structures, functions, object-oriented programming, GUI and game development, file handling, string manipulation, regular expressions, network programming, image and document processing, data analysis, machine learning, and team project development. During the journey, various tools and concepts like Agile development, Docker containers, MySQL performance optimization, REST API design, Django development, software testing, deployment procedures, e-commerce website essentials, performance tuning, and interview preparation are discussed. The 100-day journey culminates with a detailed Python interview question compilation.",Python - 100å¤©ä»Žæ–°æ‰‹åˆ°å¤§å¸ˆ,Python - 100å¤©ä»Žæ–°æ‰‹åˆ°å¤§å¸ˆ blogpost text not longer than 5 sentences...,"Python - 100å¤©ä»Žæ–°æ‰‹åˆ°å¤§å¸ˆ blogpost with tips, projects, and resources. Learn Python and advance from novice to expert in 100 days with this comprehensive guide.",Python Learning Journey,"1,042 stars this week",https://raw.githubusercontent.com/jackfrued/Python-100-Days/master/./res/agile-scrum-sprint-cycle.png; https://raw.githubusercontent.com/jackfrued/Python-100-Days/master/./res/company_architecture.png; https://raw.githubusercontent.com/jackfrued/Python-100-Days/master/./res/pylint.png; https://raw.githubusercontent.com/jackfrued/Python-100-Days/master/./res/requirements_by_xmind.png; https://raw.githubusercontent.com/jackfrued/Python-100-Days/master/./res/uml-class-diagram.png; https://raw.githubusercontent.com/jackfrued/Python-100-Days/master/./res/power-designer-pdm.png,,147646,2018-03-01T16:05:52Z
2024-02-28,https://github.com/pydantic/FastUI,https://raw.githubusercontent.com/pydantic/FastUI/main/README.md,"FastUI is a new approach to creating web application user interfaces using declarative Python code, aiming to simplify frontend development. It allows Python developers to build responsive web apps with React without writing JavaScript, and enables frontend developers to focus on building reusable components. FastUI consists of Pydantic models and TypeScript interfaces to define the user interface and ensures validation at build time by TypeScript and Pyright/Mypy, and at runtime by Pydantic. It offers a PyPI package for UI components, a React TypeScript package, a Bootstrap implementation, and a pre-built React app. The RESTful principle behind FastUI enables a decoupled frontend and backend, promoting code reusability and development efficiency.",FastUI: Building Web Applications with Declarative Python Code,"FastUI is a new way to build web application interfaces using declarative Python code. It allows Python developers to create responsive web applications with React without writing any JavaScript. For frontend developers, this means concentrating on building reusable components. FastUI offers a true separation of concerns, enabling the backend to define the entire application while the frontend focuses solely on user interface implementation. This blog post explores the principles behind FastUI, its components, and how it simplifies web application development.","Discover FastUI, a new approach to building web app interfaces with declarative Python code. Learn how FastUI allows Python developers to create responsive web apps with React, no JavaScript required. Find out how FastUI promotes code reusability and separates frontend from backend concerns. Dive into the RESTful principle applied in FastUI and its advantages for web development.",Python Web Development,431 stars this week,https://raw.githubusercontent.com/pydantic/FastUI/main/screenshot.png,,4182,2023-09-18T08:12:00Z
2024-02-28,https://github.com/facebookresearch/jepa,https://raw.githubusercontent.com/facebookresearch/jepa/main/README.md,"The text provides information about the **V-JEPA (Video Joint Embedding Predictive Architecture)**, an architecture for self-supervised learning of visual representations from video developed by Meta AI Research at Facebook (FAIR). V-JEPA models are trained on the VideoMix2M dataset without requiring adaptation of model parameters. The models produce versatile visual representations that excel in downstream tasks. The method uses unsupervised feature prediction and does not rely on pretrained image encoders, text, negative examples, human annotations, or pixel-level reconstruction. The text also includes details about the architecture, visualizations, model zoo with pretrained models, code structure, data preparation, launching V-JEPA pretraining, and license information.",V-JEPA: Video Joint Embedding Predictive Architecture - Unsupervised Visual Representation Learning from Video,"Official PyTorch codebase for the video joint-embedding predictive architecture, V-JEPA, a method for self-supervised learning of visual representations from video. V-JEPA models produce versatile visual representations that perform well on downstream tasks using unsupervised feature prediction. The blog also discusses the method, visualizations, model zoo, code structure, data preparation, launching V-JEPA pretraining, and evaluating the models.","Explore V-JEPA, an architecture for self-supervised learning of visual representations from videos. Discover how V-JEPA models create versatile visual representations and perform well on various downstream video and image tasks. Learn about V-JEPA's unsupervised feature prediction approach and how it achieves spatio-temporal consistency with video regions.",Self-Supervised Learning Architecture.,473 stars this week,,https://www.youtube.com/watch?v=7UkJPwz_N_0,1614,2024-02-12T15:34:31Z
2024-02-28,https://github.com/danswer-ai/danswer,https://raw.githubusercontent.com/danswer-ai/danswer/main/README.md,"Danswer is an open-source tool that allows users to ask questions in natural language and receive answers based on specific team documents. It connects to common workplace tools such as Slack, Google Drive, and Confluence. Teams have used Danswer to improve customer support, engineering efficiency, sales preparation, customer request tracking, and more. The tool offers document search, AI answers, connectors to various tools, chat support, and the ability to create custom AI assistants. Danswer also provides features like hybrid search, user authentication, admin dashboard, custom deep learning models, and flexible deployment options. The roadmap includes features like organizational understanding, code search, and more. If you're interested in contributing, check out the Contribution Guide.",Enhance Team Efficiency with Danswer: AI Document Search and Gen-AI Chat,"Danswer is an Open Source Unified Search and Gen-AI Chat tool that empowers teams to improve customer support, engineering efficiency, sales preparation, and more. It connects to various workplace tools such as Slack, Google Drive, Confluence, and others, enabling users to ask questions in natural language and receive answers from team-specific documents. With Danswer, teams can streamline processes, track customer requests, and self-serve in various domains including IT, onboarding, and HR. Explore Danswer's features, deployment options, connectors, and roadmap to maximize your team's productivity.","Discover how Danswer, an AI-powered document search and chat tool, enhances team efficiency by improving customer support, engineering processes, sales preparation, and more. Connect with various workplace tools and streamline workflows effectively. Learn about Danswer's features, deployment options, and roadmap for continuous improvement.",Natural Language Processing,848 stars this week,,https://www.youtube.com/watch?v=geNzY1nbCnU,8229,2023-04-27T06:04:01Z
2024-02-28,https://github.com/public-apis/public-apis,https://raw.githubusercontent.com/public-apis/public-apis/master/README.md,"The text provides a comprehensive list of free Public APIs for software and web development. It includes APIs from various categories like Animals, Anime, Anti-Malware, Art & Design, Authentication & Authorization, Blockchain, Books, Business, Calendar, Cloud Storage & File Sharing, Continuous Integration, Cryptocurrency, and Currency Exchange. Each category contains multiple APIs with descriptions, authentication requirements, HTTPS support, and CORS availability. Developers can access a wide range of data and functionalities for their projects, such as animal pictures, anime quotes, holiday data, file sharing, market data for cryptocurrencies, exchange rates, and much more.",Discover Public APIs for Software and Web Development,"Explore a collective list of free APIs for software and web development purposes. Find APIs related to various categories such as Animals, Anime, Anti-Malware, Art & Design, Authentication & Authorization, Blockchain, Books, Business, Calendar, Cloud Storage & File Sharing, Continuous Integration, Cryptocurrency, Currency Exchange, and more. Each API comes with a description, authentication requirements, whether it supports HTTPS, and its CORS policy.","Discover a curated list of free APIs for software and web development purposes. Explore various categories such as Animals, Anime, Anti-Malware, Art & Design, Blockchain, Books, Business, Calendar, Cryptocurrency, and more. Each API includes a description, authentication details, HTTPS support, and CORS policy.",Public APIs Collection,"1,567 stars this week",,,283081,2016-03-20T23:49:42Z
2024-02-28,https://github.com/cubiq/ComfyUI_InstantID,https://raw.githubusercontent.com/cubiq/ComfyUI_InstantID/main/README.md,"The text discusses the ComfyUI InstantID extension, providing native support for InstantID with important updates like noise injection and bug fixes. Users can find basic workflows and a video tutorial for installation assistance. To install, users must upgrade ComfyUI, download required libraries/models, and address watermarks. Lowering CFG and using noise injection can enhance results. The extension supports face keypoints, additional controlnets, styling with IPAdapter, and multi-ID. An advanced node offers more control over InstantID modeling and noise. Overall, the extension works best with SDXL Turbo/Lighting and community's checkpoints for optimal results.",ComfyUI InstantID (Native Support) - Important Updates and Installation Guide,"Native InstantID support for ComfyUI. This extension integrates InstantID natively with ComfyUI, eliminating the need for diffusers. Updates include noise injection in negative embeds, bug fixes, and improved node usability. Learn how to install InstantID with InsightFace model, controlnet, and main model. Discover tips for avoiding watermarks, adjusting CFG, utilizing face keypoints, noise injection, and additional controlnets. Explore styling options with IPAdapter and consider Multi-ID support. An advanced InstantID node is available for fine-tuning compositions.","Discover the latest updates and installation guide for ComfyUI's Native InstantID support. Learn about noise injection, bug fixes, model installations, watermark avoidance, CFG adjustments, face keypoints, and styling options. Explore Multi-ID support and the advanced InstantID node for efficient composition tweaking.",Software Development,102 stars this week,https://raw.githubusercontent.com/cubiq/ComfyUI_InstantID/main/examples/instantid_basic_workflow.jpg,https://www.youtube.com/watch?v=wMLiGhogOPE; https://www.youtube.com/watch?v=wMLiGhogOPE,367,2024-01-27T17:07:29Z
2024-02-28,https://github.com/lllyasviel/stable-diffusion-webui-forge,https://raw.githubusercontent.com/lllyasviel/stable-diffusion-webui-forge/main/README.md,"The Stable Diffusion WebUI Forge is a platform built on top of the Stable Diffusion WebUI to enhance development, resource management, and speed up inference. The project draws inspiration from ""Minecraft Forge."" It offers significant speed-ups in inference based on different GPU configurations. Forge introduces the Unet Patcher feature, making it easier to implement methods like Self-Attention Guidance, Kohya High Res Fix, FreeU, etc., in just about 100 lines of code. Additionally, Forge includes new samplers like DDPM, DDPM Karras, DPM++ 2M Turbo, among others. Extensions like Masked Ip-Adapter, Masked ControlNet, PhotoMaker, as well as various preprocessor and control enhancements, have been made possible with Forge. Contributing to Forge is done through a bot that merges commits from the original repository automatically.",Stable Diffusion WebUI Forge Features and Installation Guide,"Stable Diffusion WebUI Forge is a powerful platform built on top of Stable Diffusion WebUI with the goal of enhancing development, optimizing resource management, and boosting inference speed. It introduces significant improvements, like the 'Unet Patcher' which simplifies the implementation of advanced methods like Self-Attention Guidance and Kohya High Res Fix. Additionally, Forge offers new capabilities such as ControlNets, samplers like DDPM and LCM Karras, and a seamless installation process for users proficient in Git or using the one-click installation package.","Discover the new features and enhancements brought by Stable Diffusion WebUI Forge, a powerful platform offering improved resource management, faster inference speeds, and simplified extension development. Learn how to install Forge using Git or a convenient one-click installation package.",Deep Learning Platform,540 stars this week,,,2508,2024-01-14T11:39:30Z
2024-02-28,https://github.com/guoyww/AnimateDiff,https://raw.githubusercontent.com/guoyww/AnimateDiff/main/README.md,"The text discusses the AnimateDiff project, an implementation to animate personalized text-to-image diffusion models without specific tuning. It consists of various versions, such as v1, v2, and v3, as well as modules like MotionLoRA and SparseCtrl. The project enables animation generation from community models like RealisticVision and ToonYou. The user interface was developed by the community, and a Gradio demo is available. The text provides technical details, model zoo links, setup instructions, demo examples, common issues, and contact information. The project is for academic use, and citations are provided. For more details, you can refer to the original text.",AnimateDiff: Animate Your Personalized Text-to-Image Diffusion Models without Specific Tuning,"This repository is the official implementation of AnimateDiff, a plug-and-play module turning most community models into animation generators, without the need of additional training. We developed four versions of AnimateDiff, each offering unique features and improvements over the previous versions. The latest version, AnimateDiff v3, introduces features like **Domain Adapter LoRA**, as well as two (RGB image/scribble) SparseCtrl Encoders for enhanced control over the generation process. AnimateDiff makes it easy to create animations from text-to-image models, providing various options for users to customize their animations.","Learn about AnimateDiff, a powerful module that allows users to animate text-to-image diffusion models without specific tuning. Discover the latest version, AnimateDiff v3, with features like Domain Adapter LoRA and SparseCtrl Encoders for enhanced control. Read about the various community models and contributions, and explore the possibilities of creating personalized animations using AnimateDiff.",Computer Vision,181 stars this week,,https://www.youtube.com/watch?v=mfaqqL5yOO4; https://www.youtube.com/watch?v=N1tXVR9lplM; https://www.youtube.com/watch?v=zss3xbtvOWw,7878,2023-06-17T11:14:28Z
2024-02-28,https://github.com/vvbbnn00/WARP-Clash-API,https://raw.githubusercontent.com/vvbbnn00/WARP-Clash-API/master/README.md,"The text is a guide for using the WARP Clash API, a tool that enables subscription-based usage of WARP+ for various clients like Clash and Shadowrocket. It includes features like unlimited WARP+ traffic, IP optimization, automated traffic scraping, and manual IP optimization. The setup involves installing Docker and Docker Compose, cloning the project, configuring environment variables, compiling and running with Docker Compose, and obtaining the subscription link. The text also covers manual IP optimization steps and a list of available environment variables for customization. Advanced operations such as resetting PublicKey/PrivateKey and setting LicenseKey are explained as well. The text acknowledges and references open-source projects the WARP Clash API is built upon. There's also information about a community-deployed instance of the tool.",WARP Clash API: Enjoy Fast Private Nodes with Docker Compose Deployment,"The WARP Clash API project allows you to use 'WARP+' by subscription, supporting clients like Clash and Shadowrocket. It features unlimited WARP+ traffic access with IP optimization and Docker compose one-click deployment. Enjoy automatic traffic renewal and random node updates for a unique experience. Follow the easy steps to set up and run the project, including configuring your own 'LicenseKey' and optional settings like 'SECRET_KEY'. Take advantage of manual IP optimization if needed.","Discover how to set up and deploy WARP Clash API for fast, private nodes using Docker compose. Enjoy unique features like IP optimization and automatic traffic renewal. Learn about configuring settings such as 'SECRET_KEY' and 'LicenseKey'. Read on for a step-by-step guide and manual IP optimization options.",Public APIs Collection,"2,873 stars this week",,,4033,2023-08-23T19:19:40Z
2024-02-28,https://github.com/vinta/awesome-python,https://raw.githubusercontent.com/vinta/awesome-python/master/README.md,"The text is a list of various Python libraries and resources categorized into different sections like Admin Panels, Algorithms and Design Patterns, ASGI Servers, Asynchronous Programming, Audio, Authentication, and many more. Each section contains libraries and frameworks related to that specific topic. It covers a wide range of areas from web development, machine learning, networking, to game development. Some notable libraries mentioned include Django, SQLAlchemy, Scikit-learn, Flask, TensorFlow, and many more. Overall, the text serves as a comprehensive guide to the diverse ecosystem of Python libraries and resources available for developers.",A Comprehensive Guide to Python Frameworks and Libraries,"Discover a wide range of Python frameworks, libraries, and tools in this detailed blog post. From web development frameworks like Django and Flask to machine learning frameworks like scikit-learn and TensorFlow, explore the diverse ecosystem of Python resources available for developers. Dive into categories such as Admin Panels, Algorithms and Design Patterns, ASGI Servers, Asynchronous Programming, Audio processing, Authentication, and much more. Delve into essential tools for web crawling, GUI development, data visualization, and distributed computing. Whether you're a beginner or an experienced developer, this blog post will help you navigate the vast landscape of Python libraries and choose the right tools for your projects.","Explore a comprehensive guide to Python frameworks, libraries, and tools covering web development, machine learning, data analysis, and more. Learn about popular categories such as Admin Panels, Algorithms, ASGI Servers, Asynchronous Programming, Audio processing, Authentication, and more.",Python Libraries Collection,925 stars this week,,,199360,2014-06-27T21:00:06Z
2024-02-28,https://github.com/zhayujie/chatgpt-on-wechat,https://raw.githubusercontent.com/zhayujie/chatgpt-on-wechat/master/README.md,"This project is an intelligent chatbot based on large models, supporting integration with WeChat, Enterprise WeChat, Public Accounts, Feishu, and DingTalk. Users can choose from various models like GPT3.5, GPT4.0, Claude, Wenxin One Word, Xunfei Starfire, Tongyi Qianwen, Gemini, LinkAI, ZhipuAI, capable of processing text, voice, and images. It can access external resources such as operating systems and the internet through plugins, supporting customization for enterprise AI applications based on proprietary knowledge bases. The latest version includes features like multi-platform deployment, basic conversation capabilities, speech recognition, image processing, rich plugins, and knowledge base customization. 

For commercial support and business consultancy, contact the product consultant provided in the text. The project also offers support for enterprise-level AI application platforms with features like knowledge bases, agent plugins, application management, SaaS services, private deployment, and stable hosting access. It has accumulated various AI solutions in scenes such as private domain operations, intelligent customer service, and enterprise efficiency assistants, aiming to create a one-stop platform for small and medium-sized enterprises embracing AI technology. 

For more detailed information, updates, and interactions with the open-source community, refer to the links and resources provided in the text.","Intelligent Chatbot Blog: Features, Deployment Options, and More","This project is an intelligent chatbot based on large models, supporting integration with WeChat, enterprise WeChat, public accounts, Feishu, and DingTalk. It offers a choice of GPT3.5/GPT4.0/Claude/Wenxin Yiyuan/Xunfei Xinghuo/Tongyi Qianwen/Gemini/LinkAI/ZhipuAI models, with capabilities to handle text, voice, and images. The latest version includes features such as multi-end deployment, basic conversation capabilities, voice recognition, image capabilities, rich plugins, and knowledge base customization.","Explore the latest features, deployment options, and capabilities of an intelligent chatbot based on large models. Learn about multi-end deployment, basic conversation features, voice and image capabilities, rich plugins, and knowledge base customization. Discover how to integrate GPT3.5/GPT4.0/Claude/Wenxin Yiyuan/Xunfei Xinghuo/Tongyi Qianwen/Gemini/LinkAI/ZhipuAI models for enhanced AI applications.",Artificial Intelligence,710 stars this week,,,22441,2022-08-07T08:33:41Z
2024-02-28,https://github.com/FujiwaraChoki/MoneyPrinterV2,https://raw.githubusercontent.com/FujiwaraChoki/MoneyPrinterV2/main/README.md,"MoneyPrinter V2 is an application designed to automate the process of earning money online. It is the second version of the MoneyPrinter project, featuring a comprehensive rewrite for improved functionality and a modular structure. The application includes features like a Twitter Bot, YouTube Shorts Automater, affiliate marketing options, and tools for finding local businesses and conducting outreach. To use MPV2 effectively, Python 3.9 is required. Installation involves setting up Microsoft Visual C++ build tools and potentially the Go Programming Language. The project is licensed under the Affero General Public License v3.0 and is strictly for educational purposes. Detailed documentation and contribution guidelines are provided in the project repository.",MoneyPrinter V2 - Automate Your Online Earnings Effortlessly,"An Application that automates the process of making money online. MPV2 (MoneyPrinter Version 2) is, as the name suggests, the second version of the MoneyPrinter project. It is a complete rewrite of the original project, with a focus on a wider range of features and a more modular architecture. This blogpost introduces the features, installation steps, usage instructions, documentation, contribution guidelines, license information, acknowledgments, and a disclaimer for the MoneyPrinterV2 project.","Discover how MoneyPrinter V2 can streamline your online income generation with its advanced features and modular architecture. Learn how to install and use the application effectively. Find out about the documentation, contribution guidelines, license details, acknowledgments, and disclaimer associated with MoneyPrinter V2.",Money Making Automation,951 stars this week,,https://www.youtube.com/watch?v=wAZ_ZSuIqfk,1369,2024-02-12T11:20:42Z
2024-02-28,https://github.com/microsoft/UFO,https://raw.githubusercontent.com/microsoft/UFO/main/README.md,"The text introduces a novel framework called **UFO** (UI-Focused Agent for Windows OS Interaction), which consists of two agents, AppAgent and ActAgent, along with Control Interaction. UFO leverages GPT-Vision to understand and fulfill user requests across multiple applications on Windows OS. It facilitates natural language translation into actionable operations, offers interactive mode handling multiple sub-requests, includes safeguards for sensitive actions, and allows for easy extensibility. The provided steps guide users to install and configure UFO, start the process, and review execution logs. The text also mentions the availability of a technical report, news updates, highlights, citations, and related projects.",UFO: A UI-Focused Agent for Windows OS Interaction,"UFO is a UI-Focused dual-agent framework for fulfilling user requests on Windows OS. It comprises AppAgent for selecting applications and ActAgent for executing actions, with Control Interaction translating actions into UI interactions. Using GPT-Vision, UFO understands app UIs to fulfill requests. Features include being the first Windows agent, interactive mode, action safeguards, and extensibility.","Learn about UFO, a pioneering UI-Focused agent framework for Windows OS interaction. Discover its capabilities like app selection, action execution, and UI interaction translation using GPT-Vision. Find out about its features such as being the first Windows agent, interactive mode, and extensibility for tackling diverse tasks.",Natural Language Processing.,764 stars this week,,,2273,2024-01-08T05:07:52Z
2024-02-28,https://github.com/mouredev/Hello-Python,https://raw.githubusercontent.com/mouredev/Hello-Python/main/README.md,"The text provides information about a Python programming course that covers various topics such as fundamentals, intermediate concepts, backend development, and integrating ChatGPT into projects. It includes video classes on different aspects of Python, backend, frontend development, and a session on integrating ChatGPT. The course addresses common FAQs and provides links to helpful resources, official Python documentation, and tools like FastAPI, MongoDB, and Deta for backend development. The course's creator encourages support through GitHub stars. Additionally, there's an invitation to join the developer community on platforms like Twitch, Discord, and links to the creatorâ€™s social media channels.",Learn Python Programming from Scratch for Beginners,"Curso para aprender el lenguaje de programaciÃ³n Python desde cero y para principiantes. Proyecto realizado durante emisiones en directo desde Twitch. Â¡NUEVO! Curso de Python para web. Clases en vÃ­deo que cubren desde fundamentos hasta backend. TambiÃ©n incluye cursos de frontend y cÃ³mo integrar ChatGPT en tu proyecto. AdemÃ¡s, un taller de introducciÃ³n al testing con Python y curiosidades sobre Python.","Join our course to learn Python programming from scratch designed for beginners. This course includes live-streamed projects, a new Python web course, video classes covering fundamentals to backend, frontend projects, integrating ChatGPT, introduction to testing, and fun Python facts.",Python Learning Journey,605 stars this week,https://raw.githubusercontent.com/mouredev/Hello-Python/main/./Images/header.jpg; https://raw.githubusercontent.com/mouredev/mouredev/master/mouredev_emote.png,https://www.youtube.com/watch?v=Kp4Mvapo5kc; https://www.youtube.com/watch?v=Kp4Mvapo5kc; https://www.youtube.com/watch?v=Kp4Mvapo5kc; https://www.youtube.com/watch?v=Kp4Mvapo5kc; https://www.youtube.com/watch?v=Kp4Mvapo5kc; https://www.youtube.com/watch?v=Kp4Mvapo5kc; https://www.youtube.com/watch?v=Kp4Mvapo5kc; https://www.youtube.com/watch?v=Kp4Mvapo5kc; https://www.youtube.com/watch?v=Kp4Mvapo5kc; https://www.youtube.com/watch?v=Kp4Mvapo5kc; https://www.youtube.com/watch?v=Kp4Mvapo5kc; https://www.youtube.com/watch?v=Kp4Mvapo5kc; https://www.youtube.com/watch?v=Kp4Mvapo5kc; https://www.youtube.com/watch?v=Kp4Mvapo5kc; https://www.youtube.com/watch?v=Kp4Mvapo5kc; https://www.youtube.com/watch?v=Kp4Mvapo5kc; https://www.youtube.com/watch?v=Kp4Mvapo5kc; https://www.youtube.com/watch?v=Kp4Mvapo5kc; https://www.youtube.com/watch?v=Kp4Mvapo5kc; https://www.youtube.com/watch?v=TbcEqkabAWU; https://www.youtube.com/watch?v=TbcEqkabAWU; https://www.youtube.com/watch?v=TbcEqkabAWU; https://www.youtube.com/watch?v=TbcEqkabAWU; https://www.youtube.com/watch?v=TbcEqkabAWU; https://www.youtube.com/watch?v=TbcEqkabAWU; https://www.youtube.com/watch?v=TbcEqkabAWU; https://www.youtube.com/watch?v=TbcEqkabAWU; https://www.youtube.com/watch?v=TbcEqkabAWU; https://www.youtube.com/watch?v=TbcEqkabAWU; https://www.youtube.com/watch?v=TbcEqkabAWU; https://www.youtube.com/watch?v=TbcEqkabAWU; https://www.youtube.com/watch?v=_y9qQZXE24A; https://www.youtube.com/watch?v=_y9qQZXE24A; https://www.youtube.com/watch?v=_y9qQZXE24A; https://www.youtube.com/watch?v=_y9qQZXE24A; https://www.youtube.com/watch?v=_y9qQZXE24A; https://www.youtube.com/watch?v=_y9qQZXE24A; https://www.youtube.com/watch?v=_y9qQZXE24A; https://www.youtube.com/watch?v=_y9qQZXE24A; https://www.youtube.com/watch?v=_y9qQZXE24A; https://www.youtube.com/watch?v=_y9qQZXE24A; https://www.youtube.com/watch?v=_y9qQZXE24A; https://www.youtube.com/watch?v=_y9qQZXE24A; https://www.youtube.com/watch?v=_y9qQZXE24A; https://www.youtube.com/watch?v=_y9qQZXE24A; https://www.youtube.com/watch?v=_y9qQZXE24A; https://www.youtube.com/watch?v=_y9qQZXE24A; https://www.youtube.com/watch?v=_y9qQZXE24A; https://www.youtube.com/watch?v=_y9qQZXE24A; https://www.youtube.com/watch?v=_y9qQZXE24A; https://www.youtube.com/watch?v=_y9qQZXE24A; https://www.youtube.com/watch?v=_y9qQZXE24A; https://www.youtube.com/watch?v=b8COygWdvmw; https://www.youtube.com/watch?v=344uwF1z2Gg; https://www.youtube.com/watch?v=q2lCm2KAz3w,20463,2022-08-03T17:14:53Z
2024-02-28,https://github.com/xtekky/gpt4free,https://raw.githubusercontent.com/xtekky/gpt4free/main/README.md,"The text provides information about a project called ""gpt4free"" which is a proof of concept demonstrating the development of an API package with features like timeouts, load balance, and flow control. It includes details on the latest version, stats, how to get started using Docker or Python, and the usage of various models like GPT-4 and GPT-3.5. It also mentions the availability of a web UI, interference API, and configuration options. The text also covers a table of contents, providers and models list, related projects, how to contribute, list of contributors, copyright information, star history, and the project's license which is GNU GPL v3.","Latest Developments in AI API Package: New Features, Guides, and Providers","Discover the latest innovations in the AI API package world! From new guides on using smartphones to run the package to exploring how AI can assist with code writing, there's something for everyone. Join our active community on Telegram and Discord for updates and discussions. Have a site on the repository and need it taken down? Simply email takedown@g4f.ai! We're focused on improving documentation, provider status updates, and enhancing compatibility and error handling. Stay tuned for upcoming improvements and tutorials!","Stay updated with the latest developments in the AI API package world, featuring new guides, providers, and features. Join our Telegram and Discord community, learn how to use smartphones, and discover AI's potential in code writing. Need a site taken down from the repository? Contact us at takedown@g4f.ai. We're working on enhancing documentation, provider status, and more - all aimed at improving user experience and functionality.",Open Source Tool,935 stars this week,https://raw.githubusercontent.com/xtekky/gpt4free/main//docs/cat.jpeg,,53958,2023-03-29T17:00:43Z
2024-02-28,https://github.com/reflex-dev/reflex,https://raw.githubusercontent.com/reflex-dev/reflex/main/README.md,"The text informs readers that Pynecone has been renamed to Reflex and is the right repo to search for. Reflex is a tool for creating performant, customizable web apps in pure Python. The installation process involves running `pip install reflex` in the terminal. Users can create their first app by utilizing the `reflex` command line tool. An example app is provided for creating an image generation UI around DALLÂ·E using the OpenAI API. The text also covers the Reflex UI, state management, event handlers, routing, status updates, contributing guidelines, and acknowledges contributors. Reflex is in the Public Beta stage as of July 2023.",Reflex: Performant Python Web Apps - Quick Installation & Building Examples,"Learn how to quickly create performant and customizable web apps in pure Python using Reflex. Check out the easy installation steps and dive into building examples like creating an image generation UI around OpenAI's DALLÂ·E. With Reflex, you can easily deploy and host your apps with fast refreshes for instant changes.",Discover how to build performant and customizable web apps in Python with Reflex. Follow the simple installation steps and explore building examples like creating an image generation UI using OpenAI's DALLÂ·E. Deploy your apps quickly and enjoy fast refreshes for instant updates.,Python Web Development,146 stars this week,,,15099,2022-10-25T03:08:48Z
2024-02-28,https://github.com/ndleah/python-mini-project,https://raw.githubusercontent.com/ndleah/python-mini-project/main/README.md,"The provided text is about a Python Mini Projects repository where beginners and experts can learn and share their knowledge. It includes a collection of easy Python projects like dice rolling, dictionary, hangman game, tic-tac-toe, plotter, and more. The text also explains how to contribute to the project, including starring the repo, forking, cloning, creating feature branches, making pull requests, and updating the local repository. Additionally, it provides a table of contents detailing the aim of the project, contributing guidelines, README template, list of projects, and feedback section. You can find more details and guidelines on the project's GitHub repository page.",Python Mini Projects - Easy Python Small Projects to Improve Programming Skills,A collection of easy Python small projects to help you improve your programming skills. This project is designed for folks who are just getting started with Python principles and exploring GitHub as 'contributors.' Let's 'folk-ing' create amazing things together! Follow the steps to contribute and explore various mini projects from dice rolling to game creation.,"Explore a collection of easy Python small projects designed to help you improve your programming skills. Contribute, learn, and share knowledge from dice rolling stimulator to game creation. Let's 'folk-ing' create amazing things with these fun Python projects!",Python Learning Journey,320 stars this week,https://docs.github.com/assets/images/help/stars/starring-a-repository.png; https://upload.wikimedia.org/wikipedia/commons/3/38/GitHub_Fork_Button.png; https://i.ytimg.com/vi/rgbCcBNZcdQ/maxresdefault.jpg,,2140,2021-07-16T09:05:09Z
2024-02-28,https://github.com/Pythagora-io/gpt-pilot,https://raw.githubusercontent.com/Pythagora-io/gpt-pilot/main/README.md,"GPT Pilot is an AI developer that assists in coding, debugging, and creating apps by coding step by step, similar to real-life processes, while the developer oversees. It interacts with you, asks questions, sets up requirements, and helps with coding tasks. The VS Code extension offers a real AI developer companion. The aim is for AI to write most of the code for an app, requiring human intervention for only 5% of tasks until full AGI is achieved. GPT Pilot works collaboratively with developers, focusing on developing production-ready apps, with examples like a chat app and a markdown editor. Join their Discord for updates and contributions.",GPT Pilot: AI Developer Companion for Code Generation,"GPT Pilot is a cutting-edge AI developer that assists in writing code, debugging, and more. This innovative tool engages users in specifying the type of app they want to create, asking clarifying questions, creating technical requirements, setting up the environment, and coding the app step by step while allowing developers to review and intervene when necessary. GPT Pilot aims to explore the potential of leveraging AI, particularly GPT-4, to generate fully functional apps, emphasizing the need for developer oversight in the final stages for optimal results.","Discover how GPT Pilot, a true AI developer companion, streamlines the app development process by handling code generation and step-by-step coding under developer supervision. Explore the capabilities and workings of GPT Pilot, a tool designed to assist in writing production-ready apps while highlighting the essential role of developers in ensuring code quality and functionality.",AI Coding Assistant,470 stars this week,,https://www.youtube.com/watch?v=-OB6BJKADEo; https://www.youtube.com/watch?v=7t-Q2e7QsbE; https://www.youtube.com/watch?v=bUj9DbMRYhA; https://www.youtube.com/watch?v=uZeA1iX9dgg; https://www.youtube.com/watch?v=CMN3W18zfiE,21946,2023-08-16T11:56:07Z
2024-02-28,https://github.com/huggingface/transformers,https://raw.githubusercontent.com/huggingface/transformers/main/README.md,"The text discusses the Hugging Face Transformers Library, a state-of-the-art machine learning library for JAX, PyTorch, and TensorFlow. The library provides pre-trained models for various tasks such as text, vision, and audio processing. It offers APIs for downloading and using pretrained models, fine-tuning them, and sharing them with the community. The library is compatible with the three popular deep learning libraries (JAX, PyTorch, TensorFlow) and allows seamless integration between them. It also provides online demos and showcases multiple examples of using pretrained models for tasks like language processing, image analysis, and more. The text also covers the installation process for the library and introduces various model architectures available within the library.","Transformers: State-of-the-art Machine Learning for JAX, PyTorch and TensorFlow","ðŸ¤— Transformers provides thousands of pretrained models to perform tasks on different modalities such as text, vision, and audio. These models can be applied on various tasks like text classification, image recognition, and speech processing, supporting over 100 languages. The library offers APIs for easy model downloads, fine-tuning on custom datasets, and model sharing through the model hub. Built on JAX, PyTorch, and TensorFlow, ðŸ¤— Transformers enables seamless integration between deep learning frameworks, making it easy to train and deploy models.","Discover how ðŸ¤— Transformers library provides state-of-the-art pretrained models for text, vision, and audio tasks in multiple languages. Learn how to download, fine-tune, and share models using APIs for JAX, PyTorch, and TensorFlow.",Natural Language Processing.,572 stars this week,,,121022,2018-10-29T13:56:00Z
2024-02-28,https://github.com/s0md3v/roop,https://raw.githubusercontent.com/s0md3v/roop/main/README.md,"The text describes a project called Roop, which has been discontinued with no future updates. However, the software can still be used for face replacement in videos. The installation process requires technical skills and is not recommended for beginners. The software is designed to assist in tasks like character animation, but users are advised to use it responsibly and abide by local laws. The developers have taken measures to prevent inappropriate content use. The software uses third-party libraries and pre-trained models with their own licenses. Credits are given to deepinsight for their insightface project and to other developers whose libraries were used. You can refer to the provided documentation for more details.",Roop - Video Face Swapper and Enhancer Software with Ethical Guidelines,"This project Roop, a video face swapper tool, has been discontinued but still operational. The software won't receive updates but can replace faces in videos. Users are guided on installation through a helpful Discord community. Roop aims to positively impact the AI-generated media industry while enforcing ethical usage guidelines.",Roop is a powerful video face swapper and enhancer software that continues to work despite being discontinued. Learn how to install and use the tool through a helpful Discord community. Follow ethical guidelines to ensure responsible usage of the software for positive contributions to the AI-generated media industry.,Computer Vision,222 stars this week,,,24075,2023-05-28T14:37:54Z
2024-02-29,https://github.com/OpenCodeInterpreter/OpenCodeInterpreter,https://raw.githubusercontent.com/OpenCodeInterpreter/OpenCodeInterpreter/main/README.md,"OpenCodeInterpreter integrates code generation with execution and refinement, enhancing capabilities by combining large language models with sophisticated systems like GPT-4 Code Interpreter. The suite includes various models that have been open-sourced on Hugging Face. Data collection involves interactions and feedback from the Code-Feedback dataset to refine code dynamically. Evaluation employs frameworks like HumanEval and MBPP, with extended versions for comprehensive assessment. An open-source demo allows users to generate and execute code with a locally trained language model, providing automated feedback and adjusting code based on interactions. Detailed instructions are available to explore the demo and engage in chat-based interactions with the model. For inquiries, contact via email.",OpenCodeInterpreter: Enhancing Code Generation with Execution and Refinement,"OpenCodeInterpreter is a suite of open-source code generation systems that integrate execution and iterative refinement functionalities to enhance code generation capabilities, bridging the gap between large language models and proprietary systems like the GPT-4 Code Interpreter. The models within the OpenCodeInterpreter series have been open-sourced on Hugging Face, offering access to a range of models for code generation. Data Collection for OpenCodeInterpreter is supported by the Code-Feedback dataset, which features multi-turn interactions for dynamic code refinement. The evaluation framework of OpenCodeInterpreter utilizes HumanEval and MBPP methods, along with their extended versions, for a more comprehensive assessment. Additionally, an open-source demo is available for users to generate and execute code with the LLM, providing automated execution feedback and chat-based interactions with the model.","Explore how OpenCodeInterpreter enhances code generation by integrating execution and iterative refinement functionalities. Learn about the open-source models on Hugging Face, data collection with the Code-Feedback dataset, evaluation methods using HumanEval and MBPP, and experience the capabilities of the demo for generating and executing code. Reach out to the team for inquiries and get involved in enhancing code generation processes!",Language Models.,"Python





        935





        134


        Built by

          









        62 stars today",,,935,2024-02-19T14:43:38Z
2024-02-29,https://github.com/joaomdmoura/crewAI,https://raw.githubusercontent.com/joaomdmoura/crewAI/main/README.md,"The text is about **crewAI**, an advanced framework for managing autonomous AI agents collaboratively. It enables agents to work together on complex tasks by assuming roles, sharing goals, and operating seamlessly. The framework allows for installation and setup steps, creating agents with roles and goals, defining tasks, managing processes, and connecting agents to models like OpenAI or local models through tools. Key features include role-based agent design, autonomous task delegation, task management, saving output, parsing output, and compatibility with open-source models. CrewAI is compared to Autogen and ChatDev, highlighting its flexibility and adaptability. The text also covers contribution guidelines, hiring options, telemetry usage, and licensing.",Unlocking AI Collaboration with crewAI: A Cutting-Edge Framework for Agents,"crewAI is a cutting-edge framework designed to facilitate seamless collaboration among AI agents, enabling them to work together in a cohesive unit. Whether you're creating a smart assistant platform or a multi-agent research team, crewAI provides the foundation for sophisticated multi-agent interactions. With role-based agent design, autonomous delegation capabilities, and flexible task management, crewAI empowers agents to tackle complex tasks effectively. Explore how crewAI compares to other AI frameworks and learn how to connect your crew to different Language Model Models (LLMs). Join us in harnessing the power of collaborative intelligence with crewAI!","Discover crewAI, a state-of-the-art framework that enables AI agents to collaborate effectively. Learn about role-based agent design, autonomous delegation, and task management features. Find out how crewAI stands out among other AI frameworks and how to connect your crew to LLMs. Unleash the potential of collaborative intelligence with crewAI!",Collaborative AI Framework,"Python





        8,540





        953


        Built by

          









        86 stars today",https://raw.githubusercontent.com/joaomdmoura/crewAI/main/./docs/crewai_logo.png; https://img.youtube.com/vi/tnejrr-0a94/maxresdefault.jpg; https://img.youtube.com/vi/u98wEMz-9to/maxresdefault.jpg; https://img.youtube.com/vi/xis7rWp-hjs/maxresdefault.jpg; https://img.youtube.com/vi/e0Uj4yWdaAg/maxresdefault.jpg,https://www.youtube.com/watch?v=tnejrr-0a94; https://www.youtube.com/watch?v=u98wEMz-9to; https://www.youtube.com/watch?v=xis7rWp-hjs; https://www.youtube.com/watch?v=e0Uj4yWdaAg,8540,2023-10-27T03:26:59Z
2024-02-29,https://github.com/SciPhi-AI/R2R,https://raw.githubusercontent.com/SciPhi-AI/R2R/main/README.md,"The text introduces the R2R framework, designed for deploying robust RAG systems. R2R offers a semi-opinionated approach to simplify deployment, adaptation, and maintenance of RAG pipelines for production. It aims to enhance ease of use and effectiveness in the industry. The framework provides a quick install guide using pip and offers basic examples for application deployment and interaction. Further, it includes a demo for visual intelligence and provides detailed steps for a full install using Poetry. Key features include rapid deployment, flexible standardization, easy modification, versioning, extensibility, OSS community support, and deployment assistance. Core abstractions focus on Ingestion, Embedding, RAG, and Eval Pipelines, each supported by a logging database for observability.",R2R: Production-ready RAG Systems - Simplifying Deployment and Maintenance,"R2R is a semi-opinionated framework designed to bridge the gap between experimental RAG models and robust, production-ready systems. Offering a straightforward path to deploy, adapt, and maintain RAG pipelines in production, R2R prioritizes simplicity and practicality to set a new industry benchmark. With core abstractions focused on Ingestion, Embedding, RAG, and Evaluation Pipelines, it ensures rapid deployment, flexible standardization, and easy modification while supporting extensibility and versioning for reproducibility and traceability. Built for the OSS community, R2R facilitates quick integration with various VectorDBs, LLMs, and Embeddings Models, making it suitable for startups and enterprises seeking to build and deploy RAG systems end-to-end.","Explore R2R, a semi-opinionated RAG framework that simplifies the deployment and maintenance of production-ready systems. With core abstractions centered around Ingestion, Embedding, RAG, and Evaluation Pipelines, R2R offers rapid deployment, flexible standardization, and easy modification. Built for the OSS community, it supports extensibility and versioning, making it ideal for startups and enterprises looking to build and deploy RAG systems with ease.",Collaborative AI Framework.,"Python





        737





        50


        Built by

          









        158 stars today",https://raw.githubusercontent.com/SciPhi-AI/R2R/main/./docs/pages/getting-started/demo_screenshot.png,,738,2024-02-12T03:24:27Z
2024-02-29,https://github.com/myshell-ai/MeloTTS,https://raw.githubusercontent.com/myshell-ai/MeloTTS/main/README.md,"The text provides information on MeloTTS, a high-quality multi-lingual text-to-speech library by MyShell.ai. It supports various languages with examples provided for each language. The library includes features like support for mixed Chinese and English, as well as fast CPU real-time inference. Usage instructions are provided both for quick use without installation and for local installation. The text also mentions opportunities to join the community through open-source AI grants and contributing to the repository. The library is licensed under the MIT License, allowing both commercial and non-commercial use. Acknowledgements are given to the sources on which the implementation is based.",Enhance Text-to-Speech with MeloTTS Library by MyShell.ai,"MeloTTS is a high-quality multi-lingual text-to-speech library developed by MyShell.ai. It supports various languages such as American English, British English, Indian English, Australian English, Spanish, French, Chinese, Japanese, and Korean. The library also offers features like mixed Chinese and English support and quick CPU real-time inference. Join the community to contribute to open-source AI projects and explore the usage options provided in the documentation.","Discover how MeloTTS, a powerful text-to-speech library by MyShell.ai, supports multiple languages and advanced features like mixed Chinese and English support. Join the community to contribute to open-source AI projects and explore various usage options available.",Language Models,"Python





        633





        67


        Built by

          







        102 stars today",,,633,2024-02-19T16:49:14Z
2024-02-29,https://github.com/WongKinYiu/yolov9,https://raw.githubusercontent.com/WongKinYiu/yolov9/main/README.md,"The text discusses the implementation of YOLOv9, based on the paper ""YOLOv9: Learning What You Want to Learn Using Programmable Gradient Information."" It provides performance metrics for different YOLOv9 models - YOLOv9-S, YOLOv9-M, YOLOv9-C, and YOLOv9-E on the MS COCO dataset. The models are evaluated in terms of Average Precision (AP) and Average Recall (AR) at various Intersection over Union (IoU) thresholds. It includes details on useful links, installation using Docker, evaluation with Python scripts, data preparation for training, single and multiple GPU training procedures, re-parameterization, citations, acknowledgments, and a teaser for YOLOR-Based Multi-Task Learning. The text also contains links to related repositories and code bases.",YOLOv9: Learning What You Want to Learn Using Programmable Gradient Information,"Implementation of paper - YOLOv9: Learning What You Want to Learn Using Programmable Gradient Information. This blogpost provides details on different YOLOv9 models (YOLOv9-S, YOLOv9-M, YOLOv9-C, YOLOv9-E) and their performance metrics based on MS COCO dataset. It includes useful links for custom training, ONNX export, TensorRT inference, C# inference, Hugging Face demo, CoLab demo, ONNXSlim export, YOLOv9 ByteTrack, YOLOv9 DeepSORT, YOLOv9 counting, and AnyLabeling tool. The blog also covers installation instructions, evaluation results, training processes, re-parameterization details, citation, teaser, and acknowledgements.","Learn about the YOLOv9 model, its variants, performance on MS COCO dataset, training processes, evaluation results, and useful links for custom training, export, inference, and deployment. Dive into re-parameterization, citation, acknowledgements, and get insights into YOLOR-Based Multi-Task Learning. Explore this comprehensive guide on implementing YOLOv9 for object detection tasks.",Computer Vision,"Python





        5,642





        678


        Built by

          





        959 stars today",,,5642,2024-02-18T10:09:29Z
2024-02-29,https://github.com/donnemartin/system-design-primer,https://raw.githubusercontent.com/donnemartin/system-design-primer/master/README.md,"The text is about the System Design Primer, a guide to help engineers learn how to design large-scale systems and prepare for system design interviews. It covers various topics such as scalability, load balancing, database management, and more. The guide emphasizes the importance of understanding system design principles and provides resources like Anki flashcards for retention. It also discusses concepts like CAP theorem, consistency patterns, and availability vs consistency trade-offs. The use of CDNs, load balancers, reverse proxies, and microservices are highlighted for scaling and improving system performance. Overall, it aims to help engineers build systems that can handle large loads efficiently.",Designing Large-Scale Systems: Scalability Principles and Patterns,"Learning how to design scalable systems will help you become a better engineer. System design is a broad topic with a vast amount of resources scattered throughout the web on system design principles. This organized collection of resources will help you learn how to build systems at scale. Whether you are preparing for a system design interview or looking to understand the complexities of large-scale systems, this blog post provides insights into scalability, availability, load balancing, and database management. Explore the trade-offs between performance vs scalability, consistency vs availability, and learn about key design patterns like master-slave replication, sharding, and more.","Learn how to design scalable systems with this comprehensive blog post covering key principles and patterns in system design. Explore trade-offs between performance and scalability, consistency and availability, and dive into important concepts like master-slave replication and sharding. Whether you are preparing for a system design interview or seeking to enhance your engineering skills, this resource provides valuable insights into building systems at scale.",System Design Education,"Python





        247,760





        42,526


        Built by

          









        125 stars today",https://raw.githubusercontent.com/donnemartin/system-design-primer/master/images/OfVllex.png; https://raw.githubusercontent.com/donnemartin/system-design-primer/master/images/4edXG0T.png; https://raw.githubusercontent.com/donnemartin/system-design-primer/master/images/jrUBAF7.png; https://raw.githubusercontent.com/donnemartin/system-design-primer/master/images/bWxPtQA.png; https://raw.githubusercontent.com/donnemartin/system-design-primer/master/images/V5q57vU.png; https://raw.githubusercontent.com/donnemartin/system-design-primer/master/images/cdCv5g7.png; https://raw.githubusercontent.com/donnemartin/system-design-primer/master/images/4j99mhe.png; https://raw.githubusercontent.com/donnemartin/system-design-primer/master/images/MzExP06.png; https://raw.githubusercontent.com/donnemartin/system-design-primer/master/images/jj3A5N8.png,https://www.youtube.com/watch?v=ZgdS0EUmn70; https://www.youtube.com/watch?v=-W9F__D3oY4; https://www.youtube.com/watch?v=k-Yaq8AHlFA; https://www.youtube.com/watch?v=kKjm4ehYiMs; https://www.youtube.com/watch?v=kKjm4ehYiMs; https://www.youtube.com/watch?v=kKjm4ehYiMs; https://www.youtube.com/watch?v=qI_g07C_Q5I; https://www.youtube.com/watch?v=kKjm4ehYiMs; https://www.youtube.com/watch?v=1KRYH75wgy4; https://www.youtube.com/watch?v=PE4gwstWhmc; https://www.youtube.com/watch?v=b1e4t2k2KJY; https://www.youtube.com/watch?v=PE4gwstWhmc; https://www.youtube.com/watch?v=5cKTP36HVgI; https://www.youtube.com/watch?v=z8LU0Cj6BOU; https://www.youtube.com/watch?v=w5WVu624fY8,247760,2017-02-26T16:15:28Z
2024-02-29,https://github.com/KillianLucas/open-interpreter,https://raw.githubusercontent.com/KillianLucas/open-interpreter/main/README.md,"The text describes the features of the Open Interpreter tool, which allows language models to run code locally. It highlights the ability to interact with the computer through natural language commands, such as creating and editing various files, controlling a browser, and analyzing datasets. The tool also provides a comparison to OpenAI's Code Interpreter and offers various commands and capabilities, including setting up local and online modes, customizing settings, starting a chat, and running a FastAPI server. The text emphasizes caution when running code and provides guidance on safety practices. Additionally, it encourages contributions from the community and outlines the project's roadmap.",Open Interpreter: Run Code with Language Models Locally,"Open Interpreter is a tool that lets language models run code locally, enabling users to interact with their computer's capabilities in a natural-language manner. With features like the Computer API and the `--os` flag, Open Interpreter introduces a new way to work with various tasks including creating and editing media, browsing, analyzing data, and more. Unlike hosted solutions, Open Interpreter runs in your local environment, providing full internet access and flexibility to use any package or library without limitations. The blogpost explains how Open Interpreter works, its interactive features, comparison to other tools, setup guides, safety measures, and the option to control it via HTTP REST endpoints.","Discover Open Interpreter, a local tool that enables language models to run code on your computer, providing full internet access and flexibility to execute tasks effortlessly. Learn about its features like the Computer API and interactive chat, compare it to other tools like Code Interpreter, understand its setup for different environments, and explore safety precautions to maintain control over code execution. See how Open Interpreter can enhance your workflow by harnessing the power of language models in a local development environment.",AI Coding Assistant,"Python





        41,213





        3,594


        Built by

          









        164 stars today",,,41213,2023-07-14T07:10:44Z
2024-02-29,https://github.com/binary-husky/gpt_academic,https://raw.githubusercontent.com/binary-husky/gpt_academic/master/README.md,"The text provides information about the latest version updates of the GPT Academic project. It introduces new features such as Mermaid for drawing diagrams, real-time voice input, support for various language models like ChatGLM and MOSS, and the ability to translate PDF and Arxiv papers. The project also includes a Void Terminal for executing functions through natural language input and supports custom shortcuts and function plugins. The development history and version updates are outlined, and users are encouraged to join the developer community for further learning and support.","GPT Academic Updates: Mermaid Charts, ChatGLM3 Support, and More","GPT Academic introduces new features in version 3.70, including support for Mermaid charts for brain mapping, ChatGLM3, and other Chinese models. The latest update also enhances AutoGen plugin and introduces a Void Terminal feature where you can interact with the system in natural language. Learn how to customize new convenient buttons with academic shortcuts and develop your own function plugins easily. The development history of GPT Academic showcases continuous improvements in UI design, integration of powerful functions, and support for various AI models.","Discover the latest GPT Academic updates with Mermaid charts, ChatGLM3 support, and a Void Terminal feature. Learn how to customize academic shortcuts and develop function plugins easily. Explore the evolution of GPT Academic with continuous enhancements and support for various AI models.",Language Models,"Python





        52,200





        6,622


        Built by

          









        66 stars today",,,52201,2023-03-20T09:05:13Z
2024-02-29,https://github.com/ronibandini/reggaetonBeGone,https://raw.githubusercontent.com/ronibandini/reggaetonBeGone/main/README.md,"The text describes a project called ""Reggaeton Be Gone"" that uses Machine Learning to detect reggaeton music and disable Bluetooth speakers. The project involves Raspberry Pi 3, DFRobot Oled 128x32 screen, push button, BT Audio Receiver 5.0, and jumper cables. The Machine Learning model is trained using the Edge Impulse platform. The full instructions for the project are available on Hackster.io. The connections for the components are detailed, and the project uses a specific Oled screen font. The creator of the project is Roni Bandini, who can be contacted on Twitter. Full details can be found at the provided links.",How to Detect Reggaeton with Machine Learning and Disable Bluetooth Speakers Tutorial,"Learn how to detect reggaeton music using Machine Learning and disable Bluetooth speakers with a Raspberry Pi 3 and DFRobot components. The model is trained using the Edge Impulse platform, and complete instructions can be found on Hackster.io. Connect the DFRobot OLED screen and push button to the Raspberry Pi GPIO pins for this fun project.",Discover how to identify reggaeton music genre using Machine Learning and block Bluetooth speakers using a Raspberry Pi and DFRobot components. Get step-by-step instructions on setting up the project. Dive into the world of edge computing and music detection in this exciting tutorial.,Machine Learning Music_detection,"Python





        331





        34


        Built by

          





        64 stars today",,,331,2024-02-20T21:10:05Z
2024-02-29,https://github.com/joaomdmoura/crewAI-examples,https://raw.githubusercontent.com/joaomdmoura/crewAI-examples/main/README.md,"The text provides examples for utilizing crewAI to enhance the collaboration of role-playing AI agents. It showcases different applications of the crewAI framework for automating various processes. The examples are categorized into Basic and Advanced Examples, including tasks such as creating job postings, trip planning, Instagram post creation, markdown validation, game generation, and utilizing Azure OpenAI API. There is also mention of starting your own example using the provided starter template. Advanced examples cover areas like stock analysis, landing page generation, and integrating crewAI with LangGraph. The text serves as a resource for users interested in leveraging crewAI for AI agent collaboration.",Examples of Using crewAI Framework for AI Automation | joaomdmoura,"crewAI is a tool created to enhance the cooperation among AI role-playing agents, providing a framework to automate various processes. The blog by [@joaomdmoura](https://x.com/joaomdmoura) showcases a range of examples demonstrating the versatility of crewAI. From fundamental tasks like job posting and trip planning to advanced projects such as stock analysis and landing page generation, the blog illustrates diverse applications of crewAI in AI automation.",Explore a collection of examples showcasing the application of crewAI framework for AI automation. Learn how to automate tasks with crewAI - from basic ones like job posting and trip planning to advanced projects including stock analysis and landing page generation. Read more at the blog by [@joaomdmoura](https://x.com/joaomdmoura).,Collaborative AI Framework.,"Python





        857





        236


        Built by

          









        19 stars today",,,857,2023-12-19T11:46:48Z
2024-02-29,https://github.com/MrMimic/data-scientist-roadmap,https://raw.githubusercontent.com/MrMimic/data-scientist-roadmap/master/README.md,"The text discusses a data science skills roadmap created by Swami Chandrasekaran, shared on his blog. It highlights the increasing popularity of data science jobs and the availability of tutorials to guide individuals interested in learning about this field. The roadmap emphasizes the use of Wikipedia and LLMs for resources and encourages collaboration through forking the repository and making pull requests. The guidelines include commenting on code, maintaining a specific file structure, and sharing helpful links in README files. Overall, the text presents a structured approach for beginners to start their journey in data science.",Ultimate Data Scientist Roadmap for Aspiring Data Science Professionals,"I just found this data science skills roadmap, drawn by Swami Chandrasekaran on his cool blog. Jobs linked to data science are becoming more and more popular. A bunch of tutorials could easily complete this roadmap, helping whoever wants to start learning stuff about data science. For the moment, a lot is got on Wikipedia or generated by LLMs (except for codes, always handmade). Any help's thus welcome!","Discover the ultimate data scientist roadmap created by Swami Chandrasekaran to guide aspiring data science professionals. Explore the growing popularity of data science jobs and the resources available to start learning about data science. Join the community, contribute, and enhance your skills in this exciting field.",Data Science Learning,"Python





        6,704





        1,859


        Built by

          









        29 stars today",http://nirvacana.com/thoughts/wp-content/uploads/2013/07/RoadToDataScientist1.png,,6704,2017-06-05T06:30:08Z
2024-02-29,https://github.com/state-spaces/mamba,https://raw.githubusercontent.com/state-spaces/mamba/main/README.md,"The text discusses Mamba, a linear-time sequence modeling architecture based on selective state spaces. This model is designed for dense data like language modeling and is more efficient than previous subquadratic models. It utilizes a structured state space model approach and has efficient hardware-aware design similar to FlashAttention. Installation requirements include specific PyTorch versions, CUDA, and NVIDIA GPU. The interface exposes features like Selective SSM layer and Mamba Block. Pretrained models are available, trained on the Pile dataset. Evaluations and benchmarks are provided to analyze model performance. Troubleshooting tips and a citation are also included.",Mamba: Linear-Time Sequence Modeling with Selective State Spaces - Overview and Installation Guide,"Mamba is a novel state space model architecture designed for information-dense data like language modeling. It offers efficient hardware-aware design, with performance surpassing traditional subquadratic models. The blog post covers the model's structure, installation process, usage examples, and pre-trained models available. It also provides guidance on evaluations, troubleshooting tips, and a citation reference.","Learn about Mamba, a state space model architecture focused on language modeling efficiency. This blog post includes installation instructions, usage examples, pre-trained model details, evaluations, troubleshooting tips, and a citation guide for referencing the work.",Language Models,"Python





        7,037





        553


        Built by

          









        72 stars today",,,7038,2023-12-01T01:17:39Z
2024-02-29,https://github.com/Azure/PyRIT,https://raw.githubusercontent.com/Azure/PyRIT/main/README.md,"The Python Risk Identification Tool (PyRIT) is an automation framework created to aid security professionals and ML engineers in assessing the robustness of their AI models against various types of harmful content such as bias, harassment, and fabrication. PyRIT automates tasks related to AI red teaming, enabling operators to focus on complex tasks while identifying security and privacy risks like malware generation and identity theft. Researchers can use PyRIT to establish a performance baseline for their models, track improvements, and enhance mitigations against different harms. Microsoft is utilizing PyRIT for product iterations and protection against prompt injection attacks. More information on PyRIT can be found on Microsoft Learn and in the project's documentation.",Python Risk Identification Tool for generative AI (PyRIT) - Empowering Security Professionals and ML Engineers,"The Python Risk Identification Tool for generative AI (PyRIT) is a powerful automation framework developed to enhance the assessment of model robustness. PyRIT assists in identifying and combating various security harms such as fabrication, misuse, and prohibited content. By automating AI Red Teaming tasks, PyRIT enables researchers to focus on complex assignments and detect security and privacy vulnerabilities. Researchers can utilize PyRIT to establish a performance baseline and enhance mitigation strategies for different harm categories.","Learn how PyRIT, a Python Risk Identification Tool for generative AI, empowers security professionals and ML engineers to assess model robustness. Automate AI Red Teaming tasks, focus on complex assignments, and detect security and privacy vulnerabilities effectively with PyRIT.",AI Red Teaming,"Python





        945





        180


        Built by

          









        189 stars today",https://github.com/Azure/PyRIT/blob/main/assets/pyrit_architecture.png,,945,2023-12-12T15:46:28Z
2024-02-29,https://github.com/prowler-cloud/prowler,https://raw.githubusercontent.com/prowler-cloud/prowler/master/README.md,"The text provides information about Prowler, an Open Source security tool for assessing and monitoring security practices on AWS, GCP, Azure, and Kubernetes. It covers multiple compliance frameworks and categories, offering detailed checks for each provider. The tool can be installed via Pip package, containers, or Github. It requires proper authentication and permissions for AWS, Azure, and Google Cloud Platform. Prowler generates reports in various formats and allows users to customize checks configurations. Detailed usage instructions for executing specific checks/services and modifying configurations are provided. Prowler is licensed under Apache License 2.0.",Enhance Cloud Security with Prowler's Dynamic Assessments,"""Prowler SaaS and Prowler Open Source are as dynamic and adaptable as the environment theyâ€™re meant to protect. Trusted by the leaders in security. Learn more at prowler.com. Prowler is an Open Source security tool to perform AWS, GCP and Azure security best practices assessments, audits, incident response, continuous monitoring, hardening and forensics readiness. It contains hundreds of controls covering various compliance frameworks and categories from AWS, GCP, Azure, and Kubernetes. The full documentation can now be found at https://docs.prowler.com/projects/prowler-open-source/en/latest/.""","Learn how Prowler, an Open Source security tool, can enhance the security of your cloud infrastructure with dynamic assessments, best practices audits, incident response, and more. Discover hundreds of controls covering various compliance frameworks and categories. Find out more at prowler.com.",Cybersecurity Tool,"Python





        9,219





        1,340


        Built by

          









        15 stars today",,,9219,2016-08-24T15:12:24Z
2024-02-29,https://github.com/mistralai/client-python,https://raw.githubusercontent.com/mistralai/client-python/main/README.md,"The Mistral Python Client is developed based on the cohere-python project. You can easily interact with the Mistral AI API by installing the client using pip. The client relies on `poetry` for managing dependencies and setting up a virtual environment. To run the examples provided in the `examples/` directory, you can use `poetry run` or enter the virtual environment with `poetry shell`. To use the client, you need to obtain a Mistral API key, set it as an environment variable, and then you can run the examples like `python chat_no_streaming.py`. The integration provides an easy way to leverage the Mistral AI capabilities through Python scripting.",How to Use the Mistral Python Client for Mistral AI API,"Learn how to interact with Mistral AI API using the Mistral Python client, inspired by cohere-python. Install the client through pip or from source using poetry. Set up your API key and run examples from the provided directory using poetry run or poetry shell.","Discover how to leverage the Mistral Python client to access Mistral AI API with ease. Follow step-by-step instructions to install the client, set up your API key, and run examples seamlessly. Enhance your AI projects today!",AI Python Client,"Python





        322





        45


        Built by

          









        14 stars today",,,322,2023-12-07T10:09:51Z
2024-02-29,https://github.com/wagtail/wagtail,https://raw.githubusercontent.com/wagtail/wagtail/main/README.md,"Wagtail is an open source content management system built on Django. It offers precise control for designers and developers, with features like a fast interface, control over design, scalability, content API, powerful search, and multi-site readiness. It runs on Python 3 and supports multiple platforms. Organizations like NASA, Google, and more use Wagtail. The full documentation for Wagtail is available at docs.wagtail.org. There is active community support on Stack Overflow and Slack, and commercial support is provided by Torchbox. Security is taken seriously, and Wagtail follows a strict release schedule with regular updates. The project is licensed under BSD.",Introducing Wagtail: A Powerful open-source CMS built on Django,"Wagtail is an open source content management system built on Django, with a strong community and commercial support. It's focused on user experience, and offers precise control for designers and developers. Features include fast and attractive interface, complete control over front-end design, scalability, powerful search, and multi-site readiness. Wagtail is trusted by organizations like NASA, Google, and more. Explore more at wagtail.org.","Discover Wagtail, a user-friendly open-source CMS built on Django with features like fast interface, powerful search, and multi-site readiness. Trusted by organizations like NASA and Google. Learn more at wagtail.org.",Software Development,"Python





        16,849





        3,587


        Built by

          









        15 stars today",https://cdn.jsdelivr.net/gh/wagtail/wagtail@main/.github/wagtail-screenshot-with-browser.png; https://raw.githubusercontent.com/wagtail/wagtail/main/.github/install-animation.gif; https://raw.githubusercontent.com/wagtail/wagtail/main/.github/join-slack-community.png; https://cdn.jsdelivr.net/gh/wagtail/wagtail@main/.github/assistivlabs-logo.png,,16849,2014-02-03T12:41:59Z
2024-02-29,https://github.com/gpt-engineer-org/gpt-engineer,https://raw.githubusercontent.com/gpt-engineer-org/gpt-engineer/main/README.md,"GPT-Engineer is an AI-powered tool that allows users to specify software requirements in natural language and then generates and executes the corresponding code. Users can also ask the AI to make improvements to the code. The tool supports Python versions 3.10 to 3.12 and offers various installation options. It requires an API key for operation and provides different ways to run the tool, including using Docker. The project aims to maintain coding tools for building AI agents and encourages collaboration within the open-source community. Users interested in contributing can refer to the roadmap and join the Discord community for guidance on how to get involved.",Automating Software Development with GPT-Engineer: A Comprehensive Guide,"GPT-engineer is a powerful tool that allows you to specify software in natural language and witness an AI write and execute the code for you. With GPT-Engineer, you can easily ask the AI to implement improvements, making your development process more efficient and productive. Learn how to get started by installing GPT-engineer and setting up your API key. Explore various ways to run GPT-Engineer, create new code, and improve existing projects. Join the gpt-engineer community to contribute and be a part of the open-source mission.","Discover the power of GPT-Engineer in automating software development. Learn how to specify software in natural language, let AI write and execute code, and implement improvements effortlessly. Join the open-source community, get started with installation, and leverage the tool for enhanced coding experiences.",AI Coding Assistant,"Python





        49,317





        6,392


        Built by

          









        30 stars today",,,49317,2023-04-29T12:52:15Z
2024-02-29,https://github.com/Clouditera/SecGPT,https://raw.githubusercontent.com/Clouditera/SecGPT/main/README.md,"The text introduces SecGPT, a large model aimed at incorporating artificial intelligence technology into the field of cybersecurity to enhance network defense efficiency and effectiveness. SecGPT can be used for various cybersecurity tasks such as vulnerability analysis, trace analysis, traffic analysis, threat assessment, command interpretation, and cybersecurity knowledge Q&A. It features self-training code for memory savings, high-quality cybersecurity training sets, DPO reinforcement learning, and unrestricted GPT modeling for in-depth analysis. The model is open-source, providing training codes and datasets for users to train their own large-scale cybersecurity models. Users are advised to carefully evaluate and use the generated content when utilizing the model.",Exploring SecGPT: Advancing Network Security with Large Models,"SecGPT aims to bring AI technology into the field of network security to enhance defense efficiency and effectiveness. It serves as a foundational security model for various network security tasks, such as vulnerability analysis, forensics, traffic analysis, attack assessment, command interpretation, and cybersecurity knowledge Q&A. Unlike other open-source models, SecGPT offers unique features like self-written training code for memory savings, high-quality security training datasets, DPO reinforcement learning, and ethical unrestricted analysis capabilities.","Discover how SecGPT leverages AI technology in network security, contributing to better cybersecurity defenses. Learn about its applications in vulnerability analysis, forensics, traffic analysis, and more. Uncover the unique features of SecGPT like self-written training code, high-quality datasets, and DPO reinforcement learning.",Cybersecurity Tool,"Python





        807





        111


        Built by

          







        23 stars today",https://raw.githubusercontent.com/Clouditera/SecGPT/main/images/640.png; https://raw.githubusercontent.com/Clouditera/SecGPT/main/images/641.png; https://raw.githubusercontent.com/Clouditera/SecGPT/main/images/6402.png; https://raw.githubusercontent.com/Clouditera/SecGPT/main/images/640%203.png; https://raw.githubusercontent.com/Clouditera/SecGPT/main/images/640%204.png; https://raw.githubusercontent.com/Clouditera/SecGPT/main/images/640%205.png; https://raw.githubusercontent.com/Clouditera/SecGPT/main/images/6406.png; https://raw.githubusercontent.com/Clouditera/SecGPT/main/images/640%207.png; https://raw.githubusercontent.com/Clouditera/SecGPT/main/images/640%208.png; https://raw.githubusercontent.com/Clouditera/SecGPT/main/images/640%209.png; https://raw.githubusercontent.com/Clouditera/SecGPT/main/images/61.png; https://raw.githubusercontent.com/Clouditera/SecGPT/main/images/62.png; https://raw.githubusercontent.com/Clouditera/SecGPT/main/images/63.png; https://raw.githubusercontent.com/Clouditera/SecGPT/main/images/64.png; https://raw.githubusercontent.com/Clouditera/SecGPT/main/images/image-2.png; https://raw.githubusercontent.com/Clouditera/SecGPT/main/images/image-3.png; https://raw.githubusercontent.com/Clouditera/SecGPT/main/images/image-4.png,,807,2023-11-20T05:41:24Z
2024-02-29,https://github.com/rany2/edge-tts,https://raw.githubusercontent.com/rany2/edge-tts/master/README.md,"`edge-tts` is a Python module that enables the use of Microsoft Edge's online text-to-speech service. It provides commands like `edge-tts` and `edge-playback` for Python developers to integrate this service into their code. The installation can be done via pip or pipx. Basic usage involves generating speech using specified text and output options. One can also change the voice, adjust speech rate, volume, and pitch. The `edge-playback` command facilitates immediate playback of generated speech. Custom SSML support has been discontinued. The module can be directly used in Python scripts for various applications as demonstrated in the provided examples.",Using Microsoft Edge Online Text-to-Speech with edge-tts Python Module,"`edge-tts` is a Python module that enables utilizing Microsoft Edge's online text-to-speech service directly in Python code or via the `edge-tts` and `edge-playback` commands. To install, use `pip` or `pipx` for command line usage. Explore various options like changing voices, adjusting rate/volume/pitch, and utilizing the Python module directly. Learn more about the commands, voice customization, and usage examples in the blogpost.","Learn how to integrate Microsoft Edge's online text-to-speech service into your Python projects with the `edge-tts` module. Install and use the commands, customize voices, adjust speech characteristics, and discover Python module usage examples in this comprehensive guide.",AI Python Client,"Python





        2,905





        313


        Built by

          









        20 stars today",,,2905,2021-05-10T18:55:14Z
2024-02-29,https://github.com/Fanghua-Yu/SUPIR,https://raw.githubusercontent.com/Fanghua-Yu/SUPIR/master/README.md,"The text discusses a project called SUPIR, focusing on model scaling for photo-realistic image restoration. The project involves a team from various institutions and labs, working on enhancing image quality in real-world settings. It emphasizes high RAM and VRAM costs, requiring an online demo. The process involves cloning the repository, installing dependencies, and downloading checkpoints. Different models are provided for training settings. The text explains usage instructions for SUPIR, including quick inference and Python script examples. It also mentions an upcoming online demo. Additionally, it provides contact information and a declaration for non-commercial use of the software.",Scaling Up to Excellence: Model Scaling for Photo-Realistic Image Restoration - CVPR2024,"The blog post discusses the practice of model scaling for photo-realistic image restoration in the wild, focusing on the SUPIR project. It covers the dependencies and installation steps, including cloning the repository, installing dependent packages, and downloading checkpoints. The post also provides information on dependent models, custom path editing for checkpoints, quick inference methods, usage of SUPIR, and Python scripts for different scenarios. Additionally, it mentions online demo availability and includes BibTeX citation for reference.","Explore the practice of model scaling for photo-realistic image restoration in the wild with the SUPIR project. Learn about installation steps, dependent models, quick inference methods, Python scripts, and more. Check out the BibTeX citation and ways to contact the developers for non-commercial use. Stay tuned for the online demo release!",Computer Vision,"Python





        1,830





        129


        Built by

          





        71 stars today",https://github.com/Fanghua-Yu/SUPIR/blob/master/assets/teaser.png,,1830,2023-12-21T11:23:35Z
2024-02-29,https://github.com/LiheYoung/Depth-Anything,https://raw.githubusercontent.com/LiheYoung/Depth-Anything/main/README.md,"The text provides an overview of ""Depth Anything: Unleashing the Power of Large-Scale Unlabeled Data."" The project aims to enhance robust monocular depth estimation by training on a mix of 1.5M labeled images and over 62M unlabeled images. Noteworthy features include relative depth estimation, metric depth estimation with strong capabilities, a better depth-conditioned ControlNet, and downstream high-level scene understanding. The text showcases the project's performance compared to the earlier MiDaS model, highlighting key metrics. Pre-trained models are offered in different scales for relative depth estimation. The text also mentions details on installation, running the project, and resources for further community support. It concludes with acknowledgments and a citation request.",Depth Anything: Unleashing the Power of Large-Scale Unlabeled Data,"This work presents Depth Anything, a highly practical solution for robust monocular depth estimation by training on a combination of 1.5M labeled images and 62M+ unlabeled images. It emphasizes on features like Relative depth estimation, Metric depth estimation, Better depth-conditioned ControlNet, and Downstream high-level scene understanding. The blogpost also includes a comparison of Depth Anything performance with the MiDaS model, information on pre-trained models, installation instructions, running details, and community support acknowledgements.","Discover Depth Anything, a powerful solution for monocular depth estimation using a mix of labeled and unlabeled data. Explore its features, performance comparisons, pre-trained models, installation instructions, and community support. Unleash the potential of large-scale unlabeled data with Depth Anything.",Self-Supervised Learning Architecture.,"Python





        4,807





        318


        Built by

          






        34 stars today",https://raw.githubusercontent.com/LiheYoung/Depth-Anything/main/assets/teaser.png,,4807,2024-01-22T01:09:25Z
2024-02-29,https://github.com/Eladlev/AutoPrompt,https://raw.githubusercontent.com/Eladlev/AutoPrompt/main/README.md,"The text provides an overview of the AutoPrompt framework, a tool designed to enhance and refine prompts for real-world applications. AutoPrompt employs a calibration process to generate high-quality prompts tailored to user intentions, addressing issues such as prompt sensitivity and ambiguity. The system is applicable to tasks like moderation and content generation, with the ability to optimize prompts efficiently. The framework supports various open-source tools and LLM providers for flexible integration. Users can follow the setup instructions to configure their system, set budget limits, and run prompt optimization pipelines. The project is open for contributions and is licensed under Apache 2.0. For further details, the full text and references are provided in the document.",Enhance Prompt Engineering with AutoPrompt: A Framework for Optimizing Prompts,"Auto Prompt is a prompt optimization framework designed to enhance and perfect prompts for real-world use cases. The framework generates high-quality prompts tailored to user intentions through a sophisticated calibration process. Addressing prompt sensitivity and ambiguity issues, Auto Prompt empowers users to create robust prompts with minimal effort. The system implements an Intent-based Prompt Calibration method, refining prompts based on user-provided inputs and task descriptions. By combining synthetic data generation and prompt optimization, Auto Prompt outperforms traditional methods while ensuring efficient performance enhancements.","Learn how AutoPrompt, a prompt optimization framework, refines and perfects prompts for real-world scenarios. Empower users to create robust prompts with minimal effort and address prompt sensitivity and ambiguity. Discover how AutoPrompt's Intent-based Prompt Calibration method improves prompt performance and generates high-quality prompts tailored to user intentions.",Collaborative AI Framework.,"Python





        897





        62


        Built by

          









        176 stars today",https://raw.githubusercontent.com/Eladlev/AutoPrompt/main/./docs/AutoPrompt_Diagram.png; https://raw.githubusercontent.com/Eladlev/AutoPrompt/main/./docs/autoprompt_recording.gif,,897,2023-12-02T18:45:14Z
2024-02-29,https://github.com/Avaiga/taipy,https://raw.githubusercontent.com/Avaiga/taipy/master/README.md,"Taipy is an open-source Python library for application development that integrates data and AI algorithms into production-ready web apps. It features what-if analyses, smart pipeline execution, built-in scheduling, and deployment tools. Designed for data scientists and machine learning engineers, Taipy enables building full-stack apps without the need for learning additional languages or frameworks. It includes a Python-based UI framework, pre-built components for data pipelines, scenario and data management features, version management, and pipeline orchestration tools. The tool allows users to easily create scenarios and manage data, such as filtering movie data based on selected genres. Taipy Cloud offers easy deployment options, and there are opportunities for contributing to the project.",Developing Production-Ready Web Apps with Taipy: Data and AI Algorithms in Action,"Taipy is an open-source Python library designed for easy, end-to-end application development, emphasizing what-if analyses, smart pipeline execution, built-in scheduling, and deployment tools. It enables data scientists and ML engineers to build full-stack apps without needing to learn new languages or frameworks, focusing on Data and AI algorithms. With features like Python-Based UI Framework, Pre-Built Components for Data Pipelines, Scenario and Data Management, and Version Management, Taipy simplifies the process of building production-ready web applications. Discover how to filter movie data based on genre using Taipy, create full-stack applications, and deploy your Taipy applications effortlessly with Taipy Cloud.","Learn how to leverage Taipy, an open-source Python library, to develop production-ready web applications with data and AI algorithms. Discover features like Python-Based UI Framework, Pre-Built Components for Data Pipelines, Scenario and Data Management, and Version Management. Explore a practical demo on filtering movie data by genre using Taipy and deployment options with Taipy Cloud.",Collaborative AI Framework.,"Python





        6,515





        410


        Built by

          









        361 stars today",https://github.com/Avaiga/taipy/raw/develop/readme_img/readme_demo_studio.gif; https://github.com/Avaiga/taipy/raw/develop/readme_img/readme_cloud_demo.gif,,6515,2022-02-18T15:55:45Z
2024-02-29,https://github.com/microsoft/unilm,https://raw.githubusercontent.com/microsoft/unilm/master/README.md,"The text provides information about large-scale self-supervised pre-training across different tasks, languages, and modalities. It includes details on hiring opportunities, foundation architectures like TorchScale, and various foundation models such as Foundation Transformers and Length-Extrapolatable Transformers. It also mentions model architectures like BitNet, RetNet, and LongNet, as well as applications in language understanding, generation, image analysis, speech, and multimodal tasks. Additionally, it highlights recent releases, model advancements, and links to relevant repositories and resources. For further details, you can refer to the full text or contact the provided email address for inquiries.",Revolutionizing Foundation Models and Architectures: A Deep Dive into TorchScale and New Innovations,"Discover the latest advancements in foundation models and architectures with TorchScale, a library focusing on modeling generality, stability, and efficiency. Explore cutting-edge technologies like DeepNet, Foundation Transformers, Length-Extrapolatable Transformers, and X-MoE. Uncover the groundbreaking BitNet, RetNet, and LongNet in the realm of model architecture revolution. Delve into the evolution of Multimodal LLM with models like Kosmos and MetaLM, enabling general-purpose modeling across various modalities.","Learn about the latest innovations in foundation models and architectures with TorchScale and explore technologies like DeepNet, Foundation Transformers, and X-MoE. Discover advancements such as BitNet, RetNet, and LongNet, and delve into the domain of Multimodal LLM with models like Kosmos and MetaLM.",Self-Supervised Learning Architecture.,"Python





        17,372





        2,261


        Built by

          









        95 stars today",,,17372,2019-07-23T04:15:28Z
2024-02-29,https://github.com/pytorch/examples,https://raw.githubusercontent.com/pytorch/examples/main/README.md,"The text provides information about the PyTorch Examples repository, showcasing various examples using PyTorch. The repository aims to offer curated, high-quality examples with minimal dependencies for diverse use cases. It includes models for image classification, natural language processing, generative models, reinforcement learning, neural style transfer, and more. Aside from the core examples within the repo, it also suggests external repositories for additional models. The text also mentions related resources like tutorials, model hub, production recipes, and support channels. It encourages contributions and provides guidelines for anyone willing to contribute examples or fix issues. The examples cover a wide range of applications and learning scenarios.",Explore PyTorch Examples for High-Quality Deep Learning Models,"`pytorch/examples` is a repository showcasing examples of using PyTorch with curated, high-quality models and diverse applications such as image classification, language modeling, and reinforcement learning. Find tutorials, ready-to-use models, and contributions guidelines for your own examples. Discover advanced techniques like generative adversarial networks and variational auto-encoders implemented in PyTorch.","Discover a curated repository of high-quality PyTorch examples showcasing deep learning models for various tasks like image classification, language modeling, and reinforcement learning. Explore tutorials, pre-trained models, and guidelines for contributing your own examples to the PyTorch community.",Deep Learning Platform,"Python





        21,466





        9,398


        Built by

          









        4 stars today",,,21466,2016-08-24T03:12:48Z
2024-02-29,https://github.com/qnguyen3/chat-with-mlx,https://raw.githubusercontent.com/qnguyen3/chat-with-mlx/main/README.md,"The text describes a repository featuring a Retrieval-augmented Generation (RAG) chat interface that supports various open-source models. It allows users to chat using different types of data like doc, pdf, txt, and YouTube videos. The installation can be done via Pip or manually through Git and Conda. Users can add their own models by configuring a .yaml file. The MLX framework mentioned supports machine learning research on Apple silicon, providing familiar APIs, lazy computation, dynamic graph construction, and more. The text acknowledges the Apple Machine Learning Research team, LangChain, ChromaDB, and other teams for their contributions. The repository's star history chart is also provided.",Native RAG on MacOS and Apple Silicon with MLX ðŸ§‘â€ðŸ’» | Chat with MLX,"This repository showcases a Retrieval-augmented Generation (RAG) chat interface with support for multiple open-source models. Chat with your Data: doc(x), pdf, txt and YouTube video via URL. Multilingual support. Easy integration with HuggingFace and MLX Compatible Open-Source Models. Installation and usage instructions for both Pip and Conda. Add your own models using provided solutions. Known issues and tips for using the MLX chat app. Reasoning behind MLX framework and acknowledgements.","Discover how to use Retrieval-augmented Generation (RAG) chat interface on MacOS and Apple Silicon using MLX. Chat with MLX supports various open-source models and allows easy integration with HuggingFace models. Learn how to install and use the chat app, add your own models, and understand the benefits of MLX framework. Find tips for resolving known issues and explore acknowledgements in the MLX community.",Natural Language Processing,"Python





        433





        37


        Built by

          







        180 stars today",https://raw.githubusercontent.com/qnguyen3/chat-with-mlx/main/assets/chat-w-mlx.gif,,433,2024-02-16T13:59:06Z
2024-02-29,https://github.com/NUS-HPC-AI-Lab/OpenDiT,https://raw.githubusercontent.com/NUS-HPC-AI-Lab/OpenDiT/master/README.md,"OpenDiT is an open-source project focusing on enhancing the efficiency of training and inference for Diffusion Transformers (DiT) applications, such as text-to-video and text-to-image generation. It offers performance boosts through techniques like kernel optimization, hybrid parallelism, and FastSeq for large sequences. OpenDiT provides an easy-to-use platform with a complete pipeline for various tasks. The installation process involves setting up prerequisites, installing ColossalAI, and OpenDiT, along with optional speed-up libraries. The usage guide covers training and inference for both image and video tasks, with detailed commands and options. FastSeq, a novel sequence parallelism method, is introduced to optimize training for DiT models. Additionally, reproducibility results and acknowledgements are provided in the documentation. The codebase is available on GitHub for contributions, and citation information is provided for referencing the project.",OpenDiT: A High-Performance System for DiT Training and Inference,"OpenDiT is an open-source project designed to enhance the efficiency of training and inference for Diffusion Transformer applications, such as text-to-video and text-to-image generation. It offers performance boosts through techniques like speed optimizations, hybrid parallelism methods, and ease of use. The system also provides a complete pipeline for text-to-image and text-to-video generation, making it easy for researchers and engineers to adapt for real-world applications. Stay tuned for more features and updates!","Explore OpenDiT, an open-source project tailored for efficient training and inference of Diffusion Transformers. Discover techniques like speed optimizations and hybrid parallelism methods to enhance performance. Easily create text-to-image and text-to-video applications with OpenDiT's complete pipeline. Join us on GitHub and get ready for upcoming features!",Collaborative AI Framework.,"Python





        514





        22


        Built by

          









        154 stars today",https://raw.githubusercontent.com/NUS-HPC-AI-Lab/OpenDiT/master/./figure/fastseq_overview.png; https://raw.githubusercontent.com/NUS-HPC-AI-Lab/OpenDiT/master/./figure/fastseq_exp.png; https://raw.githubusercontent.com/NUS-HPC-AI-Lab/OpenDiT/master/./figure/dit_results.png; https://raw.githubusercontent.com/NUS-HPC-AI-Lab/OpenDiT/master/./figure/dit_loss.png,,514,2024-02-17T08:40:35Z
2024-02-29,https://github.com/evo-design/evo,https://raw.githubusercontent.com/evo-design/evo/main/README.md,"Evo is a biological foundation model designed for long-context modeling and design, utilizing the StripedHyena architecture for sequence modeling at a single-nucleotide, byte-level resolution. It boasts 7 billion parameters and is trained on the OpenGenome dataset. To use Evo, one can install it via `pip` or GitHub source, after ensuring the correct PyTorch version. Various example scripts demonstrate Evo's capabilities, including generating sequences, folding proteins, and scoring log-likelihoods. Evo is integrated with HuggingFace and will soon be accessible through an API by TogetherAI. Please refer to the provided citation when mentioning Evo.",Sequence Modeling and Design with Evo: A Molecular to Genome Scale Approach,"Evo is a revolutionary biological foundation model with 7 billion parameters trained on the OpenGenome dataset. It enables long-context modeling and design using the StripedHyena architecture, offering near-linear scaling of compute and memory relative to context length. The model comes with checkpoints like 'evo-1-8k-base' and 'evo-1-131k-base' for different tasks, providing users with flexibility and efficiency. Evo supports various operations from sequence generation to scoring log-likelihoods, making it a versatile tool for molecular and genome-scale applications. Explore Evo's capabilities through HuggingFace integration and stay tuned for its upcoming availability via the TogetherAI API.","Discover Evo, a cutting-edge biological foundation model designed for sequence modeling and design from molecular to genome scale. Learn about the model's 7 billion parameters, training on OpenGenome data, and use of the StripedHyena architecture. Explore checkpoints like 'evo-1-8k-base' and 'evo-1-131k-base', along with examples of using Evo for tasks such as sequence generation and log-likelihood scoring. Integrated with HuggingFace and soon available through the TogetherAI API, Evo offers a wide range of functionalities for biological research and application.",Language Models,"Python





        332





        22


        Built by

          








        123 stars today",https://raw.githubusercontent.com/evo-design/evo/main/evo.jpg,,332,2024-02-17T19:11:33Z
2024-02-29,https://github.com/pygments/pygments,https://raw.githubusercontent.com/bruin-data/ingestr/main/README.md,"Ingestr is a command-line application that simplifies data ingestion from any source to any destination without writing code. It offers features such as copying data, incremental loading options (append, merge, delete+insert), and single-command installation. Users can easily transfer data from sources like Postgres, BigQuery, Snowflake, Redshift, Databricks, and more to various destinations. The tool eliminates backend management complexity and coding requirements, allowing users to run commands to move data efficiently. To get started, users can install Ingestr via pip and follow a quickstart guide to ingest data from a source to a destination effortlessly. Furthermore, the Ingestr project acknowledges the contributions of the SQLAlchemy and dlt teams for their support in connecting to different data sources and destinations. More details are available in the documentation and the community Slack channel.",Ingest Data Easily with Ingestr: Code-Free Data Transfer Tool,"Ingestr is a command-line application that simplifies data ingestion from any source to any destination without the need for writing code. With features like incremental loading and single-command installation, Ingestr streamlines the data transfer process. Simply install Ingestr using 'pip install ingestr' and follow a quickstart command to start ingesting data effortlessly.","Discover Ingestr, a code-free data ingestion tool that allows seamless copying of data between various sources and destinations. Learn about the easy installation process and how to use Ingestr for your data transfer needs.",Data Ingestion Tool.,"Python





        1,665





        604


        Built by

          









        15 stars today",,,1180,2019-08-31T15:46:03Z
2024-02-29,https://github.com/bruin-data/ingestr,https://raw.githubusercontent.com/521xueweihan/HelloGitHub/master/README.md,"HelloGitHub is a platform that shares interesting and beginner-friendly open-source projects on GitHub through monthly updates in a magazine format. The content includes interesting projects, open-source books, practical projects, enterprise-level projects, and more to help people experience the charm of open-source and develop a love for it quickly. Readers can enjoy a better reading experience on the official website or HelloGitHub public account. The platform welcomes project recommendations to become contributors. It is also sponsored by various companies to support its activities. The text is licensed under a Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 International License.",Discover Interesting Open Source Projects with HelloGitHub,"HelloGitHub is a platform that shares interesting and beginner-friendly open source projects on GitHub, updated monthly on the 28th. It includes a variety of content such as fun projects, open source books, practical projects, and enterprise-level projects, allowing you to quickly experience the charm of open source and fall in love with it. For a better reading experience, visit the official website or check out HelloGitHub's public account.","Explore the world of open source projects with HelloGitHub. Get insights into fun and beginner-friendly projects, open source books, practical projects, and more. Experience the joy of open source on this platform that updates monthly on the 28th.",Open Source Community,"Python





        1,180





        11


        Built by

          





        482 stars today",,,82566,2024-02-12T23:00:36Z
2024-02-29,https://github.com/521xueweihan/HelloGitHub,https://raw.githubusercontent.com/speechbrain/speechbrain/main/README.md,"The text provides an overview of SpeechBrain, an open-source PyTorch toolkit for developing Conversational AI technologies like speech assistants, chatbots, and large language models. It offers a holistic toolkit that supports various technologies for complex Conversational AI systems, spanning speech recognition, dialogue, language modeling, and more. SpeechBrain provides over 200 training recipes on 40 datasets, supporting 20 speech and text processing tasks. It integrates with HuggingFace for pretrained models and offers features like training orchestration, hyperparameter management, dynamic batching, GPU training, and more. The project encourages contributions and provides a roadmap for future development.",Accelerate Conversational AI Development with SpeechBrain: A Holistic Toolkit Overview,"SpeechBrain is an open-source PyTorch toolkit designed to accelerate Conversational AI development, including technologies for speech assistants, chatbots, and large language models. Built for easy creation of advanced technologies for speech and text processing, SpeechBrain offers a holistic toolkit that supports various technologies like speech recognition, speaker recognition, speech enhancement, speech separation, language modeling, and dialogue. With over 200 competitive training recipes on different datasets and tasks, SpeechBrain supports training from scratch and fine-tuning pretrained models. The toolkit also integrates with Hugging Face for access to over 100 pretrained models and provides prebuilt functionalities for training orchestration, hyperparameter management, efficient data reading, GPU training, mixed-precision training, and more.","Discover how SpeechBrain, an open-source PyTorch toolkit, simplifies Conversational AI development with technologies like speech recognition, speaker recognition, and speech enhancement. Learn about the toolkit's support for over 200 training recipes, integration with Hugging Face, and features for training orchestration, hyperparameter management, and efficient data reading.",Collaborative AI Framework.,"Python





        82,566





        9,361


        Built by

          









        37 stars today",,,7446,2016-05-04T06:24:11Z
2024-02-29,https://github.com/speechbrain/speechbrain,https://raw.githubusercontent.com/sdv-dev/SDV/main/README.md,"The text provides an overview of the Synthetic Data Vault (SDV) project, a Python library for generating tabular synthetic data. It uses various machine learning algorithms to learn patterns from real data and replicate them in synthetic data. The SDV offers features such as creating synthetic data, evaluating and visualizing data, preprocessing, anonymizing, and defining constraints. Users can install the SDV using pip or conda, then use it to synthesize data from real datasets. The library also allows for evaluating the quality of synthetic data by comparing it to real data and provides various visualization tools. The text concludes with credits to contributors and a citation recommendation.",Demystifying Synthetic Data Generation with the SDV Python Library,"The Synthetic Data Vault (SDV) is a powerful Python library designed to simplify the process of creating synthetic tabular data. Using various machine learning algorithms, SDV can learn patterns from real data and replicate them in synthetic datasets. From creating data using machine learning to evaluating and visualizing the data along with the ability to preprocess, anonymize, and define constraints, SDV offers a comprehensive solution for synthetic data generation. Whether you need single table data or interconnected tables, SDV can handle it all with ease. Learn how to get started with SDV, generate synthetic data, evaluate its quality, and explore the various features it offers.","Discover how the Synthetic Data Vault (SDV) Python library makes synthetic data generation effortless. From creating synthetic tabular data using machine learning to evaluating data quality and defining constraints, SDV offers a complete solution. Learn about its features, including preprocessing, anonymization, and visualization tools.",Python Libraries Collection,"Python





        7,446





        1,226


        Built by

          









        106 stars today",https://github.com/sdv-dev/SDV/blob/stable/docs/images/Single-Table-Metadata-Example.png; https://github.com/sdv-dev/SDV/blob/stable/docs/images/Real-vs-Synthetic-Evaluation.png,,1964,2020-04-28T17:48:45Z
2024-02-29,https://github.com/sdv-dev/SDV,https://raw.githubusercontent.com/jianchang512/pyvideotrans/main/README.md,"The text provides an overview of a video translation and dubbing tool. It describes features like translating videos to specified languages, generating subtitles, and adding dubbing automatically. The tool supports various language translations and voice synthesis methods. It allows for tasks like extracting and translating subtitles, merging subtitles and videos, creating dubbing for subtitles, separating voice and background music in videos, and downloading videos from YouTube. The text also includes information on using CUDA acceleration, configuring the tool through a command-line interface, and offers advanced settings through configuration files. Additionally, it lists related projects by the same author and provides contact details for support or donations.",Video Translation and Dubbing Tool,"This is a video translation and dubbing tool that can translate videos from one language to another, automatically generate and add subtitles and dubbing in the specified language. The tool uses faster-whisper and openai-whisper offline models for speech recognition. It supports translation services from Microsoft, Google, Baidu, Tencent, ChatGPT, Azure, Gemini, DeepL, DeepLX, and offline translation services. Voice synthesis supports Microsoft Edge TTS, Openai TTS-1, Elevenlabs TTS, and custom TTS server APIs, with the option to clone voices using 'clone-voice' to replicate the original voice. The tool allows for background music retention and supports various languages such as Chinese, English, Korean, Japanese, Russian, French, German, Italian, Spanish, Portuguese, Vietnamese, Thai, Arabic, Turkish, Hungarian, and Indian languages.","Explore a video translation and dubbing tool that transforms videos from one language to another, automatically adding subtitles and dubbing in the desired language. Support for various languages and services including speech recognition, translation, and voice synthesis methods.",Video Translation Tool.,"Python





        1,964





        271


        Built by

          









        15 stars today",https://raw.githubusercontent.com/jianchang512/pyvideotrans/main/./images/p2.png,,4348,2018-05-11T15:56:50Z
2024-02-29,https://github.com/Fanghua-Yu/SUPIR,https://raw.githubusercontent.com/ultralytics/yolov5/master/README.md,"The text provided introduces the YOLOv5, YOLOv8, and their various features, functionalities, and applications. It details their use in vision AI, including segmentation, classification, and object detection tasks. The text also mentions the availability of pre-trained models, training tutorials, and deployment options. It further highlights the different environments where you can quickly get started with YOLOv5 and how you can contribute to the project. Licensing options for AGPL-3.0 and Enterprise License are explained, along with contact information for bug reports, feature requests, and community interactions.",Introducing YOLOv8: The State-of-the-Art Object Detection Model,"YOLOv8 ðŸš€ is the world's most loved vision AI, representing Ultralytics open-source research into future vision AI methods, incorporating lessons learned and best practices evolved over thousands of hours of research and development. We are thrilled to announce the launch of Ultralytics YOLOv8 ðŸš€, our NEW cutting-edge, state-of-the-art (SOTA) model released at github.com/ultralytics/ultralytics. YOLOv8 is designed to be fast, accurate, and easy to use, making it an excellent choice for a wide range of object detection, image segmentation and image classification tasks. See the YOLOv8 Docs for details and get started with: PyPI version, Downloads, pip install ultralytics. Visit Ultralytics for more details and resources.","Introducing YOLOv8 ðŸš€, the latest state-of-the-art object detection model from Ultralytics. YOLOv8 is designed to be fast, accurate, and easy to use, making it an excellent choice for a wide range of object detection, image segmentation, and image classification tasks. Check out YOLOv8 Docs for details and resources. Purchase an Enterprise License at Ultralytics Licensing for commercial use.",Computer Vision Platform,"Python





        1,874





        131


        Built by

          





        69 stars today",https://user-images.githubusercontent.com/26833433/203113421-decef4c4-183d-4a0a-a6c2-6435b33bc5d3.jpg; https://user-images.githubusercontent.com/26833433/203113416-11fe0025-69f7-4874-a0a6-65d0bfe2999a.jpg,https://www.youtube.com/watch?v=LNwODJXcvt4,45377,2023-12-21T11:23:35Z
2024-02-29,https://github.com/ultralytics/yolov5,https://raw.githubusercontent.com/yerfor/GeneFacePlusPlus/main/README.md,"GeneFace++ is a real-time 3D talking face generation model implemented with Pytorch, focusing on high lip-sync, video-reality, and system efficiency. The official repository provides a guide for quick start, including environment setup, dataset download, and model checkpoints. The implementation includes features like eye blink control and an experimental audio-to-motion model. Users can interact with the model through provided scripts or a Gradio WebUI. Training GeneFace++ with custom videos is possible, with guidelines provided in the documentation. The authors invite citations for their work and plan future releases and enhancements.",GeneFace++: Generalized and Stable Real-Time 3D Talking Face Generation,"This blog post introduces GeneFace++, the official implementation that enables high lip-sync, high video-reality, and high system-efficiency 3D talking face generation using Pytorch. It provides a guide for a quick start in GeneFace++, including steps to prepare the environment, download datasets, and use pre-trained models. The post also covers FAQs, trainings, and citations related to GeneFace++. Explore the post for detailed information and resources.","Learn about GeneFace++, an implementation for high-quality 3D talking face generation, offering a quick start guide, FAQs, training details, and citations. Explore how GeneFace++ enables stable real-time generation of talking faces with high fidelity and efficiency.",Deep Learning Platform.,"Python





        45,377





        15,285


        Built by

          









        35 stars today",,,485,2020-05-18T03:45:11Z
2024-02-29,https://github.com/KillianLucas/open-interpreter,https://raw.githubusercontent.com/Sinaptik-AI/pandas-ai/main/README.md,"PandasAI is a Python library that utilizes generative AI to simplify data exploration, cleaning, and analysis through natural language queries. It offers easy installation via pip or poetry and interactive demos using Colab notebooks. The tool supports various deployment methods, including Jupyter notebooks or as a REST API with FastAPI or Flask. Users can ask questions, visualize data, and work with multiple dataframes. Privacy and security are prioritized through anonymization techniques. The software is available under the MIT license, with options for a managed cloud service or self-hosted enterprise offering. Contributions to the project are encouraged, and documentation, examples, and community discussions are available.",Exploring Data with PandasAI: Natural Language AI for Data Analysis,"PandasAI is a Python library that utilizes generative AI to enable users to interact with their data in natural language. With PandasAI, you can explore, clean, and analyze your data effortlessly using AI-powered tools. The library allows users to ask questions and generate visualizations quickly and effectively. Whether you're a beginner or an expert, PandasAI simplifies the data analysis process and provides valuable insights for decision-making purposes. Discover the power of PandasAI and revolutionize how you interact with your datasets today!","Learn how PandasAI, a Python library powered by generative AI, helps you explore, clean, and analyze data through natural language interactions. Simplify your data analysis process using PandasAI's powerful tools and get valuable insights effortlessly. Whether you're a beginner or an expert, PandasAI revolutionizes the way you work with datasets.",Natural Language Processing.,"Python





        41,238





        3,598


        Built by

          









        50 stars today",https://raw.githubusercontent.com/Sinaptik-AI/pandas-ai/main/images/logo.png,,9933,2023-07-14T07:10:44Z
2024-02-29,https://github.com/Sinaptik-AI/pandas-ai,https://raw.githubusercontent.com/airbytehq/airbyte/master/README.md,"The text describes Airbyte, an open-source data integration platform for ELT pipelines. It aims to cover a wide range of data sources and empower data engineers to customize connectors. Airbyte offers over 300 connectors for APIs, databases, data warehouses, and data lakes. Users can deploy Airbyte Open Source or use Airbyte Cloud to centralize data, create connectors easily, explore tutorials, and orchestrate data syncs. Various tools like Airflow, Prefect, and SQL can be used with Airbyte. The community can engage through Slack, forums, and office hours. Security concerns should be reported to `security@airbyte.io`. Airbyte also offers dedicated support and an Enterprise version with additional features.",Airbyte - Open Source Data Integration Platform,"We believe that only an open-source solution to data movement can cover the long tail of data sources while empowering data engineers to customize existing connectors. Our ultimate vision is to help you move data from any source to any destination. Airbyte already provides the largest catalog of 300+ connectors for APIs, databases, data warehouses, and data lakes. Getting Started: Deploy Airbyte Open Source or set up Airbyte Cloud to start centralizing your data. Create connectors in minutes with our no-code Connector Builder or low-code CDK. Join the Airbyte Community in our Slack, Forum, or Office Hours. Airbyte takes security issues seriously, please email security@airbyte.io for vulnerabilities.","Learn about Airbyte, an open-source data integration platform that offers a wide range of connectors for data movement. Explore how to get started with deploying Airbyte, building connectors, and engaging with the Airbyte community. Find out about Airbyte's security practices and enterprise features. Discover how to contribute to Airbyte and its commitment to open source. Read more on Airbyte's license, security information, and thank you page.",Data Ingestion Tool.,"Python





        9,933





        865


        Built by

          









        26 stars today",,,13370,2023-04-22T12:58:01Z
2024-02-29,https://github.com/airbytehq/airbyte,https://raw.githubusercontent.com/microsoft/sample-app-aoai-chatGPT/main/README.md,"The text describes a sample chat web application that incorporates Azure OpenAI. It includes prerequisites for deploying the app, such as having an Azure OpenAI resource and options for connecting to different data sources. The deployment process is explained, including using Azure Developer CLI, one-click Azure deployment, and deploying from a local machine. Different setups are detailed, such as basic chat experience, chat with your data, enabling chat history, and enabling message feedback. Additionally, information on adding an identity provider, customization scenarios, scalability, debugging the deployed app, configuring vector search, and changing citation display is provided. Best practices and contributing guidelines are also mentioned.",Building a Chat App with Azure OpenAI: Step-By-Step Guide,"This blog post provides a detailed guide on building a chat webapp that integrates with Azure OpenAI. It covers prerequisites such as having an existing Azure OpenAI resource and model deployment, and using Azure OpenAI on different data sources. The post also walks you through deploying the app using Azure Developer CLI, one-click Azure deployment, and deploying from your local machine. Additionally, it includes instructions on enabling chat history, message feedback, and authentication support in your app.","Learn how to build a chat webapp integrating Azure OpenAI with this comprehensive guide. Find steps for deploying the app using Azure Developer CLI, one-click Azure deployment, and deploying from your local machine. Discover how to enable chat history, message feedback, and authentication support.",Collaborative AI Framework.,"Python





        13,370





        3,469


        Built by

          









        75 stars today",,,1073,2020-07-27T23:55:54Z
2024-02-29,https://github.com/microsoft/sample-app-aoai-chatGPT,https://raw.githubusercontent.com/huggingface/diffusers/main/README.md,"The text provides an overview of the ðŸ¤— Diffusers library, a collection of state-of-the-art pretrained diffusion models for generating images, audio, and 3D structures. It emphasizes usability, simplicity, and customizability. The library offers diffusion pipelines, noise schedulers, and pretrained models for creating end-to-end diffusion systems. The installation process for PyTorch and Flax is explained. It also provides a quickstart guide for generating outputs using Diffusers. The text includes links to the documentation, tutorials, optimization guides, and training resources. It encourages contributions from the open-source community and lists popular tasks, pipelines, libraries, credits, and a citation.","ðŸ¤— Diffusers: State-of-the-art diffusion models for Images, Audio, and 3D Structures","ðŸ¤— Diffusers is the go-to library for state-of-the-art pretrained diffusion models for generating images, audio, and even 3D structures of molecules. Whether you're looking for a simple inference solution or training your own diffusion models, ðŸ¤— Diffusers is a modular toolbox that supports both.","Explore ðŸ¤— Diffusers, the library offering state-of-the-art diffusion pipelines, noise schedulers, and pretrained models for generating images, audio, and 3D structures. Learn about installation, quickstart guide, documentation navigation, contributions, popular tasks & pipelines, libraries using ðŸ§¨ Diffusers, credits, and citation.",Deep Learning Platform.,"Python





        1,073





        1,523


        Built by

          









        9 stars today",,,21299,2023-04-06T21:16:41Z
2024-03-03,https://github.com/kyegomez/BitNet,https://raw.githubusercontent.com/kyegomez/BitNet/main/README.md,"The text is about a PyTorch implementation called BitNet, which is based on the ""BitNet: Scaling 1-bit Transformers for Large Language Models"" paper. The BitNet architecture replaces linear projections in Transformers with BitLinear modules. The implementation is simple and involves the transformation of tensor data. BitNet includes features such as BitNetTransformer, BitAttention, BitFeedForward, and BitNetInference for various applications. The text also mentions training on the enwiki8 dataset, new optimizations like BitMGQA, and collaboration in the Agora Discord community. It provides installation instructions, usage examples, and a Huggingface integration guide. Future plans include implementing new versions like BitNet1.5b in Cuda.",BitNet: Scaling 1-bit Transformers for Large Language Models - Implementation and Optimization,"The BitNet architecture offers a simple implementation of 1-bit Transformers for large language models. By replacing linear projections with BitLinear modules, BitNet provides a scalable solution for efficient model training and deployment. The latest iteration of BitNet introduces optimizations such as Bit Attention 'BitMGQA,' which leverages Multi Grouped Query Attention for improved decoding and context handling. With easy-to-use implementations and new features like Bit FeedForward, BitNet opens up possibilities for diverse applications beyond text processing.","Explore the implementation and optimization of BitNet, a revolutionary approach to scaling 1-bit Transformers for large language models. Learn how BitNet simplifies model architecture by introducing BitLinear modules and discover new enhancements like Bit Attention 'BitMGQA.' Dive into the world of efficient model training and deployment with BitNet's innovative features and capabilities.",Language Models,"Python





        819





        68


        Built by

          








        175 stars today",https://raw.githubusercontent.com/kyegomez/BitNet/main/agorabanner.png; https://raw.githubusercontent.com/kyegomez/BitNet/main/bitnet.png,,819,2023-10-18T16:19:06Z
2024-03-03,https://github.com/python-poetry/poetry,https://raw.githubusercontent.com/python-poetry/poetry/main/README.md,"Poetry is a tool for easy Python packaging and dependency management. It simplifies declaring, managing, and installing dependencies for Python projects, ensuring a consistent stack. With Poetry, you can streamline your project setup by replacing multiple files like `setup.py` and `requirements.txt` with a single `pyproject.toml` file. This file specifies project details, dependencies, and optional configurations. Poetry supports various dependency types, including standard, version-specific, git-based, and optional dependencies. Additionally, it organizes dependencies into groups for better management. The tool offers multiple installation methods and comprehensive documentation for users, as well as opportunities for contribution to the project.",Demystifying Python Packaging and Dependency Management with Poetry,"Poetry helps you declare, manage, and install dependencies of Python projects, ensuring you have the right stack everywhere. It replaces `setup.py`, `requirements.txt`, `setup.cfg`, `MANIFEST.in`, and `Pipfile` with a simple `pyproject.toml` based project format. Poetry supports multiple installation methods, including a simple script found at install.python-poetry.org. For full installation instructions, including advanced usage of the script, alternate install methods, and CI best practices, see the full installation documentation.","Learn how Poetry simplifies Python packaging and dependency management, making it easier to manage dependencies, declare projects, and install the right stack everywhere. Discover multiple installation methods, including a simple script at install.python-poetry.org. Find detailed installation instructions and best practices in the full installation documentation.",Python Libraries Collection.,"Python





        28,793





        2,161


        Built by

          









        12 stars today",https://raw.githubusercontent.com/python-poetry/poetry/master/assets/install.gif,,28793,2018-02-28T15:23:47Z
2024-03-03,https://github.com/embedchain/embedchain,https://raw.githubusercontent.com/embedchain/embedchain/main/README.md,"Embedchain is an open-source RAG Framework designed to simplify the creation and deployment of AI applications by offering a *""Conventional but Configurable""* approach. It aids software and machine learning engineers in managing unstructured data efficiently by segmenting it, generating embeddings, and storing them in a vector database for optimized retrieval. With diverse APIs, users can extract contextual information, find answers, and engage in chat conversations tailored to their data. The framework supports easy installation via Python API and showcases a live demo called ""Chat with PDF."" Extensive documentation, community engagement options, and guidelines for contributing are available. Anonymous telemetry data is collected to enhance the package's quality and user experience.",Introducing Embedchain: Open Source RAG Framework for Creating AI Apps,"Embedchain is an Open Source RAG Framework that simplifies the creation and deployment of AI apps. It is designed to be 'Conventional but Configurable' to cater to both software and machine learning engineers. The framework facilitates the development of Retrieval-Augmented Generation (RAG) applications, allowing users to efficiently manage unstructured data, generate embeddings, and optimize retrieval. With a range of APIs, Embedchain empowers users to extract contextual information, find precise answers, and engage in chat conversations tailored to their data.","Discover Embedchain, the Open Source RAG Framework that streamlines AI app development. Learn how Embedchain simplifies managing unstructured data, generating embeddings, and enabling precise answers through diverse APIs.",Collaborative AI Framework.,"Python





        7,962





        944


        Built by

          









        14 stars today",https://raw.githubusercontent.com/embedchain/embedchain/main/docs/images/cover.gif,,7963,2023-06-20T08:58:36Z
2024-03-03,https://github.com/allenai/fm-cheatsheet,https://raw.githubusercontent.com/allenai/fm-cheatsheet/main/README.md,"The text is about ""The Foundation Model Development Cheatsheet,"" providing resources and recommendations for best practices in developing and releasing models. To contribute to the cheatsheet, resources need to meet certain criteria including helpfulness, documentation quality, and value to the development process. They primarily focus on tools like data catalogs, search/analysis tools, and evaluation repositories. Contributors can use an upload form or create a pull request to add resources. For questions, contact slongpre@media.mit.edu. A citation will be available soon. The cheatsheet aims to support responsible development practices and improve the model development process with valuable insights and resources.",Foundation Model Development: Best Practices and Resources,Explore resources and recommendations for best practices in developing and releasing models through our comprehensive cheatsheet. Contribute your own resources by following the provided guidelines and criteria for inclusion. Get involved by using the upload form or creating a pull request on the repository. Contact us for any questions or inquiries regarding this valuable resource.,Discover a cheatsheet with resources and best practices for developing and releasing foundation models. Learn how to contribute resources and get involved in responsible development practices. Contact us for any questions and find out more about citations for the provided information.,Data Science Resources.,"Python





        113





        11


        Built by

          







        27 stars today",https://raw.githubusercontent.com/allenai/fm-cheatsheet/main/app/resources/logos/cheatsheet-0.png,,113,2023-12-01T19:05:20Z
2024-03-03,https://github.com/maszhongming/Multi-LoRA-Composition,https://raw.githubusercontent.com/maszhongming/Multi-LoRA-Composition/main/README.md,"The text discusses a project called Multi-LoRA Composition for Image Generation that introduces two training-free methods, LoRA Switch and LoRA Composite, to integrate various elements into images through multi-LoRA composition. It compares these methods to traditional techniques like LoRA Merge. The project provides guidelines for setting up the environment, downloading pre-trained LoRAs, and generating images using these methods. Additionally, it includes experiments on ComposLoRA and comparative evaluations using GPT-4V. The work also involves human evaluations for assessing composition and image quality. To know more, visit their website or check out the paper on arXiv (https://arxiv.org/abs/2402.16843).",Multi-LoRA Composition for Image Generation: Enhancing Image Creativity with LoRA Switch and LoRA Composite,"Low-Rank Adaptation (LoRA) techniques have revolutionized text-to-image models, allowing for precise rendering of unique elements in generated images. Our project introduces two innovative, training-free methods called LoRA Switch and LoRA Composite. These methods enable multi-LoRA composition, showcasing significant improvements over traditional LoRA Merge approaches. By integrating any number of elements seamlessly into images, our techniques spark creativity and offer a wide range of possibilities for image generation. Explore our step-by-step guide for setting up the environment, downloading pre-trained LoRAs, and utilizing ComposLoRA for generating captivating images with our cutting-edge multi-LoRA Composition methods.","Discover the power of multi-LoRA Composition techniques in the realm of image generation with our innovative LoRA Switch and LoRA Composite methods. Unleash your creativity by seamlessly integrating diverse elements into images, creating visually stunning compositions. Follow our comprehensive guide to set up the environment, download pre-trained LoRAs, and leverage ComposLoRA for image generation that transcends traditional boundaries. Enhance your image creation process with our groundbreaking approaches to multi-LoRA Composition.",Image Generation Platform.,"Python





        226





        23


        Built by

          





        14 stars today",https://raw.githubusercontent.com/maszhongming/Multi-LoRA-Composition/main/images/tangram.png; https://raw.githubusercontent.com/maszhongming/Multi-LoRA-Composition/main/images/intro_fig.png; https://raw.githubusercontent.com/maszhongming/Multi-LoRA-Composition/main/images/merge_example.png; https://raw.githubusercontent.com/maszhongming/Multi-LoRA-Composition/main/images/switch_example.png; https://raw.githubusercontent.com/maszhongming/Multi-LoRA-Composition/main/images/composite_example.png,,226,2024-02-20T20:43:36Z
2024-03-03,https://github.com/PaddlePaddle/PaddleNLP,https://raw.githubusercontent.com/PaddlePaddle/PaddleNLP/main/README.md,"PaddleNLP is a user-friendly and powerful natural language processing and large language model (LLM) development library. It provides high-quality pre-trained models and a seamless development experience, covering a wide range of NLP scenarios with industry-specific model libraries and practical examples to meet developers' needs for customization.

The latest release, **PaddleNLP v2.7**, includes significant upgrades for large model experiences, unified tools for large model training, fine-tuning, compression, inference, and deployment. It introduces a unified checkpoint storage mechanism, LoRA efficient fine-tuning support, and algorithms like QLoRA.

Previous release, **PaddleNLP v2.6**, introduced a full-process large model toolchain covering pre-training, fine-tuning, compression, inference, and deployment. It offers optimized algorithms like LoRA and Prefix Tuning, INT8/INT4 quantization, and supports major large models.

PaddleNLP features a variety of Chinese pre-trained models, a comprehensive collection of application examples, end-to-end industry system examples, and high-performance distributed training and inference capabilities.

For more information and details on installation, features, examples, and community interactions, please refer to the complete text provided above.",PaddleNLP: Easy-to-Use Natural Language Processing Library,"PaddleNLP is a simple yet powerful natural language processing and large language model (LLM) development library. It aggregates industry-quality pre-trained models and provides an out-of-the-box development experience, covering a model library for NLP in various scenarios with industrial practice examples to meet developers' flexible customization needs.","Discover PaddleNLP, a comprehensive library for natural language processing and large language model development. Learn about industry-quality pre-trained models, easy-to-use development tools, and practical examples for various NLP scenarios.",Natural Language Processing,"Python





        11,072





        2,753


        Built by

          









        6 stars today",https://user-images.githubusercontent.com/1371212/175816733-8ec25eb0-9af3-4380-9218-27c154518258.png; https://user-images.githubusercontent.com/11793384/159693816-fda35221-9751-43bb-b05c-7fc77571dd76.gif; https://user-images.githubusercontent.com/11793384/168514909-8817d79a-72c4-4be1-8080-93d1f682bb46.gif; https://user-images.githubusercontent.com/11793384/168514868-1babe981-c675-4f89-9168-dd0a3eede315.gif; https://user-images.githubusercontent.com/11793384/168407260-b7f92800-861c-4207-98f3-2291e0102bbe.png; https://user-images.githubusercontent.com/16698950/168589100-a6c6f346-97bb-47b2-ac26-8d50e71fddc5.png; https://user-images.githubusercontent.com/11793384/168407921-b4395b1d-44bd-41a0-8c58-923ba2b703ef.png; https://user-images.githubusercontent.com/11793384/168407831-914dced0-3a5a-40b8-8a65-ec82bf13e53c.gif; https://user-images.githubusercontent.com/11793384/168515134-513f13e0-9902-40ef-98fa-528271dcccda.png; https://user-images.githubusercontent.com/11987277/245085922-0aa68d24-00ff-442e-9c53-2f1e898151ce.png,,11072,2021-02-05T13:07:42Z
2024-03-03,https://github.com/stanfordnlp/dspy,https://raw.githubusercontent.com/stanfordnlp/dspy/main/README.md,"The text provides information about DSPy, a framework for optimizing language model prompts and weights. DSPy separates the program flow from prompt parameters and introduces optimizers to tune the prompts and weights of language model calls. It aims to improve the quality and cost efficiency of using language models for complex tasks. The framework offers tutorials, documentation, and examples to help users get started. DSPy offers a new paradigm where language models and prompts are optimized pieces of a larger system. It focuses on less prompting, higher scores, and a systematic approach to solving challenging tasks using language models.",DSPy: Programming Foundation Models for Algorithmic Optimization,"**DSPy** is a framework for algorithmically optimizing LM prompts and weights. It separates the flow of your program from the parameters of each step and introduces new optimizers that can tune the prompts and/or the weights of your LM calls. **DSPy** can help teach powerful models like GPT-3.5 or GPT-4 to be more reliable at tasks, leading to higher quality and a more systematic approach to solving hard tasks with LMs.","Learn about how DSPy helps optimize LM prompts and weights, teaches powerful models like GPT-3.5 or GPT-4 to be more reliable, and offers a systematic approach to task-solving with LMs.",Natural Language Processing,"Python





        7,378





        497


        Built by

          









        51 stars today",https://raw.githubusercontent.com/stanfordnlp/dspy/main/docs/images/DSPy8.png,https://www.youtube.com/watch?v=Dt3H2ninoeY; https://www.youtube.com/watch?v=im7bCLW2aM4; https://www.youtube.com/watch?v=41EfOY0Ldkc; https://www.youtube.com/watch?v=ycfnKPxBMck; https://www.youtube.com/watch?v=CDung1LnLbY; https://www.youtube.com/watch?v=CEuUG4Umfxs,7378,2023-01-09T21:01:51Z
2024-03-03,https://github.com/bigcode-project/starcoder2,https://raw.githubusercontent.com/bigcode-project/starcoder2/main/README.md,"StarCoder2 is a collection of code generation models trained on over 600 programming languages from The Stack v2 dataset, as well as natural language text sources like Wikipedia, Arxiv, and GitHub issues. The models use Grouped Query Attention and have significant token capacities. The 3B and 7B models were trained on trillions of tokens, while the 15B model was trained on more than 4 trillion tokens. These models are designed for code completion tasks and are not suitable for instruction-based tasks. The models can be fine-tuned using various techniques such as Low-Rank Adaptation training and quantization. To explore more details, refer to the provided paper link.",Introducing StarCoder2: Advanced Code Generation Models for Programming Languages,"StarCoder2 is a family of code generation models (3B, 7B, and 15B), trained on 600+ programming languages from The Stack v2 and some natural language text such as Wikipedia, Arxiv, and GitHub issues. These models use Grouped Query Attention and have impressive memory footprints, offering various functionalities for code generation and fine-tuning. Learn how to install, load models, generate code, and fine-tune StarCoder2 models efficiently.","Discover StarCoder2, a new family of code generation models trained on diverse programming languages and natural language text. Explore how to install, load, and use these models for code generation, inference, and fine-tuning. Check out this comprehensive guide to understand more about StarCoder2's architecture, memory footprint, and advanced functionalities.",Natural Language Processing,"Python





        522





        43


        Built by

          






        95 stars today",,,522,2023-12-08T08:46:25Z
2024-03-03,https://github.com/MooreThreads/Moore-AnimateAnyone,https://raw.githubusercontent.com/MooreThreads/Moore-AnimateAnyone/master/README.md,"The text provides an update on the release of training codes for AnimateAnyone models, a link to the demo, and details on the repository that reproduces AnimateAnyone. It mentions current limitations and improvements planned for the future. The text includes information on release plans, examples generated, installation instructions, downloading weights, and training and inference details. Additionally, it highlights a Gradio Demo, community contributions, use on the Mobi MaLiang platform, a disclaimer, and acknowledgments to related repositories and contributors. The text also encourages feedback and ideas from the community for further development.",Enhancing Moore-AnimateAnyone: Training Codes Released and Demo Updated,"We have released the training codes for our AnimateAnyone models, allowing users to train their own models. In addition, we have updated the HuggingFace Spaces demo of Moore-AnimateAnyone. Our repository aims to reproduce AnimateAnyone results with various methods, although some differences may exist from the original paper. While our current version approximates 80% of the performance shown in AnimateAnyone, we acknowledge certain limitations such as background artifacts and scale mismatches. Future improvements will address these issues. Instructions for installation, downloading weights, training, and inference are provided in detail.","Explore the latest updates on Moore-AnimateAnyone with the release of training codes and an updated HuggingFace Spaces demo. Reproducing AnimateAnyone results with our repository while addressing limitations. Installation guidance, weight downloading instructions, training, and inference details included for users' convenience.",Image Generation Platform.,"Python





        2,243





        171


        Built by

          







        21 stars today",,https://github.com/MooreThreads/Moore-AnimateAnyone/assets/138439222/9c4d852e-0a99-4607-8d63-569a1f67a8d2; https://github.com/MooreThreads/Moore-AnimateAnyone/assets/138439222/722c6535-2901-4e23-9de9-501b22306ebd; https://github.com/MooreThreads/Moore-AnimateAnyone/assets/138439222/17b907cc-c97e-43cd-af18-b646393c8e8a; https://github.com/MooreThreads/Moore-AnimateAnyone/assets/138439222/86f2f6d2-df60-4333-b19b-4c5abcd5999d,2243,2024-01-12T07:55:21Z
2024-03-03,https://github.com/freqtrade/freqtrade,https://raw.githubusercontent.com/freqtrade/freqtrade/master/README.md,"Freqtrade is an open-source crypto trading bot written in Python, supporting major exchanges and controllable via Telegram or webUI. It offers backtesting, plotting, and money management tools, with strategy optimization through machine learning. The bot provides features like persistence, dry-run mode, strategy optimization, adaptive prediction modeling, position sizing, whitelist/blacklist cryptocurrencies, a built-in WebUI, Telegram management, and performance reporting. It runs on Python 3.9+ and utilizes sqlite for persistence. Freqtrade is best used for educational purposes, emphasizing the need for understanding before investing real money. Detailed documentation and development branches are available for further exploration and community support. Required resources include an accurate clock, minimum hardware specifications, Python 3.9+, TA-Lib, virtualenv, and Docker.",Discover Freqtrade: Free Open Source Crypto Trading Bot in Python,"Freqtrade is a free and open source crypto trading bot written in Python, designed to support all major exchanges and controlled via Telegram or webUI. It offers features like backtesting, money management tools, and strategy optimization via machine learning. Please start by running the bot in Dry-run mode and ensure you have coding and Python knowledge before engaging money. Join the Freqtrade community through Discord for help, to report bugs, or make feature requests.","Explore Freqtrade, a free and open source Python-based crypto trading bot supporting major exchanges. Learn about its features, community support, and requirements for running the bot efficiently. Join the Discord server for help, bug reporting, and feature requests.",Crypto Trading Bot,"Python





        24,677





        5,384


        Built by

          









        130 stars today",https://raw.githubusercontent.com/freqtrade/freqtrade/develop/docs/assets/freqtrade-screenshot.png,,24677,2017-05-17T23:48:53Z
2024-03-03,https://github.com/jhao104/proxy_pool,https://raw.githubusercontent.com/jhao104/proxy_pool/master/README.md,"The text provides information about ProxyPool, a web crawler proxy IP pool project. It includes details on the functionality, usage methods (API and CLI), supported Python versions, running the project, using Docker, extending proxy sources, and free proxy sources. The text also offers guidance on contributing to the project, reporting issues, and using the proxies in web scraping. It mentions contributors and provides a link to the changelog. The project aims to collect free proxies, verify their validity, and offer them through an API. You can find more detailed information in the complete text.",ProxyPool: A Comprehensive Guide to Building and Managing Proxy IP Pools,"ProxyPool project focuses on collecting and verifying free proxies from various sources. It ensures the availability of proxies by regular validation and offers API and CLI interfaces. Users can extend proxy sources to enhance the quality and quantity of the proxy pool IP addresses. This blog provides instructions on running the project, setting up, using Docker images, and expanding proxy sources for better performance.","Discover how ProxyPool project can help you in managing and validating proxy IP pools effectively. Learn about the features, setup instructions, Docker Image usage, and how to add new proxy sources for better performance.",Open Source Tool,"Python





        19,776





        4,888


        Built by

          









        6 stars today",,,19776,2016-11-25T13:49:07Z
2024-03-03,https://github.com/fluencelabs/dev-rewards,https://raw.githubusercontent.com/fluencelabs/dev-rewards/main/README.md,"The text provides guidelines on how to generate proof for Fluence Developer Rewards using different methods. 

For docker image proof generation, you need to build the image and run the script with your ssh keys directory path specified.

For local proof generation using shell script, you should install dependencies and run the shell script provided.

For local proof generation using python script, you need to install Python, create a virtual environment, install dependencies, and run the Python script.

These steps involve setting up docker images, running local shell scripts, and running Python scripts to generate proof for Fluence Developer Rewards.",Fluence Developer Rewards: Generating Proof via Docker and Local Scripts,"Learn how to generate proof for Fluence developer rewards using Docker and local scripts. Docker image can be built using `docker build -t dev-reward-script .` command. If your ssh keys are in different directories, customize the Docker run command accordingly. For generating proof using local scripts, dependencies need to be installed with `./install.sh` and the respective scripts need to be run as described.",Discover the process of generating proof for Fluence developer rewards with Docker and local scripts. Follow the instructions to build a Docker image and run scripts locally. Install dependencies and execute the necessary scripts to claim your developer rewards efficiently.,Crypto Tools & Guides.,"Python





        147





        116


        Built by

          









        16 stars today",,,147,2024-02-27T12:12:28Z
2024-03-03,https://github.com/kijai/ComfyUI-SUPIR,https://raw.githubusercontent.com/kijai/ComfyUI-SUPIR/main/README.md,"The text provides information about the ComfyUI SUPIR upscaler wrapper node, which is a work in progress. Users can install the node by managing and installing from git or cloning the repo to custom_nodes and running specific commands. Additional instructions on installing necessary dependencies are provided. The text also mentions memory requirements and system specifications for running the node efficiently. Furthermore, it includes links to access the SUPIR models and provides warnings about downloading large models. The text also shares links for original models, associated BibTeX information, contact details, and guidelines for non-commercial use.",ComfyUI SUPIR Upscaling Node Guide,"ComfyUI SUPIR upscaler wrapper node is an essential tool for enhancing image resolution and quality. To install, either manage and install from Git or clone the repo to custom_nodes and run `pip install -r requirements.txt`. Memory requirements are directly related to input image resolution. Additionally, you can find the SUPIR model(s) and SDXL model in the `ComfyUI/models/checkpoints` folder. For testing, you can conduct video upscale tests and image upscales with provided links. Check the blog for more details.",Learn how to use the ComfyUI SUPIR upscaling node to enhance image quality and resolution. Install the node with provided instructions and explore various model options. Test the node's performance with upscale tests. Find the SUPIR model(s) and SDXL model in the designated folder. Discover more about image enhancement with this comprehensive guide.,Custom Node Framework.,"Python





        280





        13


        Built by

          






        33 stars today",,,280,2024-02-28T19:14:40Z
2024-03-03,https://github.com/speechbrain/speechbrain,https://raw.githubusercontent.com/Z4nzu/hackingtool/master/README.md,"The text describes a comprehensive hacking tool for hackers with various features and updates. It includes installation instructions for Linux and Docker, along with a list of hacking tools categorized under different sections such as Anonymously Hiding Tools, Information Gathering Tools, Wordlist Generator, Wireless Attack Tools, SQL Injection Tools, Phishing Attack Tools, Web Attack Tools, Post Exploitation Tools, etc. The tool comes with a menu listing different tool categories and provides links to access them on GitHub. The text emphasizes using the tool responsibly and provides social media links for the original author. Additionally, it offers future updates and encourages feedback and suggestions for improvements.",The Ultimate Hacking Tool Collection for Hackers | All-in-One Toolkit,"Discover the ultimate hacking toolkit that includes tools for anonymity, information gathering, wordlist generation, wireless attacks, SQL injections, phishing, web attacks, post-exploitation, forensic analysis, payload creation, exploit frameworks, reverse engineering, DDoS attacks, RAT tools, XSS attacks, steganography, and more. This comprehensive resource also covers social media bruteforcing, Android hacking, IDN homograph attacks, email verification, hash cracking, WiFi deauthentication, social media reconnaissance, payload injection, web crawling, and a mix of other helpful tools. Ensure you use this toolkit responsibly, and explore various tools for ethical hacking and cybersecurity testing.","Explore the ultimate hacking toolkit featuring tools for anonymity, information gathering, SQL injections, phishing, web attacks, post-exploitation, payload creation, and more. Discover tools for social media bruteforcing, Android hacking, steganography, and more. Use this toolkit responsibly for ethical hacking and cybersecurity testing.",Cybersecurity Tool,"Python





        7,493





        1,230


        Built by

          









        25 stars today",https://github.com/Z4nzu/hackingtool/blob/master/images/A00.png; https://github.com/Z4nzu/hackingtool/blob/master/images/A0.png; https://github.com/Z4nzu/hackingtool/blob/master/images/A1.png; https://github.com/Z4nzu/hackingtool/blob/master/images/A2.png; https://github.com/Z4nzu/hackingtool/blob/master/images/A4.png,https://www.youtube.com/watch?v=BsFhpIDcd9I,42145,2020-04-28T17:48:45Z
2024-03-03,https://github.com/layerdiffusion/sd-forge-layerdiffusion,https://raw.githubusercontent.com/layerdiffusion/sd-forge-layerdiffusion/main/README.md,"The text provides updates and details about the ""sd-forge-layerdiffusion"" repository, focusing on transparent image layer diffusion using latent transparency. It mentions work-in-progress extensions, image generation functionalities, and model releases for SDXL. The text includes specific prompts for users to check the transparency diffusion process, details on released models, and instructions for background and foreground conditions. It also addresses potential upcoming releases, model improvements, and emphasizes reproducing results accurately. The repository aims to provide a dynamic code base for generating transparent images and layers using innovative techniques, benefiting professional content creation studios.",,,,Image Generation Platform.,"Python





        1,085





        85


        Built by

          





        301 stars today",,,1085,2024-03-01T06:41:32Z
2024-03-03,https://github.com/naver/dust3r,https://raw.githubusercontent.com/naver/dust3r/main/README.md,"The text provides information about the implementation of DUSt3R, a tool for geometric 3D vision. It includes details like the project page, arXiv link, and a BibTeX citation. Installation steps are outlined, along with checkpoints for pre-trained models. An interactive demo is described for reconstructing scenes, along with code snippets for usage examples. Training instructions are also included, with hyperparameters and steps for training the DUSt3R models. Overall, the text covers various aspects of DUSt3R, from its features to practical usage and training guidance.",DUSt3R: Geometric 3D Vision Made Easy | Implementation and Usage Guide,"DUSt3R offers an official implementation of 'DUSt3R: Geometric 3D Vision Made Easy'. The blogpost provides comprehensive information on the installation process, checkpoints, interactive demo, usage guidelines, as well as training insights. Learn how to clone DUSt3R, create the environment, compile cuda kernels, download pre-trained models, run interactive demos, perform global alignment, visualize reconstructions, and more. Dive into the world of 3D vision with DUSt3R!","Discover the official implementation of 'DUSt3R: Geometric 3D Vision Made Easy' along with installation guides, checkpoints information, interactive demo instructions, usage insights, and training details. Learn how to use DUSt3R for 3D reconstruction and enhance your understanding of 3D vision. Get started with DUSt3R today!",Computer Vision Platform.,"Python





        894





        63


        Built by

          






        198 stars today",https://raw.githubusercontent.com/naver/dust3r/main/assets/pipeline1.jpg; https://raw.githubusercontent.com/naver/dust3r/main/assets/dust3r_archi.jpg; https://raw.githubusercontent.com/naver/dust3r/main/assets/demo.jpg; https://raw.githubusercontent.com/naver/dust3r/main/assets/matching.jpg,,894,2024-02-21T07:13:14Z
2024-03-03,https://github.com/AUTOMATIC1111/stable-diffusion-webui,https://raw.githubusercontent.com/AUTOMATIC1111/stable-diffusion-webui/master/README.md,"The text describes a web interface called Stable Diffusion web UI, developed using the Gradio library. The interface offers various features, including img2img and txt2img modes, outpainting, inpainting, color sketch, and more. Users can adjust attention to specific text parts, run img2img processing multiple times, and create 3D image plots. Additional functionalities include the ability to run arbitrary Python code, mouseover hints, and support for various neural network tools. The text also provides detailed installation instructions for different platforms and highlights the contributions from various sources. The interface supports multiple extensions and integrations, making it a comprehensive tool for visual generation tasks.","Enhancing Visual Generation with Stable Diffusion Web UI: Features, Installation, and Contributions","Stable Diffusion Web UI is a powerful tool that offers various features such as original txt2img and img2img modes, outpainting, inpainting, color sketch, prompt matrix, stable diffusion upscale, and much more. Users can enjoy live previews, custom scripts, tiling support, highres fix, and API support. The installation process varies for different platforms, including NVidia GPUs, AMD GPUs, Intel CPUs and GPUs, and Apple Silicon. The project welcomes contributions and provides comprehensive documentation on its wiki.","Discover the diverse features of Stable Diffusion Web UI for visual generation, learn how to install it on different platforms, and explore opportunities to contribute. Check out the detailed installation guides for NVidia GPUs, AMD GPUs, Intel CPUs, and Apple Silicon. Get started with this innovative tool today!",Computer Vision Platform.,"Python





        123,701





        24,154


        Built by

          









        142 stars today",https://raw.githubusercontent.com/AUTOMATIC1111/stable-diffusion-webui/master/screenshot.png,,123701,2022-08-22T14:05:26Z
2024-03-03,https://github.com/allenai/OLMo,https://raw.githubusercontent.com/allenai/OLMo/main/README.md,"OLMo, short for Open Language Model, is a repository dedicated to training and utilizing AI2's advanced open language models, developed by scientists specifically for scientific purposes. It offers models like OLMo 1B, OLMo 7B, and OLMo 7B Twin 2T, trained on the Dolma dataset. Users can install OLMo via PyPI or from the source code. The text details installation instructions, various models in the OLMo family, how to run inference using Hugging Face integration, finetuning checkpoints, quantization, reproducibility tips for training, inspecting training data, finetuning instructions, evaluation tools, and a citation reference for OLMo research.","OLMo: Open Language Model - Overview, Installation, Models, and Inference","OLMo is a repository for training and using AI2's state-of-the-art open language models. Built by scientists, for scientists, OLMo offers models like OLMo 1B, OLMo 7B, and OLMo 7B Twin 2T trained on the Dolma dataset. The blogpost covers installation instructions for PyTorch, models overview, inference using Hugging Face integration, quantization details, reproducibility with training and inspecting data, fine-tuning guidance, evaluation tools, and citation information.","Learn about OLMo, a repository for open language models like OLMo 1B, OLMo 7B, and OLMo 7B Twin 2T. Explore installation guides, models overview, inference methods with Hugging Face, quantization, reproducibility steps, fine-tuning instructions, evaluation tools, and citation details for OLMo. Discover how OLMo accelerates the science of language models.",Language Models,"Python





        3,264





        283


        Built by

          









        60 stars today",https://allenai.org/olmo/olmo-7b-animation.gif,,3264,2023-02-20T22:29:43Z
2024-03-03,https://github.com/mini-sora/minisora,https://raw.githubusercontent.com/mini-sora/minisora/main/README.md,"Mini Sora is an open-source community organized by students aiming to explore the implementation path of Sora and its future development direction. They conduct roundtable discussions with the community to explore possibilities, and discuss existing technologies for video generation. The community also has a paper reproduction group focusing on GPU-friendly, training-efficient, and inference-efficient targets. They have ongoing discussions, reading plans, and various related works in the field of diffusion models, transformers, video generation, and more. The community welcomes contributions and has a dedicated group of contributors. You can learn more and contribute by visiting their GitHub repository.","Exploring the World of Sora: Latest Updates, Research, and Community Discussions","Join the Mini Sora open-source community, a place for exploring Sora's implementation paths and future directions. Engage in roundtable discussions, explore video generation technologies, and delve into diffusion models for visual computing. Stay updated with the latest research, papers, and shared insights within the community.","Discover the Mini Sora open-source community, where you can participate in roundtable discussions, explore video generation technologies, and dive into diffusion models. Stay up-to-date with the latest research and community insights on Sora's implementation paths and future directions.",Collaborative AI Framework.,"Python





        310





        40


        Built by

          









        51 stars today",https://raw.githubusercontent.com/mini-sora/minisora/main/assets/logo.jpg; https://raw.githubusercontent.com/mini-sora/minisora/main/assets/qrcode.png,,310,2024-02-21T13:50:34Z
2024-03-03,https://github.com/liguodongiot/llm-action,https://raw.githubusercontent.com/liguodongiot/llm-action/main/README.md,"The text provides an overview of various topics related to large language models (LLMs). It covers different aspects such as model training, inference, compression, algorithm architecture, AI compilers, AI infrastructure, model deployment on servers, and common tools used in these domains. The text includes information on specific LLM training practices, optimization techniques like knowledge distillation and low-rank decomposition, as well as tools and frameworks commonly used in LLM development. It also mentions learning and discussion groups dedicated to LLMs and provides links to relevant resources and materials. Additionally, there is a section on the history of stars the project has gathered over time.","Exploring Large Language Models: Training, Inference, and Compression","The blog post dives into different aspects of large language models (LLMs) including training techniques, inference frameworks, and model compression methods. It covers topics like distributed training, LLM fine-tuning technologies, knowledge distillation, low-rank decomposition, model localization, AI compilers, and more. The post also provides insights on LLM applications, AI infrastructure setup, and commonly used tools. Join the LLM learning and discussion groups, and follow the companion WeChat Official Account for the latest updates on AI engineering practices.","Explore various facets of large language models (LLMs) from training to inference and model compression. Learn about distributed training techniques, LLM fine-tuning methods, knowledge distillation, low-rank decomposition, AI compilers, AI infrastructure setup, and essential tools. Join learning groups and follow the WeChat Official Account for AI engineering insights.",Language Models,"Python





        3,711





        346


        Built by

          





        154 stars today",https://github.com/liguodongiot/llm-action/blob/main/pic/llm-action-v3.png; https://github.com/liguodongiot/llm-action/blob/main/pic/wx.jpg; https://github.com/liguodongiot/llm-action/blob/main/pic/wx-gzh.png,,3711,2023-05-23T05:29:16Z
2024-03-03,https://github.com/lllyasviel/Fooocus,https://raw.githubusercontent.com/tinygrad/tinygrad/master/README.md,"tinygrad is a deep learning framework maintained by tiny corp. It aims to be a simple framework to add new accelerators to, supporting both inference and training. The framework is still in alpha stage but has received funding for further development. Key features include LLaMA and Stable Diffusion, as well as laziness for fused operations. Neural networks can be easily implemented with tinygrad, along with support for various accelerators such as GPU, C Code, LLVM, METAL, CUDA, and HIP. Installation is recommended from source. Contributions are welcomed, with guidelines provided for submitting PRs. Tests can be run locally using pytest.",Exploring tinygrad: A Simple yet Powerful Deep Learning Framework,"tinygrad is a deep learning framework maintained by tiny corp, sitting between PyTorch and micrograd. Despite its simplicity, it aims to be versatile and easy to extend with new accelerators for both inference and training purposes. With features like LLaMA and Stable Diffusion, laziness for efficient kernel fusion, and neural network capabilities, tinygrad offers a promising tool for machine learning enthusiasts. The framework already supports various accelerators like GPU, C Code, LLVM, METAL, CUDA, and HIP, with the flexibility to add more. Installation is recommended from the source code, and documentation can be found in the docs directory.","Discover the simplicity and power of tinygrad, a deep learning framework between PyTorch and micrograd. Learn about its features, including LLaMA and Stable Diffusion, laziness for efficient kernel fusion, and neural network capabilities. Explore how tinygrad supports various accelerators like GPU, C Code, LLVM, METAL, CUDA, and HIP, with the flexibility to add more. Installation is recommended from the source code, and documentation can be found in the docs directory.",Deep Learning Framework,"Python





        32,053





        3,665


        Built by

          









        70 stars today",https://raw.githubusercontent.com/tinygrad/tinygrad/master/docs/logo.png,,22567,2023-08-09T18:43:40Z
2024-03-03,https://github.com/freqtrade/freqtrade,https://raw.githubusercontent.com/roboflow/supervision/main/README.md,"The text provides information about a computer vision toolkit called Supervision. It offers tools for loading datasets, drawing detections on images or videos, and counting detections in a zone. The toolkit supports various models and provides customizable annotators and dataset utilities. Users can install the Supervision package using pip in a Python environment. The text includes code examples for working with detection models and annotating images. Additionally, it mentions tutorials on vehicle tracking and traffic analysis. The text also encourages contributions and provides links to documentation and resources related to Supervision.",Computer Vision Tools: Building Reusable Models with Supervision,"Discover how Supervision provides reusable computer vision tools for loading datasets, drawing detections, and counting detections. Pip install the supervision package in a Python environment to get started. Use Supervision for model-agnostic tasks like classification, detection, and segmentation. Explore various connectors and annotators to enhance your computer vision projects. Learn about the dataset utilities provided by Supervision for loading, splitting, merging, and saving datasets.","Learn about the reusable computer vision tools offered by Supervision for loading datasets, drawing detections, and counting detections. Follow a quick installation guide by pip installing the supervision package in Python environment. Dive into model-agnostic applications for classification, detection, and segmentation tasks. Explore connectors and annotators provided by Supervision to enhance your computer vision projects. Discover the dataset utilities for loading, splitting, merging, and saving datasets.",Computer Vision Platform.,"Python





        24,695





        5,387


        Built by

          









        40 stars today",https://raw.githubusercontent.com/ultralytics/assets/main/social/logo-transparent.png; https://raw.githubusercontent.com/ultralytics/assets/main/social/logo-transparent.png; https://raw.githubusercontent.com/ultralytics/assets/main/social/logo-transparent.png; https://raw.githubusercontent.com/ultralytics/assets/main/social/logo-transparent.png; https://raw.githubusercontent.com/ultralytics/assets/main/social/logo-transparent.png,https://www.youtube.com/watch?v=uWP6UjDeZvY; https://www.youtube.com/watch?v=uWP6UjDeZvY; https://www.youtube.com/watch?v=4Q3ut7vqD5o; https://www.youtube.com/watch?v=4Q3ut7vqD5o,9780,2017-05-17T23:48:53Z
2024-03-03,https://github.com/microsoft/unilm,https://raw.githubusercontent.com/ltdrdata/ComfyUI-Impact-Pack/master/README.md,"The text provides detailed information about a custom node pack called ComfyUI-Impact-Pack. It includes various custom nodes such as Detectors, Detailers, SEGS Manipulation nodes, Pipe nodes, Image Utils, Switch nodes, Wildcards, and more. The pack offers features like controlling nodes, applying sampling methods, working with detectors and classifiers, and handling image and mask manipulation. Additionally, the text mentions explanations on Ultralytics models, installation instructions, and package dependencies. Users can apply these nodes to enhance image quality, process segmentation, work with detectors, and manage conditional logic within ComfyUI workflows effectively.",ComfyUI-Impact-Pack Custom Nodes for Enhancing Images and Models,"The ComfyUI-Impact-Pack is a collection of custom nodes designed to enhance images through various detectors, detailers, upscalers, and more. Recent compatibility patches and feature updates ensure smooth performance, but users are advised to update to the latest versions for optimal functionality. Various custom nodes such as Detectors, SAMLoader, Detailers, and SEGS Manipulation nodes are included to streamline image enhancement workflows. Installing the Impact Pack allows access to Ultralytics models for face, people, and clothing detection, along with NSFW content models.","Discover the capabilities of the ComfyUI-Impact-Pack, a collection of custom nodes designed to enhance images through detectors, detailers, and upscalers. Stay up-to-date with recent compatibility patches and feature updates to ensure optimal performance. Update to the latest versions for seamless workflow integration and access to Ultralytics models for various detections, including face, people, and clothing models.",Custom Node Pack,"Python





        17,587





        2,302


        Built by

          









        132 stars today",https://github.com/ltdrdata/ComfyUI-extension-tutorials/raw/Main/ComfyUI-Impact-Pack/images/simple.png; https://github.com/ltdrdata/ComfyUI-extension-tutorials/raw/Main/ComfyUI-Impact-Pack/images/simple-original.png; https://github.com/ltdrdata/ComfyUI-extension-tutorials/raw/Main/ComfyUI-Impact-Pack/images/simple-refined.png; https://github.com/ltdrdata/ComfyUI-extension-tutorials/raw/Main/ComfyUI-Impact-Pack/images/2pass-simple.png; https://github.com/ltdrdata/ComfyUI-extension-tutorials/raw/Main/ComfyUI-Impact-Pack/images/2pass-original.png; https://github.com/ltdrdata/ComfyUI-extension-tutorials/raw/Main/ComfyUI-Impact-Pack/images/2pass-1pass.png; https://github.com/ltdrdata/ComfyUI-extension-tutorials/raw/Main/ComfyUI-Impact-Pack/images/2pass-2pass.png; https://github.com/ltdrdata/ComfyUI-extension-tutorials/raw/Main/ComfyUI-Impact-Pack/images/combination.jpg; https://github.com/ltdrdata/ComfyUI-extension-tutorials/raw/Main/ComfyUI-Impact-Pack/images/combination-original.png; https://github.com/ltdrdata/ComfyUI-extension-tutorials/raw/Main/ComfyUI-Impact-Pack/images/combination-refined.png; https://github.com/ltdrdata/ComfyUI-extension-tutorials/raw/Main/ComfyUI-Impact-Pack/images/upscale-workflow.png; https://github.com/ltdrdata/ComfyUI-extension-tutorials/raw/Main/ComfyUI-Impact-Pack/images/upscale-original.png; https://github.com/ltdrdata/ComfyUI-extension-tutorials/raw/Main/ComfyUI-Impact-Pack/images/upscale-3x.png; https://github.com/ltdrdata/ComfyUI-extension-tutorials/raw/Main/ComfyUI-Impact-Pack/images/SAMDetector-menu.png; https://github.com/ltdrdata/ComfyUI-extension-tutorials/raw/Main/ComfyUI-Impact-Pack/images/SAMDetector-dialog.jpg; https://github.com/ltdrdata/ComfyUI-extension-tutorials/raw/Main/ComfyUI-Impact-Pack/images/SAMDetector-result.jpg,https://www.youtube.com/watch?v=AccoxDZIg3Y; https://www.youtube.com/watch?v=AccoxDZIg3Y,959,2019-07-23T04:15:28Z
2024-03-03,https://github.com/ltdrdata/ComfyUI-Impact-Pack,https://raw.githubusercontent.com/BatsResearch/bonito/main/README.md,"Bonito is an open-source model designed for creating task-specific training datasets from unannotated text for instruction tuning. It allows for easy generation of synthetic datasets using the Hugging Face `transformers` and `vllm` libraries. The tool supports various task types such as question answering, sentiment analysis, summarization, and more. To use Bonito, you can create a synthetic instruction tuning dataset by providing unannotated text and defining the task type. The model is accessible through the `bonito-v1` repository and the `ctga-v1` dataset. To reproduce experiments, refer to the `nayak-arxiv24-code` GitHub repository. If using Bonito in research, remember to cite the provided paper.",Bonito: An Open-Source Model for Instruction Tuning Dataset Generation,"Bonito is an open-source model designed to convert unannotated text into task-specific training datasets for instruction tuning. This blog introduces Bonito as a lightweight library that allows for the easy creation of synthetic datasets using Hugging Face `transformers` and `vllm` libraries. Users can follow specific installation and usage instructions to generate synthetic instruction tuning datasets across various supported task types. Additionally, the post includes information on citation guidelines for referencing Bonito in research.","Learn about Bonito, an open-source model for generating instruction tuning datasets from unannotated text. Discover how to easily create synthetic datasets with Bonito using Hugging Face libraries. Explore the installation steps and basic usage instructions for generating synthetic datasets for various supported task types.",Language Models.,"Python





        959





        92


        Built by

          









        3 stars today",https://raw.githubusercontent.com/BatsResearch/bonito/main/assets/workflow.png,,162,2023-03-30T13:54:51Z
2024-03-03,https://github.com/BatsResearch/bonito,https://raw.githubusercontent.com/huggingface/alignment-handbook/main/README.md,"The text is a handbook called ""The Alignment Handbook"" that focuses on aligning language models with human and AI preferences. It discusses techniques like supervised fine-tuning, reward modeling, rejection sampling, and direct preference optimization. The handbook provides robust training recipes and highlights recent releases and news related to aligning language models. It includes links to models, datasets, and demos, along with navigation tips for the project structure. The text also mentions installation instructions and encourages readers to cite the handbook if found useful. Overall, the handbook aims to be a resource for the ML community on training language models to better align with user preferences.",The Alignment Handbook: Robust Training Recipes for Language Model Alignment,"Robust recipes to align language models with human and AI preferences. Just one year ago, chatbots were out of fashion and most people hadn't heard about techniques like Reinforcement Learning from Human Feedback (RLHF) to align language models with human preferences. The Alignment Handbook aims to fill the gap by providing robust training recipes that span the entire pipeline, including supervised fine-tuning, reward modeling, rejection sampling, and direct preference optimization (DPO). Explore how to replicate models like Zephyr 7B, navigate the project, and install dependencies.","Discover robust training recipes in The Alignment Handbook for aligning language models with human and AI preferences. Learn about supervised fine-tuning, reward modeling, rejection sampling, and direct preference optimization (DPO). Explore project navigation and installation instructions for running the code efficiently.",Natural Language Processing.,"Python





        162





        8


        Built by

          






        38 stars today",https://raw.githubusercontent.com/huggingface/alignment-handbook/main/assets/handbook.png,,3331,2024-02-25T13:33:33Z
2024-03-03,https://github.com/huggingface/alignment-handbook,https://raw.githubusercontent.com/alexta69/metube/master/README.md,"MeTube is a web GUI for youtube-dl that uses the yt-dlp fork, allowing you to download videos from various sites with playlist support. It can be run with Docker or docker-compose, and settings can be configured via environment variables. You can set options such as user and group IDs, download directories, themes, output file templates, and more. MeTube supports using browser cookies for restricted or private videos, browser extensions for easy downloads, an iOS Shortcut, and a bookmarklet. Running behind a reverse proxy is recommended for authentication and HTTPS support. Regular updates are necessary to keep up with changes in the yt-dlp engine.",A Complete Guide to MeTube: Web GUI for youtube-dl with Playlist Support,"MeTube is a powerful web GUI for youtube-dl that supports playlists from YouTube and many other sites. You can easily download videos by running it using Docker or docker-compose. Customize MeTube using various environment variables for settings like theme, download directories, output templates, and more. Additionally, learn how to use browser cookies with MeTube, browser extensions, iOS shortcuts, and bookmarklets for seamless video downloads. Discover tips for running MeTube behind a reverse proxy, updating yt-dlp, and building/running MeTube locally.","Explore the functionalities of MeTube, a web GUI for youtube-dl with playlist support. Learn how to download videos from YouTube and other platforms, customize settings via environment variables, use browser cookies, browser extensions, iOS shortcuts, and bookmarklets for efficient downloads. Get insights on running MeTube behind a reverse proxy, updating yt-dlp, and building/running MeTube locally for a seamless video download experience.",Data Ingestion Tool,"Python





        3,331





        248


        Built by

          









        12 stars today",https://github.com/alexta69/metube/raw/master/screenshot.gif,,2890,2023-08-25T11:35:34Z
2024-03-03,https://github.com/alexta69/metube,https://raw.githubusercontent.com/VikParuchuri/marker/master/README.md,"Marker is a tool that converts PDF, EPUB, and MOBI files to markdown, emphasizing speed and accuracy. It specializes in handling PDF documents such as books and scientific papers. The conversion process involves advanced deep learning models for tasks like text extraction, layout detection, and formatting. Marker outperforms a similar tool named Nougat in speed and has lower hallucination risks due to its focused algorithm. The tool supports multiple languages and provides customizable settings. Marker is suitable for academic and digital PDFs, offering features like equation conversion to LaTeX and code block formatting. It is optimized for GPU, CPU, or MPS usage. Marker's limitations include occasional issues with equations and language support. Installation instructions and usage guidelines are provided for Linux and Mac systems. Performance benchmarks showcase Marker's speed and accuracy, comparing it with Nougat and naive text extraction methods. Commercial usage is restricted due to licensing of certain dependencies, but a commercial version is being developed. The tool acknowledges various open-source models and datasets that have contributed to its development.",Introducing Marker: A Fast and Accurate PDF to Markdown Converter,"Marker is a powerful tool that efficiently converts PDF, EPUB, and MOBI files to markdown format. It boasts a 10x speed improvement over similar tools like nougat and offers greater accuracy, especially on complex documents. With features like support for various PDF document types, equation conversion to Latex, code block and table formatting, and multi-language support, Marker is a versatile solution. Its deep learning pipeline ensures efficient text extraction, page layout detection, and post-processing, resulting in high-quality markdown output.","Discover Marker, a revolutionary tool for converting PDF files to markdown at lightning speed. Learn about its features, speed, and accuracy compared to existing solutions. See how Marker's deep learning models ensure precise text extraction and formatting, making it a standout choice for your PDF conversion needs.",Document Conversion Tool,"Python





        2,890





        198


        Built by

          









        128 stars today",https://raw.githubusercontent.com/VikParuchuri/marker/master/data/images/overall.png; https://raw.githubusercontent.com/VikParuchuri/marker/master/data/images/per_doc.png,,6974,2019-11-29T17:24:51Z
2024-03-03,https://github.com/VikParuchuri/marker,https://raw.githubusercontent.com/majacinka/crewai-experiments/main/README.md,"The text describes experiments using CrewAI, focusing on different AI projects. The projects involve tasks like examining startup ideas, creating AI newsletters from Google SERP and Reddit Scraping, and developing an email classifier. Various AI models like GPT-4, Gemini Pro, Mistral, Open Chat, Nous Hermes, among others, were used for the experiments. Results varied, with some models producing generic content, lacking coherence, or failing to use appropriate tools. The Llama 2 13B model showed better understanding but lacked coherence for newsletter content. Some models like Llama 2 13B chat and text failed to produce any output, indicating limitations in understanding and task completion.",Unveiling My CREWAI Experiments: Leveraging AI Models with Varied Results,"In my recent experiments with CREWAI, I delved into trying 3 diverse projects, ranging from straightforward to intricate tasks. The main goal was to assign these tasks to a team of AI agents, each aimed at different objectives including examining a startup idea, building AI newsletters using Google SERP and Reddit Scraper, alongside developing an Email classifier. Through this venture, I explored numerous AI models, both through API calls like GPT-4 and Gemini Pro, as well as local models via Ollama, assessing their performance and output quality diligently.",Explore my journey with CREWAI experiments where I tasked AI agents with diverse projects like analyzing startup ideas and crafting AI newsletters. Discover the varied performance and output quality of different AI models tested through API calls and locally via Ollama. Dive into the world of AI experimentation with insights on model behavior and task understanding.,Collaborative AI Framework.,"Python





        6,974





        250


        Built by

          






        50 stars today",,,460,2023-10-30T20:14:08Z
2024-03-03,https://github.com/majacinka/crewai-experiments,https://raw.githubusercontent.com/smicallef/spiderfoot/master/README.md,"SpiderFoot is an open-source intelligence automation tool designed to analyze data from various sources. It features over 200 modules, supports a YAML-configurable correlation engine, and offers export options like CSV and JSON. Users can access it through a web-based UI or CLI. It allows for the extraction of diverse data types, including IP addresses, email addresses, social media accounts, and more. SpiderFoot integrates with external tools like SHODAN, HaveIBeenPwned, and Nmap. It supports Python 3 and is MIT-licensed. SpiderFoot can be used for offensive (red team exercises, pen testing) or defensive purposes. Additional features are available in SpiderFoot HX, a cloud-based managed solution. You can learn more on their website or join their community on Discord.",SpiderFoot: Open Source Intelligence Automation Tool,"SpiderFoot is an open source intelligence (OSINT) automation tool designed to aggregate and analyze data from various sources. It features a web-based UI and CLI interface making it easy to navigate and utilize the data seamlessly. Written in Python 3 and MIT-licensed, SpiderFoot offers over 200 modules for comprehensive data extraction and analysis. Whether used offensively or defensively, SpiderFoot can target various entities like IP addresses, domains, and even social media accounts to provide in-depth insights and analysis.","Discover how SpiderFoot, an open source intelligence tool, uses Python 3 and over 200 modules to gather and analyze data from diverse sources. Explore its features, uses, and installation process. Join the SpiderFoot community for discussions, tutorials, and more. Follow SpiderFoot on Twitter for the latest updates.",Cybersecurity Tool.,"Python





        460





        105


        Built by

          





        12 stars today",https://www.spiderfoot.net/wp-content/themes/spiderfoot/img/spiderfoot-wide.png; https://www.spiderfoot.net/wp-content/uploads/2022/04/opensource-screenshot-v4.png,,11365,2024-01-13T17:00:01Z
2024-03-04,https://github.com/lining808/CS-Ebook,https://raw.githubusercontent.com/lining808/CS-Ebook/main/README.md,"This text introduces a repository that contains a curated list of high-quality books on computer science and technology. The collection is constantly updated and covers most software-related fields. The main categories include:

- **Computer Basics**: Introduces books on fundamental topics like computer introduction, architecture, operating systems, computer networks, data structures, and algorithms.
- **Programming Languages**: Features books on various languages, including C, C++, C#, Rust, Java, Go, Python, SQL, JavaScript, PHP, Ruby, Matlab, and Latex.
- **Software Engineering**: Offers resources for roles like product managers and provides insights into software architecture and debugging/testing.
- **Mathematical Tools**: Lists books on basic and applied mathematics.
- **Big Data**: Includes books on data analysis and data mining.
- **Artificial Intelligence**: Covers machine learning, deep learning, reinforcement learning, etc.
- **Survival Guide**: Shares tips on surviving in the field, including advice on certifications, job interviews, etc.

The guide ensures quality over quantity and aims to include classic books for each direction. The books are recommended for their latest editions, though downloading links are not directly provided; it refers readers to the Z-Library for accessing a wider range of books.

The text also mentions that the entire book recommendations come from online sources and are meant for personal learning and reference. Finally, it touches upon some computer fundamentals with specific book recommendations for deeper learning, but does not go into the details of all categories mentioned.",Ultimate Guide for Aspiring Computer Scientists: Top Book Recommendations,"Discover a curated repository of high-quality computer science and technology books to advance your learning journey. Covering most software-related fields, this list is continually updated and meticulously organized. Dive into computer fundamentals, programming languages, software engineering, mathematical tools, big data, artificial intelligence, survival guides, and much more. Whether you're a beginner, an expert, or somewhere in between, these recommendations promise to enrich your understanding and skill set in the ever-evolving world of computing.","Explore an expertly curated list of computer science and technology books, updated regularly. It spans topics from basics to AI, making it perfect for learners at any stage.",Data Science Resources,"Python





        1,028





        89


        Built by

          





        79 stars today",https://raw.githubusercontent.com/lining808/CS-Ebook/main/images/bg.jpg; https://raw.githubusercontent.com/lining808/CS-Ebook/main/images/start.jpg; https://raw.githubusercontent.com/lining808/CS-Ebook/main/images/è®¡ç®—æœºæ¦‚è®º/å¤§è¯è®¡ç®—æœº å·1-3.jpg; https://raw.githubusercontent.com/lining808/CS-Ebook/main/images/è®¡ç®—æœºæ¦‚è®º/è®¡ç®—æœºç§‘å­¦æŠ€æœ¯ç™¾ç§‘å…¨ä¹¦ (ç¬¬ä¸‰ç‰ˆ).jpg; https://raw.githubusercontent.com/lining808/CS-Ebook/main/images/è®¡ç®—æœºæ¦‚è®º/è®¡ç®—æœºç§‘å­¦æ¦‚è®º (ç¬¬13ç‰ˆ).jpg; https://raw.githubusercontent.com/lining808/CS-Ebook/main/images/è®¡ç®—æœºæ¦‚è®º/è®¡ç®—æœºç§‘å­¦å¯¼è®ºï¼ˆç¬¬4ç‰ˆï¼‰.jpg; https://raw.githubusercontent.com/lining808/CS-Ebook/main/images/ç»„æˆåŽŸç†/è®¡ç®—æœºç»„æˆ  ç»“æž„åŒ–æ–¹æ³•ï¼ˆåŽŸä¹¦ç¬¬6ç‰ˆï¼‰.jpg; https://raw.githubusercontent.com/lining808/CS-Ebook/main/images/ç»„æˆåŽŸç†/è®¡ç®—æœºç»„æˆä¸Žè®¾è®¡ ç¡¬ä»¶è½¯ä»¶æŽ¥å£ (ç¬¬5ç‰ˆ).jpg; https://raw.githubusercontent.com/lining808/CS-Ebook/main/images/ç»„æˆåŽŸç†/è®¡ç®—æœºç»„æˆä¸Žè®¾è®¡ï¼šç¡¬ä»¶è½¯ä»¶æŽ¥å£ï¼ˆARMç‰ˆï¼‰.jpg; https://raw.githubusercontent.com/lining808/CS-Ebook/main/images/ç»„æˆåŽŸç†/è®¡ç®—æœºç»„æˆä¸Žè®¾è®¡ï¼šç¡¬ä»¶è½¯ä»¶æŽ¥å£ï¼ˆRISC-Vç‰ˆï¼‰.jpg; https://raw.githubusercontent.com/lining808/CS-Ebook/main/images/ç»„æˆåŽŸç†/æ‰‹æŠŠæ‰‹æ•™ä½ è®¾è®¡CPU-RISC-Vå¤„ç†å™¨ç¯‡.jpg; https://raw.githubusercontent.com/lining808/CS-Ebook/main/images/ç»„æˆåŽŸç†/ç”µè„‘ç»„è£…ã€ç»´æŠ¤ã€ç»´ä¿®å…¨èƒ½ä¸€æœ¬é€š.jpg; https://raw.githubusercontent.com/lining808/CS-Ebook/main/images/ç»„æˆåŽŸç†/è®¡ç®—æœºç»„è£…ä¸Žç»´æŠ¤.jpg; https://raw.githubusercontent.com/lining808/CS-Ebook/main/images/è®¡ç®—æœºç½‘ç»œ/è®¡ç®—æœºç½‘ç»œ (ç¬¬8ç‰ˆ).jpg; https://raw.githubusercontent.com/lining808/CS-Ebook/main/images/è®¡ç®—æœºç½‘ç»œ/è®¡ç®—æœºç½‘ç»œ è‡ªé¡¶å‘ä¸‹æ–¹æ³• (ç¬¬ä¸ƒç‰ˆ).jpg; https://raw.githubusercontent.com/lining808/CS-Ebook/main/images/è®¡ç®—æœºç½‘ç»œ/ç½‘ç»œæ˜¯æ€Žæ ·è¿žæŽ¥çš„.jpg; https://raw.githubusercontent.com/lining808/CS-Ebook/main/images/è®¡ç®—æœºç½‘ç»œ/TCP IPè¯¦è§£ (ç¬¬2ç‰ˆ).jpg; https://raw.githubusercontent.com/lining808/CS-Ebook/main/images/è®¡ç®—æœºç½‘ç»œ/è®¡ç®—æœºç½‘ç»œ ç³»ç»Ÿæ–¹æ³• (ç¬¬5ç‰ˆ).jpg; https://raw.githubusercontent.com/lining808/CS-Ebook/main/images/è®¡ç®—æœºç½‘ç»œ/å›¾è§£HTTP.jpg; https://raw.githubusercontent.com/lining808/CS-Ebook/main/images/è®¡ç®—æœºç½‘ç»œ/å›¾è§£TCPIPåè®®.jpg; https://raw.githubusercontent.com/lining808/CS-Ebook/main/images/æ“ä½œç³»ç»Ÿ/æ·±å…¥ç†è§£è®¡ç®—æœºç³»ç»Ÿï¼ˆåŽŸä¹¦ç¬¬3ç‰ˆï¼‰.jpg; https://raw.githubusercontent.com/lining808/CS-Ebook/main/images/æ“ä½œç³»ç»Ÿ/çŽ°ä»£æ“ä½œç³»ç»Ÿ (ç¬¬4ç‰ˆ).jpg; https://raw.githubusercontent.com/lining808/CS-Ebook/main/images/æ“ä½œç³»ç»Ÿ/æ“ä½œç³»ç»Ÿå¯¼è®º.jpg; https://raw.githubusercontent.com/lining808/CS-Ebook/main/images/ç®—æ³•ä¸Žæ•°æ®ç»“æž„/ç®—æ³•å¯¼è®ºï¼ˆåŽŸä¹¦ç¬¬3ç‰ˆï¼‰.jpg; https://raw.githubusercontent.com/lining808/CS-Ebook/main/images/ç®—æ³•ä¸Žæ•°æ®ç»“æž„/ç®—æ³•  (ç¬¬4ç‰ˆ).jpg; https://raw.githubusercontent.com/lining808/CS-Ebook/main/images/ç®—æ³•ä¸Žæ•°æ®ç»“æž„/è®¡ç®—æœºç¨‹åºè®¾è®¡è‰ºæœ¯1.jpg; https://raw.githubusercontent.com/lining808/CS-Ebook/main/images/ç®—æ³•ä¸Žæ•°æ®ç»“æž„/labuladongçš„ç®—æ³•å°æŠ„ .jpg; https://raw.githubusercontent.com/lining808/CS-Ebook/main/images/ç®—æ³•ä¸Žæ•°æ®ç»“æž„/LeetCode 101 (C++ Version).jpg; https://raw.githubusercontent.com/lining808/CS-Ebook/main/images/ç®—æ³•ä¸Žæ•°æ®ç»“æž„/ç¼–ç¨‹ç çŽ‘.jpg; https://raw.githubusercontent.com/lining808/CS-Ebook/main/images/ç®—æ³•ä¸Žæ•°æ®ç»“æž„/å¤§è¯æ•°æ®ç»“æž„ã€æº¢å½©åŠ å¼ºç‰ˆã€‘.jpg; https://raw.githubusercontent.com/lining808/CS-Ebook/main/images/ç®—æ³•ä¸Žæ•°æ®ç»“æž„/ç®—æ³•å›¾è§£.jpg; https://raw.githubusercontent.com/lining808/CS-Ebook/main/images/ç®—æ³•ä¸Žæ•°æ®ç»“æž„/æ¼«ç”»ç®—æ³• å°ç°çš„ç®—æ³•ä¹‹æ—….jpg; https://raw.githubusercontent.com/lining808/CS-Ebook/main/images/ç®—æ³•ä¸Žæ•°æ®ç»“æž„/æ•°æ®ç»“æž„ (ç¬¬3ç‰ˆ).jpg; https://raw.githubusercontent.com/lining808/CS-Ebook/main/images/ç®—æ³•ä¸Žæ•°æ®ç»“æž„/æ•°æ®ç»“æž„ä¸Žç®—æ³•åˆ†æž Cè¯­è¨€æè¿°ï¼ˆåŽŸä¹¦ç¬¬2ç‰ˆï¼‰.jpg; https://raw.githubusercontent.com/lining808/CS-Ebook/main/images/ç®—æ³•ä¸Žæ•°æ®ç»“æž„/æ•°æ®ç»“æž„ä¸Žç®—æ³•å›¾è§£.jpg; https://raw.githubusercontent.com/lining808/CS-Ebook/main/images/ç®—æ³•ä¸Žæ•°æ®ç»“æž„/ç®—æ³•ç¬”è®°.jpg; https://raw.githubusercontent.com/lining808/CS-Ebook/main/images/ç®—æ³•ä¸Žæ•°æ®ç»“æž„/ç®—æ³•ç²¾ç²¹.jpg; https://raw.githubusercontent.com/lining808/CS-Ebook/main/images/ç®—æ³•ä¸Žæ•°æ®ç»“æž„/ç®—æ³•è®¾è®¡ä¸Žåˆ†æžåŸºç¡€ (ç¬¬3ç‰ˆ).jpg; https://raw.githubusercontent.com/lining808/CS-Ebook/main/images/ç¼–ç¨‹å·¥å…·/PyCharm ä¸­æ–‡æŒ‡å—ï¼ˆWinç‰ˆï¼‰v2.0.jpg; https://raw.githubusercontent.com/lining808/CS-Ebook/main/images/ç¼–ç¨‹å·¥å…·/VSCodeæƒå¨æŒ‡å—.jpg; https://raw.githubusercontent.com/lining808/CS-Ebook/main/images/ç¼–ç¨‹å·¥å…·/ç²¾é€šGit (ç¬¬2ç‰ˆ).jpg; https://raw.githubusercontent.com/lining808/CS-Ebook/main/images/æ±‡ç¼–/ç¼–è¯‘åŽŸç† (ç¬¬2ç‰ˆ).jpg; https://raw.githubusercontent.com/lining808/CS-Ebook/main/images/C/Cç¨‹åºè®¾è®¡è¯­è¨€ï¼ˆç¬¬2ç‰ˆï¼‰.jpg; https://raw.githubusercontent.com/lining808/CS-Ebook/main/images/C/C Primer Plusï¼ˆç¬¬6ç‰ˆï¼‰.jpg; https://raw.githubusercontent.com/lining808/CS-Ebook/main/images/C/Cè¯­è¨€ç¨‹åºè®¾è®¡ çŽ°ä»£æ–¹æ³• (ç¬¬2ç‰ˆ.ä¿®è®¢ç‰ˆ).jpg; https://raw.githubusercontent.com/lining808/CS-Ebook/main/images/C/Cå’ŒæŒ‡é’ˆ.jpg; https://raw.githubusercontent.com/lining808/CS-Ebook/main/images/Cpp/C++ Primer (ç¬¬5ç‰ˆ).jpg; https://raw.githubusercontent.com/lining808/CS-Ebook/main/images/Cpp/C++ Primerä¹ é¢˜é›†ï¼ˆç¬¬5ç‰ˆï¼‰.jpg; https://raw.githubusercontent.com/lining808/CS-Ebook/main/images/Cpp/C++ Primer Plus (ç¬¬6ç‰ˆ).jpg; https://raw.githubusercontent.com/lining808/CS-Ebook/main/images/Cpp/C++æ ‡å‡†åº“ (ç¬¬2ç‰ˆ) .jpg; https://raw.githubusercontent.com/lining808/CS-Ebook/main/images/Cpp/C++ç¨‹åºè®¾è®¡è¯­è¨€ï¼ˆç‰¹åˆ«ç‰ˆï¼‰.jpg; https://raw.githubusercontent.com/lining808/CS-Ebook/main/images/Cpp/C++ç¨‹åºè®¾è®¡è¯­è¨€ ç¬¬1ï½ž3éƒ¨åˆ†ï¼ˆç¬¬4ç‰ˆï¼‰.jpg; https://raw.githubusercontent.com/lining808/CS-Ebook/main/images/Cpp/C++ç¨‹åºè®¾è®¡è¯­è¨€ ç¬¬4éƒ¨åˆ†ï¼ˆç¬¬4ç‰ˆï¼‰.jpg; https://raw.githubusercontent.com/lining808/CS-Ebook/main/images/Cpp/C++20é«˜çº§ç¼–ç¨‹ï¼ˆç¬¬5ç‰ˆï¼‰.jpg; https://raw.githubusercontent.com/lining808/CS-Ebook/main/images/Cpp/Effective Modern C++.jpg; https://raw.githubusercontent.com/lining808/CS-Ebook/main/images/Cpp/More Effective C++.jpg; https://raw.githubusercontent.com/lining808/CS-Ebook/main/images/Cpp/æ˜Žè§£C++.jpg; https://raw.githubusercontent.com/lining808/CS-Ebook/main/images/Cpp/C++ Templates (ç¬¬2ç‰ˆÂ·ä¸­æ–‡ç‰ˆ).jpg; https://raw.githubusercontent.com/lining808/CS-Ebook/main/images/Csharp/æ·±å…¥ç†è§£Cï¼ˆç¬¬3ç‰ˆï¼‰.jpg; https://raw.githubusercontent.com/lining808/CS-Ebook/main/images/Csharp/C å›¾è§£æ•™ç¨‹  (ç¬¬5ç‰ˆ).jpg; https://raw.githubusercontent.com/lining808/CS-Ebook/main/images/R/Rè¯­è¨€å®žæˆ˜ï¼ˆç¬¬3ç‰ˆï¼‰.jpg; https://raw.githubusercontent.com/lining808/CS-Ebook/main/images/Rust/Rust ç¨‹åºè®¾è®¡ï¼ˆç¬¬2ç‰ˆï¼‰.jpg; https://raw.githubusercontent.com/lining808/CS-Ebook/main/images/Rust/ç²¾é€šRust(ç¬¬2ç‰ˆ).jpg; https://raw.githubusercontent.com/lining808/CS-Ebook/main/images/Java/Javaç¼–ç¨‹æ€æƒ³ (ç¬¬5ç‰ˆ).jpg; https://raw.githubusercontent.com/lining808/CS-Ebook/main/images/Java/æ·±å…¥ç†è§£Javaè™šæ‹Ÿæœºï¼ˆç¬¬3ç‰ˆï¼‰.jpg; https://raw.githubusercontent.com/lining808/CS-Ebook/main/images/Java/Javaæ ¸å¿ƒæŠ€æœ¯Â·å·Iï¼ˆåŽŸä¹¦ç¬¬12ç‰ˆï¼‰.jpg; https://raw.githubusercontent.com/lining808/CS-Ebook/main/images/Java/Javaå®žæˆ˜ (ç¬¬2ç‰ˆ).jpg; https://raw.githubusercontent.com/lining808/CS-Ebook/main/images/Java/Effective Java (ç¬¬3ç‰ˆ).jpg; https://raw.githubusercontent.com/lining808/CS-Ebook/main/images/Java/spring boot Vue3.jpg; https://raw.githubusercontent.com/lining808/CS-Ebook/main/images/Java/spring bootå®žæˆ˜ï¼š.jpg; https://raw.githubusercontent.com/lining808/CS-Ebook/main/images/Java/Spring Bootå®žæˆ˜.jpg; https://raw.githubusercontent.com/lining808/CS-Ebook/main/images/Java/Springå®žæˆ˜ï¼ˆç¬¬6ç‰ˆï¼‰.jpg; https://raw.githubusercontent.com/lining808/CS-Ebook/main/images/Java/Springå¾®æœåŠ¡å®žæˆ˜ï¼ˆç¬¬2ç‰ˆï¼‰.jpg; https://raw.githubusercontent.com/lining808/CS-Ebook/main/images/Java/Kafkaæƒå¨æŒ‡å—ï¼ˆç¬¬2ç‰ˆï¼‰.jpg; https://raw.githubusercontent.com/lining808/CS-Ebook/main/images/Java/æ·±å…¥ç†è§£Kafkaï¼šæ ¸å¿ƒè®¾è®¡ä¸Žå®žè·µåŽŸç†.jpg; https://raw.githubusercontent.com/lining808/CS-Ebook/main/images/Java/MyBatisä»Žå…¥é—¨åˆ°ç²¾é€š.jpg; https://raw.githubusercontent.com/lining808/CS-Ebook/main/images/Go/Goè¯­è¨€åœ£ç».jpg; https://raw.githubusercontent.com/lining808/CS-Ebook/main/images/Go/Goè¯­è¨€å­¦ä¹ ç¬”è®°.jpg; https://raw.githubusercontent.com/lining808/CS-Ebook/main/images/Python/Effect Python.jpg; https://raw.githubusercontent.com/lining808/CS-Ebook/main/images/Python/Flash Webå¼€å‘ (ç¬¬2ç‰ˆ).jpg; https://raw.githubusercontent.com/lining808/CS-Ebook/main/images/Python/Flask Webå¼€å‘å®žæˆ˜.jpg; https://raw.githubusercontent.com/lining808/CS-Ebook/main/images/Python/Pandasæ•°æ®å¤„ç†ä¸Žåˆ†æž.jpg; https://raw.githubusercontent.com/lining808/CS-Ebook/main/images/Python/Python asyncio å¹¶å‘ç¼–ç¨‹.jpg; https://raw.githubusercontent.com/lining808/CS-Ebook/main/images/Python/Python Qt GUIä¸Žæ•°æ®å¯è§†åŒ–ç¼–ç¨‹.jpg; https://raw.githubusercontent.com/lining808/CS-Ebook/main/images/Python/Python3ç½‘ç»œçˆ¬è™«å¼€å‘å®žæˆ˜ ç¬¬2ç‰ˆ.jpg; https://raw.githubusercontent.com/lining808/CS-Ebook/main/images/Python/Pythonç¼–ç¨‹ï¼šä»Žå…¥é—¨åˆ°å®žè·µï¼ˆç¬¬3ç‰ˆï¼‰.jpg; https://raw.githubusercontent.com/lining808/CS-Ebook/main/images/Python/PythonåŸºç¡€æ•™ç¨‹ (ç¬¬3ç‰ˆ).jpg; https://raw.githubusercontent.com/lining808/CS-Ebook/main/images/Python/Pythonè®©ç¹çå·¥ä½œè‡ªåŠ¨åŒ–.jpg; https://raw.githubusercontent.com/lining808/CS-Ebook/main/images/Python/Pythonç½‘ç»œçˆ¬è™«æƒå¨æŒ‡å— (ç¬¬2ç‰ˆ).jpg; https://raw.githubusercontent.com/lining808/CS-Ebook/main/images/Python/Selenium3è‡ªåŠ¨åŒ–æµ‹è¯•å®žæˆ˜.jpg; https://raw.githubusercontent.com/lining808/CS-Ebook/main/images/Python/SQLAlchemy Pythonæ•°æ®åº“å®žæˆ˜.jpg; https://raw.githubusercontent.com/lining808/CS-Ebook/main/images/Python/æµç•…çš„ Pythonï¼ˆç¬¬2ç‰ˆï¼‰.jpg; https://raw.githubusercontent.com/lining808/CS-Ebook/main/images/Python/æ˜Žè§£Python.jpg; https://raw.githubusercontent.com/lining808/CS-Ebook/main/images/SQL/MySQLåŸºç¡€æ•™ç¨‹.jpg; https://raw.githubusercontent.com/lining808/CS-Ebook/main/images/SQL/MySQLæ˜¯æ€Žæ ·è¿è¡Œçš„.jpg; https://raw.githubusercontent.com/lining808/CS-Ebook/main/images/SQL/SQLå¿…çŸ¥å¿…ä¼š (ç¬¬5ç‰ˆ).jpg; https://raw.githubusercontent.com/lining808/CS-Ebook/main/images/SQL/SQLåŸºç¡€æ•™ç¨‹ (ç¬¬2ç‰ˆ).jpg; https://raw.githubusercontent.com/lining808/CS-Ebook/main/images/SQL/SQLè¿›é˜¶æ•™ç¨‹.jpg; https://raw.githubusercontent.com/lining808/CS-Ebook/main/images/SQL/é«˜æ€§èƒ½MYSQLï¼ˆç¬¬3ç‰ˆ).jpg; https://raw.githubusercontent.com/lining808/CS-Ebook/main/images/SQL/é«˜æ€§èƒ½MYSQLï¼ˆç¬¬å››ç‰ˆï¼‰.jpg; https://raw.githubusercontent.com/lining808/CS-Ebook/main/images/SQL/æ•°æ®åº“ç³»ç»Ÿæ¦‚å¿µ (ç¬¬6ç‰ˆ).jpg; https://raw.githubusercontent.com/lining808/CS-Ebook/main/images/SQL/Rediså¼€å‘ä¸Žè¿ç»´.jpg; https://raw.githubusercontent.com/lining808/CS-Ebook/main/images/SQL/Redisè®¾è®¡ä¸Žå®žçŽ°.jpg; https://raw.githubusercontent.com/lining808/CS-Ebook/main/images/SQL/MongoDBå®žæˆ˜  (ç¬¬2ç‰ˆ).jpg; https://raw.githubusercontent.com/lining808/CS-Ebook/main/images/SQL/SQL Serverä»Žå…¥é—¨åˆ°ç²¾é€š.jpg; https://raw.githubusercontent.com/lining808/CS-Ebook/main/images/SQL/æ”¶èŽ·ä¸æ­¢Oracle ç¬¬2ç‰ˆ.jpg; https://raw.githubusercontent.com/lining808/CS-Ebook/main/images/SQL/PostgreSQL æŠ€æœ¯å†…å¹•.jpg; https://raw.githubusercontent.com/lining808/CS-Ebook/main/images/æ­£åˆ™/æ­£åˆ™è¡¨è¾¾å¼å¿…çŸ¥å¿…ä¼š (ä¿®è®¢ç‰ˆ).jpg; https://raw.githubusercontent.com/lining808/CS-Ebook/main/images/æ­£åˆ™/æ­£åˆ™æŒ‡å¼•ï¼ˆç¬¬2ç‰ˆï¼‰.jpg; https://raw.githubusercontent.com/lining808/CS-Ebook/main/images/æ±‡ç¼–/æ±‡ç¼–è¯­è¨€ (ç¬¬4ç‰ˆ).jpg; https://raw.githubusercontent.com/lining808/CS-Ebook/main/images/Ruby/Rubyå…ƒç¼–ç¨‹ .jpg; https://raw.githubusercontent.com/lining808/CS-Ebook/main/images/JavaScript/ä½ ä¸çŸ¥é“çš„JavaScript.jpg; https://raw.githubusercontent.com/lining808/CS-Ebook/main/images/JavaScript/JavaScripté«˜çº§ç¨‹åºè®¾è®¡ (ç¬¬4ç‰ˆ).jpg; https://raw.githubusercontent.com/lining808/CS-Ebook/main/images/JavaScript/JavaScriptæƒå¨æŒ‡å— (ç¬¬7ç‰ˆ).jpg; https://raw.githubusercontent.com/lining808/CS-Ebook/main/images/JavaScript/vue.jpg; https://raw.githubusercontent.com/lining808/CS-Ebook/main/images/JavaScript/æ·±å…¥è§£æžCSS.jpg; https://raw.githubusercontent.com/lining808/CS-Ebook/main/images/JavaScript/CSSä¸–ç•Œ.jpg; https://raw.githubusercontent.com/lining808/CS-Ebook/main/images/JavaScript/CSSæ–°ä¸–ç•Œ.jpg; https://raw.githubusercontent.com/lining808/CS-Ebook/main/images/JavaScript/CSSé€‰æ‹©å™¨ä¸–ç•Œ.jpg; https://raw.githubusercontent.com/lining808/CS-Ebook/main/images/JavaScript/æ·±å…¥æµ…å‡ºNode.jpg; https://raw.githubusercontent.com/lining808/CS-Ebook/main/images/JavaScript/å°ç¨‹åºå¼€å‘åŽŸç†ä¸Žå®žæˆ˜.jpg; https://raw.githubusercontent.com/lining808/CS-Ebook/main/images/JavaScript/jQueryå®žæˆ˜ï¼ˆç¬¬ä¸‰ç‰ˆï¼‰.jpg; https://raw.githubusercontent.com/lining808/CS-Ebook/main/images/JavaScript/TypeScriptç¼–ç¨‹.jpg; https://raw.githubusercontent.com/lining808/CS-Ebook/main/images/JavaScript/æ­ç§˜Angularï¼ˆç¬¬2ç‰ˆï¼‰.jpg; https://raw.githubusercontent.com/lining808/CS-Ebook/main/images/JavaScript/æ·±å…¥ReactæŠ€æœ¯æ ˆ.jpg; https://raw.githubusercontent.com/lining808/CS-Ebook/main/images/JavaScript/æ·±å…¥ç†è§£ES6.jpg; https://raw.githubusercontent.com/lining808/CS-Ebook/main/images/Linux/Linux UNIXç³»ç»Ÿç¼–ç¨‹æ‰‹å†Œ.jpg; https://raw.githubusercontent.com/lining808/CS-Ebook/main/images/Linux/Linuxå¸¸ç”¨å‘½ä»¤è‡ªå­¦æ‰‹å†Œ.jpg; https://raw.githubusercontent.com/lining808/CS-Ebook/main/images/Linux/Linuxå‘½ä»¤è¡Œä¸ŽShellè„šæœ¬ç¼–ç¨‹å¤§å…¨ (ç¬¬4ç‰ˆ).jpg; https://raw.githubusercontent.com/lining808/CS-Ebook/main/images/Linux/Linuxå‘½ä»¤è¡Œå¤§å…¨ï¼ˆç¬¬2ç‰ˆï¼‰.jpg; https://raw.githubusercontent.com/lining808/CS-Ebook/main/images/Linux/Unix&Liunxå¤§å­¦æ•™ç¨‹.jpg; https://raw.githubusercontent.com/lining808/CS-Ebook/main/images/Linux/UNIXçŽ¯å¢ƒé«˜çº§ç¼–ç¨‹ (ç¬¬3ç‰ˆ).jpg; https://raw.githubusercontent.com/lining808/CS-Ebook/main/images/Linux/UNIXç¼–ç¨‹è‰ºæœ¯.jpg; https://raw.githubusercontent.com/lining808/CS-Ebook/main/images/Linux/UNIXç½‘ç»œç¼–ç¨‹ å·1 (ç¬¬3ç‰ˆ).jpg; https://raw.githubusercontent.com/lining808/CS-Ebook/main/images/Linux/UNIXç½‘ç»œç¼–ç¨‹ å·2 (ç¬¬2ç‰ˆ).jpg; https://raw.githubusercontent.com/lining808/CS-Ebook/main/images/Linux/æ·±å…¥Linuxå†…æ ¸æž¶æž„.jpg; https://raw.githubusercontent.com/lining808/CS-Ebook/main/images/Linux/é¸Ÿå“¥çš„Linuxç§æˆ¿èœ (ç¬¬3ç‰ˆ).jpg; https://raw.githubusercontent.com/lining808/CS-Ebook/main/images/Linux/é¸Ÿå“¥çš„Linuxç§æˆ¿èœ (ç¬¬4ç‰ˆ).jpg; https://raw.githubusercontent.com/lining808/CS-Ebook/main/images/Linux/Vimå®žç”¨æŠ€å·§ (ç¬¬2ç‰ˆ).jpg; https://raw.githubusercontent.com/lining808/CS-Ebook/main/images/Linux/Ubuntu Linuxæ“ä½œç³»ç»Ÿï¼šå¾®è¯¾ç‰ˆ.jpg; https://raw.githubusercontent.com/lining808/CS-Ebook/main/images/Linux/Linuxç½‘ç»œæ“ä½œç³»ç»Ÿé¡¹ç›®æ•™ç¨‹ï¼ˆRHEL 7.4CentOS 7.4ï¼‰ï¼ˆç¬¬3ç‰ˆï¼‰.jpg; https://raw.githubusercontent.com/lining808/CS-Ebook/main/images/Latex/Latex Notes é›·å¤ªèµ«æŽ’ç‰ˆç³»ç»Ÿç®€ä»‹.jpg; https://raw.githubusercontent.com/lining808/CS-Ebook/main/images/PHP/Modern PHP  ä¸­æ–‡ç‰ˆ.jpg; https://raw.githubusercontent.com/lining808/CS-Ebook/main/images/MATLAB/MATLABä»Žå…¥é—¨åˆ°ç²¾é€š.jpg; https://raw.githubusercontent.com/lining808/CS-Ebook/main/images/Swift/Swiftè¿›é˜¶.jpg; https://raw.githubusercontent.com/lining808/CS-Ebook/main/images/Kotlin/Androidç¼–ç¨‹æƒå¨æŒ‡å—.jpg; https://raw.githubusercontent.com/lining808/CS-Ebook/main/images/Kotlin/kotlinå®žæˆ˜.jpg; https://raw.githubusercontent.com/lining808/CS-Ebook/main/images/äº§å“ç»ç†/äººäººéƒ½æ˜¯äº§å“ç»ç†2.jpg; https://raw.githubusercontent.com/lining808/CS-Ebook/main/images/æž¶æž„è®¾è®¡/å¤§è¯è®¾è®¡æ¨¡å¼.jpg; https://raw.githubusercontent.com/lining808/CS-Ebook/main/images/æž¶æž„è®¾è®¡/å‡¤å‡°æž¶æž„.jpg; https://raw.githubusercontent.com/lining808/CS-Ebook/main/images/æž¶æž„è®¾è®¡/æž¶æž„æ•´æ´ä¹‹é“.jpg; https://raw.githubusercontent.com/lining808/CS-Ebook/main/images/æž¶æž„è®¾è®¡/è®¾è®¡æ¨¡å¼ å¯å¤ç”¨é¢å‘å¯¹è±¡è½¯ä»¶çš„åŸºç¡€ï¼ˆå…¸è—ç‰ˆï¼‰.jpg; https://raw.githubusercontent.com/lining808/CS-Ebook/main/images/æž¶æž„è®¾è®¡/è®¾è®¡æ¨¡å¼çš„è‰ºæœ¯ï¼šè½¯ä»¶å¼€å‘äººå‘˜å†…åŠŸä¿®ç‚¼ä¹‹é“.jpg; https://raw.githubusercontent.com/lining808/CS-Ebook/main/images/æž¶æž„è®¾è®¡/è®¾è®¡æ¨¡å¼ä¹‹ç¾Ž.jpg; https://raw.githubusercontent.com/lining808/CS-Ebook/main/images/æž¶æž„è®¾è®¡/å›¾è§£è®¾è®¡æ¨¡å¼.jpg; https://raw.githubusercontent.com/lining808/CS-Ebook/main/images/æž¶æž„è®¾è®¡/å¾®æœåŠ¡æž¶æž„è®¾è®¡æ¨¡å¼.jpg; https://raw.githubusercontent.com/lining808/CS-Ebook/main/images/æž¶æž„è®¾è®¡/è½¯ä»¶å·¥ç¨‹ ï¼ˆç¬¬10ç‰ˆï¼‰.jpg; https://raw.githubusercontent.com/lining808/CS-Ebook/main/images/æž¶æž„è®¾è®¡/å†™ç»™å¤§å®¶çœ‹çš„è®¾è®¡ä¹¦ï¼ˆç¬¬4ç‰ˆï¼‰ï¼ˆå¹³è£…ï¼‰.jpg; https://raw.githubusercontent.com/lining808/CS-Ebook/main/images/æž¶æž„è®¾è®¡/æ¸¸æˆå¼•æ“Žæž¶æž„ï¼ˆç¬¬2ç‰ˆï¼‰.jpg; https://raw.githubusercontent.com/lining808/CS-Ebook/main/images/æž¶æž„è®¾è®¡/ä»£ç éšæƒ³å½• å…«è‚¡æ–‡.jpg; https://raw.githubusercontent.com/lining808/CS-Ebook/main/images/K8S/Docker å®¹å™¨ä¸Žå®¹å™¨äº‘ï¼ˆç¬¬2ç‰ˆï¼‰.jpg; https://raw.githubusercontent.com/lining808/CS-Ebook/main/images/K8S/Kubernetesä¿®ç‚¼æ‰‹å†Œ.jpg; https://raw.githubusercontent.com/lining808/CS-Ebook/main/images/K8S/kubernetæƒå¨æŒ‡å—.jpg; https://raw.githubusercontent.com/lining808/CS-Ebook/main/images/K8S/æ·±å…¥å‰–æžKubernetes.jpg; https://raw.githubusercontent.com/lining808/CS-Ebook/main/images/K8S/æ·±å…¥æµ…å‡ºDocker.jpg; https://raw.githubusercontent.com/lining808/CS-Ebook/main/images/æµ‹è¯•è¿ç»´/å…¨æ ˆæ€§èƒ½æµ‹è¯•ä¿®ç‚¼å®å…¸JMeterå®žæˆ˜.jpg; https://raw.githubusercontent.com/lining808/CS-Ebook/main/images/æµ‹è¯•è¿ç»´/è½¯ä»¶è°ƒè¯•.jpg; https://raw.githubusercontent.com/lining808/CS-Ebook/main/images/K8S/DevOpså®žè·µæŒ‡å—.jpg; https://raw.githubusercontent.com/lining808/CS-Ebook/main/images/K8S/æŒç»­äº¤ä»˜  å‘å¸ƒå¯é è½¯ä»¶çš„ç³»ç»Ÿæ–¹æ³•.jpg; https://raw.githubusercontent.com/lining808/CS-Ebook/main/images/åº”ç”¨æ•°å­¦/ç¨‹åºå‘˜çš„æ•°å­¦ (ç¬¬2ç‰ˆ).jpg; https://raw.githubusercontent.com/lining808/CS-Ebook/main/images/åº”ç”¨æ•°å­¦/ç¨‹åºå‘˜çš„æ•°å­¦ 2 æ¦‚çŽ‡ç»Ÿè®¡.jpg; https://raw.githubusercontent.com/lining808/CS-Ebook/main/images/åº”ç”¨æ•°å­¦/ç¨‹åºå‘˜çš„æ•°å­¦ 3 çº¿æ€§ä»£æ•°.jpg; https://raw.githubusercontent.com/lining808/CS-Ebook/main/images/åº”ç”¨æ•°å­¦/ç¨‹åºå‘˜æ•°å­¦.jpg; https://raw.githubusercontent.com/lining808/CS-Ebook/main/images/åº”ç”¨æ•°å­¦/ä»Žé›¶å¼€å§‹ï¼šæœºå™¨å­¦ä¹ çš„æ•°å­¦åŽŸç†å’Œç®—æ³•å®žè·µ.jpg; https://raw.githubusercontent.com/lining808/CS-Ebook/main/images/åº”ç”¨æ•°å­¦/æ”¹å˜ä¸–ç•Œçš„17ä¸ªæ–¹ç¨‹.jpg; https://raw.githubusercontent.com/lining808/CS-Ebook/main/images/åº”ç”¨æ•°å­¦/æœºå™¨å­¦ä¹ çš„æ•°å­¦.jpg; https://raw.githubusercontent.com/lining808/CS-Ebook/main/images/åº”ç”¨æ•°å­¦/è®¡ç®—æœºç§‘å­¦ä¸­çš„æ•°å­¦ï¼šä¿¡æ¯ä¸Žæ™ºèƒ½æ—¶ä»£çš„å¿…ä¿®è¯¾.jpg; https://raw.githubusercontent.com/lining808/CS-Ebook/main/images/åº”ç”¨æ•°å­¦/å…·ä½“æ•°å­¦ è®¡ç®—æœºç§‘å­¦åŸºç¡€ (ç¬¬2ç‰ˆ).jpg; https://raw.githubusercontent.com/lining808/CS-Ebook/main/images/åº”ç”¨æ•°å­¦/æ·±åº¦å­¦ä¹ çš„æ•°å­¦.jpg; https://raw.githubusercontent.com/lining808/CS-Ebook/main/images/åº”ç”¨æ•°å­¦/æ•°å­¦ä¹‹ç¾Žï¼ˆç¬¬ä¸‰ç‰ˆï¼‰.jpg; https://raw.githubusercontent.com/lining808/CS-Ebook/main/images/åº”ç”¨æ•°å­¦/ç»Ÿè®¡å­¦ä¹ æ–¹æ³• (ç¬¬2ç‰ˆ).jpg; https://raw.githubusercontent.com/lining808/CS-Ebook/main/images/åº”ç”¨æ•°å­¦/å´å†›æ•°å­¦é€šè¯†è®²ä¹‰.jpg; https://raw.githubusercontent.com/lining808/CS-Ebook/main/images/é«˜ç­‰æ•°å­¦/çº¯æ•°å­¦æ•™ç¨‹ (ç¬¬9ç‰ˆ).jpg; https://raw.githubusercontent.com/lining808/CS-Ebook/main/images/é«˜ç­‰æ•°å­¦/å¤åˆ†æž å¯è§†åŒ–æ–¹æ³•.jpg; https://raw.githubusercontent.com/lining808/CS-Ebook/main/images/é«˜ç­‰æ•°å­¦/æ¦‚çŽ‡å¯¼è®º (ç¬¬2ç‰ˆ).jpg; https://raw.githubusercontent.com/lining808/CS-Ebook/main/images/é«˜ç­‰æ•°å­¦/çº¿æ€§ä»£æ•°åŠå…¶åº”ç”¨ (ç¬¬4ç‰ˆ).jpg; https://raw.githubusercontent.com/lining808/CS-Ebook/main/images/é«˜ç­‰æ•°å­¦/çº¿æ€§ä»£æ•°åº”è¯¥è¿™æ ·å­¦ (ç¬¬3ç‰ˆ).jpg; https://raw.githubusercontent.com/lining808/CS-Ebook/main/images/é«˜ç­‰æ•°å­¦/ç¦»æ•£æ•°å­¦åŠå…¶åº”ç”¨ï¼ˆåŽŸä¹¦ç¬¬8ç‰ˆï¼‰.jpg; https://raw.githubusercontent.com/lining808/CS-Ebook/main/images/é«˜ç­‰æ•°å­¦/ç»„åˆæ•°å­¦ (ç¬¬5ç‰ˆ).jpg; https://raw.githubusercontent.com/lining808/CS-Ebook/main/images/é«˜ç­‰æ•°å­¦/æ™®æž—æ–¯é¡¿æ¦‚çŽ‡è®ºè¯»æœ¬.jpg; https://raw.githubusercontent.com/lining808/CS-Ebook/main/images/é«˜ç­‰æ•°å­¦/æ™®æž—æ–¯é¡¿æ•°å­¦åˆ†æžè¯»æœ¬.jpg; https://raw.githubusercontent.com/lining808/CS-Ebook/main/images/é«˜ç­‰æ•°å­¦/æ™®æž—æ–¯é¡¿å¾®ç§¯åˆ†è¯»æœ¬ (ä¿®è®¢ç‰ˆ).jpg; https://raw.githubusercontent.com/lining808/CS-Ebook/main/images/æ•°æ®åˆ†æž/Hadoopæƒå¨æŒ‡å—.jpg; https://raw.githubusercontent.com/lining808/CS-Ebook/main/images/æ•°æ®åˆ†æž/Pythonæ•°æ®ç§‘å­¦æ‰‹å†Œ.jpg; https://raw.githubusercontent.com/lining808/CS-Ebook/main/images/æ•°æ®åˆ†æž/åˆ©ç”¨Pythonè¿›è¡Œæ•°æ®åˆ†æž åŽŸä¹¦ç¬¬2ç‰ˆ.jpg; https://raw.githubusercontent.com/lining808/CS-Ebook/main/images/æ•°æ®åˆ†æž/Pythoné‡‘èžå¤§æ•°æ®åˆ†æž (ç¬¬2ç‰ˆ).jpg; https://raw.githubusercontent.com/lining808/CS-Ebook/main/images/æ•°æ®æŒ–æŽ˜/æ•°æ®å¯†é›†åž‹åº”ç”¨ç³»ç»Ÿè®¾è®¡.jpg; https://raw.githubusercontent.com/lining808/CS-Ebook/main/images/æ•°æ®æŒ–æŽ˜/æ•°æ®æŒ–æŽ˜ æ¦‚å¿µä¸ŽæŠ€æœ¯ (ç¬¬3ç‰ˆ).jpg; https://raw.githubusercontent.com/lining808/CS-Ebook/main/images/æ•°æ®æŒ–æŽ˜/æ•°æ®æŒ–æŽ˜å¯¼è®º (å®Œæ•´ç‰ˆ).jpg; https://raw.githubusercontent.com/lining808/CS-Ebook/main/images/æœºå™¨å­¦ä¹ /ç™¾é¢æœºå™¨å­¦ä¹ .jpg; https://raw.githubusercontent.com/lining808/CS-Ebook/main/images/æœºå™¨å­¦ä¹ /åŠ¨æ‰‹å­¦æœºå™¨å­¦ä¹ .jpg; https://raw.githubusercontent.com/lining808/CS-Ebook/main/images/æœºå™¨å­¦ä¹ /æœºå™¨å­¦ä¹  (ç¬¬2ç‰ˆ).jpg; https://raw.githubusercontent.com/lining808/CS-Ebook/main/images/æœºå™¨å­¦ä¹ /æœºå™¨å­¦ä¹  å…¬å¼æŽ¨åˆ°ä¸Žä»£ç å®žçŽ°.jpg; https://raw.githubusercontent.com/lining808/CS-Ebook/main/images/æœºå™¨å­¦ä¹ /æœºå™¨å­¦ä¹ .jpg; https://raw.githubusercontent.com/lining808/CS-Ebook/main/images/æœºå™¨å­¦ä¹ /æœºå™¨å­¦ä¹ Pythonå®žæˆ˜.jpg; https://raw.githubusercontent.com/lining808/CS-Ebook/main/images/æœºå™¨å­¦ä¹ /æœºå™¨å­¦ä¹ ç¬”è®°(å´æ©è¾¾)v5.51.jpg; https://raw.githubusercontent.com/lining808/CS-Ebook/main/images/æœºå™¨å­¦ä¹ /æœºå™¨å­¦ä¹ å…¬å¼è¯¦è§£.jpg; https://raw.githubusercontent.com/lining808/CS-Ebook/main/images/æœºå™¨å­¦ä¹ /æœºå™¨å­¦ä¹ å®žæˆ˜ï¼šåŸºäºŽScikit-Learnã€Keraså’ŒTensorFlow (ç¬¬2ç‰ˆ).jpg; https://raw.githubusercontent.com/lining808/CS-Ebook/main/images/æœºå™¨å­¦ä¹ /ç¾Žå›¢æœºå™¨å­¦ä¹ å®žè·µ.jpg; https://raw.githubusercontent.com/lining808/CS-Ebook/main/images/æœºå™¨å­¦ä¹ /å¯è§£é‡Šäººå·¥æ™ºèƒ½å¯¼è®º.jpg; https://raw.githubusercontent.com/lining808/CS-Ebook/main/images/æœºå™¨å­¦ä¹ /äººå·¥æ™ºèƒ½ï¼šçŽ°ä»£æ–¹æ³•ï¼ˆç¬¬4ç‰ˆï¼‰.jpg; https://raw.githubusercontent.com/lining808/CS-Ebook/main/images/æœºå™¨å­¦ä¹ /å®žç”¨æŽ¨èç³»ç»Ÿ.jpg; https://raw.githubusercontent.com/lining808/CS-Ebook/main/images/æœºå™¨å­¦ä¹ /é¸¢å°¾èŠ±ä¹¦.jpg; https://raw.githubusercontent.com/lining808/CS-Ebook/main/images/æœºå™¨å­¦ä¹ /AIè¡Œä¸šæŠ¥å‘Š2023.jpg; https://raw.githubusercontent.com/lining808/CS-Ebook/main/images/æ·±åº¦å­¦ä¹ /Pythonæ·±åº¦å­¦ä¹ ï¼ˆç¬¬2ç‰ˆï¼‰.jpg; https://raw.githubusercontent.com/lining808/CS-Ebook/main/images/æ·±åº¦å­¦ä¹ /Pytorch æ·±åº¦å­¦ä¹ å®žæˆ˜.jpg; https://raw.githubusercontent.com/lining808/CS-Ebook/main/images/æ·±åº¦å­¦ä¹ /åŠ¨æ‰‹å­¦æ·±åº¦å­¦ä¹  (ç¬¬2ç‰ˆ).jpg; https://raw.githubusercontent.com/lining808/CS-Ebook/main/images/æ·±åº¦å­¦ä¹ /æ·±åº¦å­¦ä¹ 500é—® .jpg; https://raw.githubusercontent.com/lining808/CS-Ebook/main/images/æ·±åº¦å­¦ä¹ /æ·±åº¦å­¦ä¹ åŽŸç†ä¸Žpytorchå®žæˆ˜ (ç¬¬2ç‰ˆ).jpg; https://raw.githubusercontent.com/lining808/CS-Ebook/main/images/æ·±åº¦å­¦ä¹ /Pythonæ·±åº¦å­¦ä¹ .jpg; https://raw.githubusercontent.com/lining808/CS-Ebook/main/images/æ·±åº¦å­¦ä¹ /Pytorch1.11.0å®˜æ–¹æ•™ç¨‹ä¸­æ–‡ç‰ˆ.jpg; https://raw.githubusercontent.com/lining808/CS-Ebook/main/images/æ·±åº¦å­¦ä¹ /æŽå®æ¯…æ·±åº¦å­¦ä¹ æ•™ç¨‹.jpg; https://raw.githubusercontent.com/lining808/CS-Ebook/main/images/æ·±åº¦å­¦ä¹ /æ·±åº¦å­¦ä¹ ç¬”è®°(å´æ©è¾¾)v5.72.jpg; https://raw.githubusercontent.com/lining808/CS-Ebook/main/images/æ·±åº¦å­¦ä¹ /æ·±åº¦å­¦ä¹ åŽŸç†ä¸Žå®žè·µ.jpg; https://raw.githubusercontent.com/lining808/CS-Ebook/main/images/æ·±åº¦å­¦ä¹ /Pythonç¥žç»ç½‘ç»œç¼–ç¨‹.jpg; https://raw.githubusercontent.com/lining808/CS-Ebook/main/images/æ·±åº¦å­¦ä¹ /TensorFlowæ·±åº¦å­¦ä¹ .jpg; https://raw.githubusercontent.com/lining808/CS-Ebook/main/images/æ·±åº¦å­¦ä¹ /æ¨¡å¼è¯†åˆ«ä¸Žæœºå™¨å­¦ä¹ .jpg; https://raw.githubusercontent.com/lining808/CS-Ebook/main/images/æ·±åº¦å­¦ä¹ /æ·±åº¦å­¦ä¹ é«˜æ‰‹ç¬”è®°.jpg; https://raw.githubusercontent.com/lining808/CS-Ebook/main/images/æ·±åº¦å­¦ä¹ /ç¥žç»ç½‘ç»œä¸Žæ·±åº¦å­¦ä¹ .jpg; https://raw.githubusercontent.com/lining808/CS-Ebook/main/images/æ·±åº¦å­¦ä¹ /PyTorch æ·±åº¦å­¦ä¹ .jpg; https://raw.githubusercontent.com/lining808/CS-Ebook/main/images/æ·±åº¦å­¦ä¹ /ç™¾é¢æ·±åº¦å­¦ä¹ .jpg; https://raw.githubusercontent.com/lining808/CS-Ebook/main/images/æ·±åº¦å­¦ä¹ /æ·±åº¦å­¦ä¹ .jpg; https://raw.githubusercontent.com/lining808/CS-Ebook/main/images/æ·±åº¦å­¦ä¹ /æ·±åº¦å­¦ä¹ æŽ¨èç³»ç»Ÿ.jpg; https://raw.githubusercontent.com/lining808/CS-Ebook/main/images/æ·±åº¦å­¦ä¹ /å›¾ç¥žç»ç½‘ç»œ.jpg; https://raw.githubusercontent.com/lining808/CS-Ebook/main/images/æ·±åº¦å­¦ä¹ /æ·±åº¦å­¦ä¹ å…¥é—¨2 è‡ªåˆ¶æ¡†æž¶.jpg; https://raw.githubusercontent.com/lining808/CS-Ebook/main/images/å›¾åƒå¤„ç†/3dè®¡ç®—æœºè§†è§‰.jpg; https://raw.githubusercontent.com/lining808/CS-Ebook/main/images/å›¾åƒå¤„ç†/OpenCVè½»æ¾å…¥é—¨ï¼šé¢å‘Python.jpg; https://raw.githubusercontent.com/lining808/CS-Ebook/main/images/å›¾åƒå¤„ç†/æ·±åº¦å­¦ä¹ ä¸Žç›®æ ‡æ£€æµ‹ï¼ˆç¬¬2ç‰ˆï¼‰.jpg; https://raw.githubusercontent.com/lining808/CS-Ebook/main/images/å›¾åƒå¤„ç†/è§†è§‰SLAMåå››è®² (ç¬¬2ç‰ˆ).jpg; https://raw.githubusercontent.com/lining808/CS-Ebook/main/images/å›¾åƒå¤„ç†/å›¾åƒå·¥ç¨‹ (ç¬¬4ç‰ˆ).jpg; https://raw.githubusercontent.com/lining808/CS-Ebook/main/images/å›¾åƒå¤„ç†/OpenCVè®¡ç®—æœºè§†è§‰æ•™ç¨‹.jpg; https://raw.githubusercontent.com/lining808/CS-Ebook/main/images/å›¾åƒå¤„ç†/æ·±åº¦å­¦ä¹ å…¥é—¨ åŸºäºŽPythonçš„ç†è®ºä¸Žå®žçŽ°.jpg; https://raw.githubusercontent.com/lining808/CS-Ebook/main/images/å›¾åƒå¤„ç†/æ·±åº¦å­¦ä¹ ä¹‹PyTorchç‰©ä½“æ£€æµ‹å®žæˆ˜.jpg; https://raw.githubusercontent.com/lining808/CS-Ebook/main/images/å›¾åƒå¤„ç†/æ•°å­—å›¾åƒå¤„ç†ï¼ˆç¬¬å››ç‰ˆï¼‰.jpg; https://raw.githubusercontent.com/lining808/CS-Ebook/main/images/è‡ªç„¶è¯­è¨€å¤„ç†/bertåŸºç¡€æ•™ç¨‹.jpg; https://raw.githubusercontent.com/lining808/CS-Ebook/main/images/è‡ªç„¶è¯­è¨€å¤„ç†/å¤§è§„æ¨¡è¯­è¨€æ¨¡åž‹ ä»Žç†è®ºåˆ°å®žè·µ.jpg; https://raw.githubusercontent.com/lining808/CS-Ebook/main/images/è‡ªç„¶è¯­è¨€å¤„ç†/ä¸€æœ¬ä¹¦è¯»æ‡‚AIGCï¼šChatGPTã€AIç»˜ç”»ã€æ™ºèƒ½æ–‡æ˜Žä¸Žç”Ÿäº§åŠ›å˜é©.jpg; https://raw.githubusercontent.com/lining808/CS-Ebook/main/images/è‡ªç„¶è¯­è¨€å¤„ç†/çŸ¥è¯†å›¾è°±ä¸Žæ·±åº¦å­¦ä¹ .jpg; https://raw.githubusercontent.com/lining808/CS-Ebook/main/images/è‡ªç„¶è¯­è¨€å¤„ç†/è‡ªç„¶è¯­è¨€å¤„ç†å¯¼è®º.jpg; https://raw.githubusercontent.com/lining808/CS-Ebook/main/images/è‡ªç„¶è¯­è¨€å¤„ç†/pytorchè‡ªç„¶è¯­è¨€å¤„ç†.jpg; https://raw.githubusercontent.com/lining808/CS-Ebook/main/images/è‡ªç„¶è¯­è¨€å¤„ç†/æ·±åº¦å­¦ä¹ è¿›é˜¶ è‡ªç„¶è¯­è¨€å¤„ç†.jpg; https://raw.githubusercontent.com/lining808/CS-Ebook/main/images/è‡ªç„¶è¯­è¨€å¤„ç†/çŸ¥è¯†å›¾è°±å¯¼è®º.jpg; https://raw.githubusercontent.com/lining808/CS-Ebook/main/images/è‡ªç„¶è¯­è¨€å¤„ç†/è‡ªç„¶è¯­è¨€å¤„ç†ï¼šåŸºäºŽé¢„è®­ç»ƒæ¨¡åž‹çš„æ–¹æ³•.jpg; https://raw.githubusercontent.com/lining808/CS-Ebook/main/images/è‡ªç„¶è¯­è¨€å¤„ç†/è‡ªç„¶è¯­è¨€å¤„ç†å®žæˆ˜.jpg; https://raw.githubusercontent.com/lining808/CS-Ebook/main/images/å¼ºåŒ–å­¦ä¹ /Easy RLå¼ºåŒ–å­¦ä¹ æ•™ç¨‹.jpg; https://raw.githubusercontent.com/lining808/CS-Ebook/main/images/å¼ºåŒ–å­¦ä¹ /åŠ¨æ‰‹å­¦å¼ºåŒ–å­¦ä¹ .jpg; https://raw.githubusercontent.com/lining808/CS-Ebook/main/images/å¼ºåŒ–å­¦ä¹ /å¼ºåŒ–å­¦ä¹ ï¼ˆç¬¬2ç‰ˆï¼‰.jpg; https://raw.githubusercontent.com/lining808/CS-Ebook/main/images/å¼ºåŒ–å­¦ä¹ /æ·±åº¦å¼ºåŒ–å­¦ä¹ .jpg; https://raw.githubusercontent.com/lining808/CS-Ebook/main/images/ç”Ÿå­˜æŒ‡å—/ç¨‹åºå‘˜å¥åº·æŒ‡å—.jpg; https://raw.githubusercontent.com/lining808/CS-Ebook/main/images/ç”Ÿå­˜æŒ‡å—/è½¯æŠ€èƒ½ ç¬¬2ç‰ˆ.jpg; https://raw.githubusercontent.com/lining808/CS-Ebook/main/images/ç”Ÿå­˜æŒ‡å—/è½¯æŠ€èƒ½2.jpg; https://raw.githubusercontent.com/lining808/CS-Ebook/main/images/é¢è¯•/ç¨‹åºå‘˜é¢è¯•é‡‘å…¸ï¼ˆç¬¬6ç‰ˆï¼‰.jpg; https://raw.githubusercontent.com/lining808/CS-Ebook/main/images/é¢è¯•/ä»£ç æ•´æ´ä¹‹é“.jpg; https://raw.githubusercontent.com/lining808/CS-Ebook/main/images/é¢è¯•/å‰‘æŒ‡OFFER  åä¼é¢è¯•å®˜ç²¾è®²å…¸åž‹ç¼–ç¨‹é¢˜  (ç¬¬2ç‰ˆ).jpg; https://raw.githubusercontent.com/lining808/CS-Ebook/main/images/é¢è¯•/ä½ çœŸçš„ä¼šå†™ä»£ç å—.jpg; https://raw.githubusercontent.com/lining808/CS-Ebook/main/images/é¢è¯•/é‡æž„ (ç¬¬2ç‰ˆ).jpg; https://raw.githubusercontent.com/lining808/CS-Ebook/main/images/é¢è¯•/ç¨‹åºå‘˜ä¿®ç‚¼ä¹‹é“ï¼ˆç¬¬2ç‰ˆï¼‰.jpg; https://raw.githubusercontent.com/lining808/CS-Ebook/main/images/é¢è¯•/è®¡ç®—æœºç¨‹åºçš„æž„é€ å’Œè§£é‡Š (ç¬¬2ç‰ˆ).jpg; https://raw.githubusercontent.com/lining808/CS-Ebook/main/images/é¢è¯•/å‰‘æŒ‡offerï¼ˆä¸“é¡¹çªç ´ç‰ˆï¼‰.jpg; https://raw.githubusercontent.com/lining808/CS-Ebook/main/images/è½¯è€ƒ/åµŒå…¥å¼ç³»ç»Ÿè®¾è®¡å¸ˆæ•™ç¨‹ï¼ˆç¬¬2ç‰ˆï¼‰.jpg; https://raw.githubusercontent.com/lining808/CS-Ebook/main/images/è½¯è€ƒ/æ•°æ®åº“ç³»ç»Ÿå·¥ç¨‹å¸ˆæ•™ç¨‹ï¼ˆç¬¬3ç‰ˆï¼‰.jpg; https://raw.githubusercontent.com/lining808/CS-Ebook/main/images/è½¯è€ƒ/ç½‘ç»œå·¥ç¨‹å¸ˆæ•™ç¨‹ï¼ˆç¬¬5ç‰ˆï¼‰.jpg; https://raw.githubusercontent.com/lining808/CS-Ebook/main/images/è½¯è€ƒ/ç½‘ç»œç®¡ç†å‘˜æ•™ç¨‹ï¼ˆç¬¬5ç‰ˆï¼‰.jpg; https://raw.githubusercontent.com/lining808/CS-Ebook/main/images/è½¯è€ƒ/ä¿¡æ¯å®‰å…¨å·¥ç¨‹å¸ˆæ•™ç¨‹ï¼ˆç¬¬2ç‰ˆï¼‰.jpg; https://raw.githubusercontent.com/lining808/CS-Ebook/main/images/è½¯è€ƒ/ä¿¡æ¯ç³»ç»Ÿé¡¹ç›®ç®¡ç†å¸ˆæ•™ç¨‹ï¼ˆç¬¬4ç‰ˆï¼‰.jpg; https://raw.githubusercontent.com/lining808/CS-Ebook/main/images/end.jpg,,1028,2023-03-25T08:10:33Z
2024-03-04,https://github.com/kcheng1021/GaussianPro,https://raw.githubusercontent.com/kcheng1021/GaussianPro/main/README.md,"GaussianPro introduces a novel method for enhancing 3D Gaussian Splatting (3DGS), a technique critical in neural rendering for producing high-quality renderings swiftly. The existing 3DGS process struggles with large-scale scenes, particularly when dealing with texture-less surfaces, due to its reliance on point clouds initialized by Structure-from-Motion (SfM) techniques which often fail to generate a sufficient number of points. GaussianPro addresses this by employing a progressive propagation strategy, inspired by classical multi-view stereo (MVS) techniques, to guide the densification of the 3D Gaussians. This strategy, leveraging scene geometry and patch matching, accurately positions and orients new Gaussians, thereby significantly improving rendering quality, as validated by experiments on both large and small-scale scenes, showing notable improvement over traditional 3DGS methods. The project has released a beta version of the code and demonstrated its effectiveness through various datasets and YouTube videos, indicating consistent enhancements across different scenarios.",Revolutionizing Neural Rendering with GaussianPro: A 3D Splatting Breakthrough,"GaussianPro introduces a groundbreaking approach to 3D Gaussian Splatting (3DGS) for neural rendering, addressing the limitations of Structure-from-Motion techniques in large-scale scenes. By incorporating a progressive propagation strategy, GaussianPro significantly improves the initialization process, producing high-quality renderings at real-time speeds. This method surpasses conventional 3DGS, particularly in texture-less surfaces, by utilizing reconstructed geometries and patch matching techniques. Validated by experiments on diverse scenes, GaussianPro achieves remarkable performance enhancements, marking a notable advancement in the field of neural rendering.","Discover how GaussianPro enhances neural rendering with an innovative 3D Gaussian Splatting approach, overcoming traditional challenges and leading to superior rendering quality and efficiency.",Deep Learning Platform,"Python





        257





        10


        Built by

          







        31 stars today",https://raw.githubusercontent.com/kcheng1021/GaussianPro/main/figs/comparison.gif; https://raw.githubusercontent.com/kcheng1021/GaussianPro/main/figs/pipeline.png; https://github.com/kcheng1021/GaussianPro/blob/main/figs/output.gif; https://github.com/kcheng1021/GaussianPro/blob/main/figs/output2.gif,,257,2024-02-21T01:57:53Z
2024-03-04,https://github.com/yt-dlp/yt-dlp,https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/README.md,"yt-dlp is a fork of youtube-dl, created to introduce new features and updates while staying aligned with the original project. Major enhancements include SponsorBlock integration to mark/remove sponsored sections in YouTube videos, advanced format sorting capabilities for favoring higher resolution and codecs over bitrate, and merging improvements from animelover1984/youtube-dl which adds features like writing comments, and support for various YouTube content types such as Clips, Stories, and Live. It introduces automatic cookie extraction from browsers, partial video downloads based on timestamps or chapters, multi-threaded fragment downloads, and use of aria2c for DASH and HLS formats. New extractors have been added, extractor issues fixed, and support for new MSOs and subtitle extraction from manifests is included. Enhancements to output templates, more path and template options, plugins support, self-updater, and nightly/master builds for the latest features are also notable additions. Differences from youtube-dl include updated default behavior in options, format selection, and storage locations to prioritize user convenience and performance.",Top New Features in yt-dlp: A Comprehensive Guide,"yt-dlp, a fork of youtube-dl, stands out by introducing an array of new features and updates, ensuring an enhanced video downloading experience. From SponsorBlock integration for skipping sponsor segments to advanced format sorting options prioritizing resolution and codecs, yt-dlp brings significant improvements to video downloading. Enhanced YouTube support, including downloading livestreams from the start and support for age-gated content without cookies, alongside multithreading for faster downloads, makes yt-dlp a go-to solution. Additionally, yt-dlp updates include new extractor support and portability in configuration, catering to a wide range of user preferences.","Discover the latest enhancements and features in yt-dlp, including SponsorBlock integration, improved format sorting, enhanced YouTube support, and faster downloads through multithreading. A must-read for efficient video downloading.",Document Conversion Tool,"Python





        67,184





        5,320


        Built by

          









        71 stars today",,https://www.youtube.com/watch?v=BaW_jenozKc; https://www.youtube.com/watch?v=BaW_jenozKc; https://www.youtube.com/watch?v=BaW_jenozKc; https://www.youtube.com/watch?v=BaW_jenozKc; https://www.youtube.com/watch?v=BaW_jenozKc; https://www.youtube.com/watch?v=BaW_jenozKc; https://www.youtube.com/watch?v=BaW_jenozKc; https://www.youtube.com/watch?v=BaW_jenozKc,67184,2020-10-26T04:22:55Z
2024-03-04,https://github.com/ihmily/DouyinLiveRecorder,https://raw.githubusercontent.com/ihmily/DouyinLiveRecorder/main/README.md,"The DouyinLiveRecorder is a user-friendly live-stream recording tool developed by ihmily and collaborators, capable of capturing live streams across multiple platforms including Douyin, TikTok, Kuaishou, Huya, Douyu, YY, Bilibili, Xiaohongshu, Bigo, Blued, AfreecaTV, Netease CC, Qiandu Hotplay, PandaTV, and Missevan FM, with plans to support more. It utilizes FFmpeg for recording and is customizable through config files. Available on Windows and Linux, it supports Docker for easy deployment. Users can download the latest release, set up through config files, and run it to record live streams in high definition, with various additional features like proxy support for international platforms, quality settings, ongoing monitoring without frequent restarts to avoid IP bans, and detailed instructions for setup and use. The project is open-source, welcoming contributions and provides source code for further customization, Docker support for containerized deployment, and a contributor's list celebrating the community's involvement.",Ultimate Guide to Recording Live Streams Across Platforms with DouyinLiveRecorder,"Discover how to effortlessly record live streams from Douyin, TikTok, and more using the versatile DouyinLiveRecorder tool. This straightforward guide covers everything from initial setup to advanced recording features, ensuring you capture every moment in high quality. Whether you're a newbie or a seasoned user, learn how to configure live stream URLs, customize recording settings, and even pause recordings without losing data. Plus, get insights on new platform additions and updates to keep your recording capabilities at the cutting edge. Embrace the power of recording live content seamlessly across multiple platforms.","Learn how to use DouyinLiveRecorder to capture live streams from Douyin, TikTok, and other platforms. From setup to customization, this guide ensures you never miss a live moment again.",Open Source Tool,"Python





        2,155





        224


        Built by

          







        209 stars today",,,2155,2023-07-17T10:11:12Z
2024-03-04,https://github.com/python-telegram-bot/python-telegram-bot,https://raw.githubusercontent.com/ranaroussi/yfinance/main/README.md,"The document provides an overview of yfinance, an open-source Python library not affiliated with Yahoo, Inc., used for downloading market data from Yahoo! Finance's API for research and educational purposes. It emphasizes the need to adhere to Yahoo!'s terms of use regarding the data's usage. The library offers a Pythonic approach to access ticker data, historical market data, financials, and news among other features, with support for proxy servers. Installation instructions, quick start guides, and information on logging and smarter scraping to avoid spamming Yahoo's API are included. It also touches on managing multi-level column names, integrating yfinance with pandas_datareader for faster data download, and setting up a persistent cache store to reduce Yahoo data requests. The document calls for community contributions to the project and notes its distribution under the Apache Software License, reiterating its purpose for research and educational use only.",Harnessing Yahoo! Finance API for Market Data: A Comprehensive Guide,"Discover how to leverage the Yahoo! Finance API using yfinance for Python to download market data easily. This tutorial offers a Pythonic way to access stock information, historical market data, and more while adhering to Yahoo!'s terms of use. It's essential for research, educational purposes, and personal use, highlighting the community-driven enhancements for efficient data extraction.","Explore a step-by-step guide to downloading market data using the Yahoo! Finance API with yfinance. Ideal for research and educational purposes, learn how to access stock info, historical data, and much more while following Yahoo!'s usage terms.",Python Libraries Collection,"Python





        24,364





        4,970


        Built by

          









        6 stars today",,,11436,2015-07-07T15:30:39Z
2024-03-04,https://github.com/donnemartin/system-design-primer,https://raw.githubusercontent.com/ccxt/ccxt/master/README.md,"The CCXT library is a JavaScript / Python / PHP / C# library for cryptocurrency trading and e-commerce with support for many bitcoin/ether/altcoin exchange markets and merchant APIs. It is used to connect and trade with crypto exchanges and payment processing services globally. It offers quick access to market data for storage, analysis, visualization, indicator development, algorithmic trading, strategy backtesting, bot programming, and related software engineering. The library is designed for coders, developers, technically-skilled traders, data-scientists, and financial analysts for building trading algorithms.

Features include support for many cryptocurrency exchanges, fully implemented public and private APIs, optional normalized data for cross-exchange analytics and arbitrage, and an easy-to-integrate unified API. It works in Node.js, Python, PHP, C#, and browsers. The library is open source under the MIT license, meaning it's free to use in commercial and open-source projects. However, responsibilities and warranties are disclaimed. Installation involves using package managers like npm for JavaScript, pip for Python, or including a script tag for browsers.

The CCXT library comprises a public part accessible immediately upon installation, offering unrestricted access to public information without needing an account or API key. Conversely, private APIs require API keys for actions like account management, trading, and withdrawals.

Contributions are welcome but should follow the contributing guidelines detailed in the documentation. The development team also accepts donations and sponsorship to support and accelerate the library's development.",Maximize Your Crypto Trading with the CCXT Library: The Ultimate Guide,"Discover how the CCXT Library can transform your cryptocurrency trading experience. This ultimate guide covers its features, benefits, and how it supports multiple exchange markets for effective trading. Whether you're a developer, technically-skilled trader, or a financial analyst, CCXT provides the tools you need for market analysis, algorithmic trading, and more. Explore how CCXT can enhance your trading strategies today.","Unlock the potential of cryptocurrency trading with our comprehensive guide on the CCXT Library. Learn how it supports various exchanges, streamlines trading, and provides essential tools for market analysis and algorithmic trading. Start optimizing your trading strategies with CCXT now.",Crypto Trading Bot,"Python





        248,122





        42,583


        Built by

          









        99 stars today",https://user-images.githubusercontent.com/1294454/66755907-9c3e8880-eea1-11e9-846e-0bff349ceb87.png; https://user-images.githubusercontent.com/1294454/114340585-8e35fa80-9b60-11eb-860f-4379125e2db6.png; https://user-images.githubusercontent.com/1294454/132113722-007fc092-7530-4b41-b929-b8ed380b7b2e.png; https://user-images.githubusercontent.com/1294454/152720975-0522b803-70f0-4f18-a305-3c99b37cd990.png; https://user-images.githubusercontent.com/1294454/29604020-d5483cdc-87ee-11e7-94c7-d1a8d9169293.jpg; https://user-images.githubusercontent.com/1294454/117738721-668c8d80-b205-11eb-8c49-3fad84c4a07f.jpg; https://user-images.githubusercontent.com/1294454/117738721-668c8d80-b205-11eb-8c49-3fad84c4a07f.jpg; https://github-production-user-asset-6210df.s3.amazonaws.com/1294454/253675376-6983b72e-4999-4549-b177-33b374c195e3.jpg; https://user-images.githubusercontent.com/1294454/195989417-4253ddb0-afbe-4a1c-9dea-9dbcd121fa5d.jpg; https://user-images.githubusercontent.com/1294454/129991357-8f47464b-d0f4-41d6-8a82-34122f0d1398.jpg; https://user-images.githubusercontent.com/51840849/76547799-daff5b80-649e-11ea-87fb-3be9bac08954.jpg; https://user-images.githubusercontent.com/51840849/87182089-1e05fa00-c2ec-11ea-8da9-cc73b45abbbc.jpg; https://user-images.githubusercontent.com/1294454/147792121-38ed5e36-c229-48d6-b49a-48d05fc19ed4.jpeg; https://user-images.githubusercontent.com/1294454/31784029-0313c702-b509-11e7-9ccc-bc0da6a0e435.jpg; https://user-images.githubusercontent.com/1294454/76137448-22748a80-604e-11ea-8069-6e389271911d.jpg; https://user-images.githubusercontent.com/51840849/87295558-132aaf80-c50e-11ea-9801-a2fb0c57c799.jpg; https://user-images.githubusercontent.com/1294454/147508995-9e35030a-d046-43a1-a006-6fabd981b554.jpg; https://user-images.githubusercontent.com/1294454/137283979-8b2a818d-8633-461b-bfca-de89e8c446b2.jpg; https://user-images.githubusercontent.com/1294454/152485636-38b19e4a-bece-4dec-979a-5982859ffc04.jpg; https://user-images.githubusercontent.com/1294454/150730761-1a00e5e0-d28c-480f-9e65-089ce3e6ef3b.jpg; https://user-images.githubusercontent.com/1294454/216908003-fb314cf6-e66e-471c-b91d-1d86e4baaa90.jpg; https://user-images.githubusercontent.com/1294454/187234005-b864db3d-f1e3-447a-aaf9-a9fc7b955d07.jpg; https://user-images.githubusercontent.com/1294454/112027508-47984600-8b48-11eb-9e17-d26459cc36c6.jpg; https://user-images.githubusercontent.com/1294454/55248342-a75dfe00-525a-11e9-8aa2-05e9dca943c6.jpg; https://user-images.githubusercontent.com/1294454/69354403-1d532180-0c91-11ea-88ed-44c06cefdf87.jpg; https://user-images.githubusercontent.com/1294454/29604020-d5483cdc-87ee-11e7-94c7-d1a8d9169293.jpg; https://user-images.githubusercontent.com/1294454/117738721-668c8d80-b205-11eb-8c49-3fad84c4a07f.jpg; https://user-images.githubusercontent.com/1294454/65177307-217b7c80-da5f-11e9-876e-0b748ba0a358.jpg; https://user-images.githubusercontent.com/1294454/117738721-668c8d80-b205-11eb-8c49-3fad84c4a07f.jpg; https://github-production-user-asset-6210df.s3.amazonaws.com/1294454/253675376-6983b72e-4999-4549-b177-33b374c195e3.jpg; https://user-images.githubusercontent.com/1294454/27766119-3593220e-5ece-11e7-8b3a-5a041f6bcc3f.jpg; https://user-images.githubusercontent.com/1294454/37808081-b87f2d9c-2e59-11e8-894d-c1900b7584fe.jpg; https://user-images.githubusercontent.com/1294454/117201933-e7a6e780-adf5-11eb-9d80-98fc2a21c3d6.jpg; https://user-images.githubusercontent.com/1294454/27766244-e328a50c-5ed2-11e7-947b-041416579bb3.jpg; https://user-images.githubusercontent.com/1294454/27766244-e328a50c-5ed2-11e7-947b-041416579bb3.jpg; https://user-images.githubusercontent.com/1294454/28051642-56154182-660e-11e7-9b0d-6042d1e6edd8.jpg; https://user-images.githubusercontent.com/1294454/195989417-4253ddb0-afbe-4a1c-9dea-9dbcd121fa5d.jpg; https://user-images.githubusercontent.com/1294454/30597177-ea800172-9d5e-11e7-804c-b9d4fa9b56b0.jpg; https://user-images.githubusercontent.com/1294454/129991357-8f47464b-d0f4-41d6-8a82-34122f0d1398.jpg; https://user-images.githubusercontent.com/1294454/158227251-3a92a220-9222-453c-9277-977c6677fe71.jpg; https://user-images.githubusercontent.com/1294454/139516488-243a830d-05dd-446b-91c6-c1f18fe30c63.jpg; https://user-images.githubusercontent.com/51840849/87295554-11f98280-c50e-11ea-80d6-15b3bafa8cbf.jpg; https://user-images.githubusercontent.com/1294454/27786377-8c8ab57e-5fe9-11e7-8ea4-2b05b6bcceec.jpg; https://user-images.githubusercontent.com/1294454/169202626-bd130fc5-fcf9-41bb-8d97-6093225c73cd.jpg; https://user-images.githubusercontent.com/1294454/28501752-60c21b82-6feb-11e7-818b-055ee6d0e754.jpg; https://user-images.githubusercontent.com/1294454/147515585-1296e91b-7398-45e5-9d32-f6121538533f.jpeg; https://user-images.githubusercontent.com/1294454/42625213-dabaa5da-85cf-11e8-8f99-aa8f8f7699f0.jpg; https://user-images.githubusercontent.com/51840849/87327317-98c55400-c53c-11ea-9a11-81f7d951cc74.jpg; https://user-images.githubusercontent.com/51840849/89731817-b3fb8480-da52-11ea-817f-783b08aaf32b.jpg; https://user-images.githubusercontent.com/51840849/87153926-efbef500-c2c0-11ea-9842-05b63612c4b9.jpg; https://user-images.githubusercontent.com/51840849/76547799-daff5b80-649e-11ea-87fb-3be9bac08954.jpg; https://user-images.githubusercontent.com/1294454/27766442-8ddc33b0-5ed8-11e7-8b98-f786aef0f3c9.jpg; https://user-images.githubusercontent.com/1294454/40811661-b6eceae2-653a-11e8-829e-10bfadb078cf.jpg; https://user-images.githubusercontent.com/1294454/41764625-63b7ffde-760a-11e8-996d-a6328fa9347a.jpg; https://user-images.githubusercontent.com/51840849/87182088-1d6d6380-c2ec-11ea-9c64-8ab9f9b289f5.jpg; https://user-images.githubusercontent.com/51840849/87182089-1e05fa00-c2ec-11ea-8da9-cc73b45abbbc.jpg; https://github-production-user-asset-6210df.s3.amazonaws.com/1294454/281108917-eff2ae1d-ce8a-4b2a-950d-8678b12da965.jpg; https://user-images.githubusercontent.com/51840849/87460806-1c9f3f00-c616-11ea-8c46-a77018a8f3f4.jpg; https://user-images.githubusercontent.com/1294454/38003300-adc12fba-323f-11e8-8525-725f53c4a659.jpg; https://user-images.githubusercontent.com/1294454/225719995-48ab2026-4ddb-496c-9da7-0d7566617c9b.jpg; https://user-images.githubusercontent.com/1294454/28208429-3cacdf9a-6896-11e7-854e-4c79a772a30f.jpg; https://user-images.githubusercontent.com/1294454/147792121-38ed5e36-c229-48d6-b49a-48d05fc19ed4.jpeg; https://user-images.githubusercontent.com/1294454/83718672-36745c00-a63e-11ea-81a9-677b1f789a4d.jpg; https://user-images.githubusercontent.com/1294454/99450025-3be60a00-2931-11eb-9302-f4fd8d8589aa.jpg; https://user-images.githubusercontent.com/1294454/41933112-9e2dd65a-798b-11e8-8440-5bab2959fcb8.jpg; https://user-images.githubusercontent.com/51840849/87443315-01283a00-c5fe-11ea-8628-c2a0feaf07ac.jpg; https://user-images.githubusercontent.com/1294454/27766491-1b0ea956-5eda-11e7-9225-40d67b481b8d.jpg; https://user-images.githubusercontent.com/1294454/159177712-b685b40c-5269-4cea-ac83-f7894c49525d.jpg; https://user-images.githubusercontent.com/1294454/31784029-0313c702-b509-11e7-9ccc-bc0da6a0e435.jpg; https://user-images.githubusercontent.com/1294454/27816857-ce7be644-6096-11e7-82d6-3c257263229c.jpg; https://user-images.githubusercontent.com/1294454/27766555-8eaec20e-5edc-11e7-9c5b-6dc69fc42f5e.jpg; https://user-images.githubusercontent.com/1294454/75841031-ca375180-5ddd-11ea-8417-b975674c23cb.jpg; https://user-images.githubusercontent.com/1294454/76137448-22748a80-604e-11ea-8069-6e389271911d.jpg; https://user-images.githubusercontent.com/1294454/85734211-85755480-b705-11ea-8b35-0b7f1db33a2f.jpg; https://user-images.githubusercontent.com/51840849/94481303-2f222100-01e0-11eb-97dd-bc14c5943a86.jpg; https://user-images.githubusercontent.com/51840849/87182090-1e9e9080-c2ec-11ea-8e49-563db9a38f37.jpg; https://user-images.githubusercontent.com/51840849/87070508-9358c880-c221-11ea-8dc5-5391afbbb422.jpg; https://user-images.githubusercontent.com/51840849/76173629-fc67fb00-61b1-11ea-84fe-f2de582f58a3.jpg; https://user-images.githubusercontent.com/24300605/81436764-b22fd580-9172-11ea-9703-742783e6376d.jpg; https://user-images.githubusercontent.com/51840849/87295558-132aaf80-c50e-11ea-9801-a2fb0c57c799.jpg; https://user-images.githubusercontent.com/1294454/147508995-9e35030a-d046-43a1-a006-6fabd981b554.jpg; https://user-images.githubusercontent.com/51840849/87153927-f0578b80-c2c0-11ea-84b6-74612568e9e1.jpg; https://user-images.githubusercontent.com/1294454/61511972-24c39f00-aa01-11e9-9f7c-471f1d6e5214.jpg; https://user-images.githubusercontent.com/1294454/38063602-9605e28a-3302-11e8-81be-64b1e53c4cfb.jpg; https://user-images.githubusercontent.com/1294454/27766607-8c1a69d8-5ede-11e7-930c-540b5eb9be24.jpg; https://user-images.githubusercontent.com/1294454/155840500-1ea4fdf0-47c0-4daa-9597-c6c1cd51b9ec.jpg; https://user-images.githubusercontent.com/1294454/27837060-e7c58714-60ea-11e7-9192-f05e86adb83f.jpg; https://user-images.githubusercontent.com/1294454/137283979-8b2a818d-8633-461b-bfca-de89e8c446b2.jpg; https://user-images.githubusercontent.com/1294454/108623144-67a3ef00-744e-11eb-8140-75c6b851e945.jpg; https://user-images.githubusercontent.com/1294454/92337550-2b085500-f0b3-11ea-98e7-5794fb07dd3b.jpg; https://user-images.githubusercontent.com/1294454/58385970-794e2d80-8001-11e9-889c-0567cd79b78e.jpg; https://user-images.githubusercontent.com/51840849/87295551-102fbf00-c50e-11ea-90a9-462eebba5829.jpg; https://user-images.githubusercontent.com/1294454/152485636-38b19e4a-bece-4dec-979a-5982859ffc04.jpg; https://user-images.githubusercontent.com/51840849/87153930-f0f02200-c2c0-11ea-9c0a-40337375ae89.jpg; https://user-images.githubusercontent.com/1294454/85225056-221eb600-b3d7-11ea-930d-564d2690e3f6.jpg; https://user-images.githubusercontent.com/1294454/27766817-e9456312-5ee6-11e7-9b3c-b628ca5626a5.jpg; https://user-images.githubusercontent.com/1294454/27766817-e9456312-5ee6-11e7-9b3c-b628ca5626a5.jpg; https://user-images.githubusercontent.com/51840849/79268032-c4379480-7ea2-11ea-80b3-dd96bb29fd0d.jpg; https://user-images.githubusercontent.com/1294454/70423869-6839ab00-1a7f-11ea-8f94-13ae72c31115.jpg; https://user-images.githubusercontent.com/1294454/183870484-d3398d0c-f6a1-4cce-91b8-d58792308716.jpg; https://user-images.githubusercontent.com/1294454/49245610-eeaabe00-f423-11e8-9cba-4b0aed794799.jpg; https://user-images.githubusercontent.com/1294454/84547058-5fb27d80-ad0b-11ea-8711-78ac8b3c7f31.jpg; https://user-images.githubusercontent.com/1294454/148647666-c109c20b-f8ac-472f-91c3-5f658cb90f49.jpeg; https://user-images.githubusercontent.com/1294454/66732963-8eb7dd00-ee66-11e9-849b-10d9282bb9e0.jpg; https://user-images.githubusercontent.com/1294454/150730761-1a00e5e0-d28c-480f-9e65-089ce3e6ef3b.jpg; https://user-images.githubusercontent.com/1294454/27766910-cdcbfdae-5eea-11e7-9859-03fea873272d.jpg; https://user-images.githubusercontent.com/1294454/27766927-39ca2ada-5eeb-11e7-972f-1b4199518ca6.jpg; https://user-images.githubusercontent.com/1294454/159202310-a0e38007-5e7c-4ba9-a32f-c8263a0291fe.jpg,,30661,2017-02-26T16:15:28Z
2024-03-04,https://github.com/ccxt/ccxt,https://raw.githubusercontent.com/Sanster/IOPaint/main/README.md,"IOPaint is a free, open-source tool designed for inpainting and outpainting tasks, utilizing state-of-the-art AI models. It's fully self-hosted and supports both CPU and GPU, including Apple Silicon, making it accessible for a wide range of users. The platform offers a versatile range of AI models for erasing unwanted objects or defects from images and for creative tasks like object replacement or outpainting. Models cater to various needs, from erasing to diffusion models capable of intricate modifications. Additionally, IOPaint provides plugins for functions like object segmentation, background removal, super-resolution, and face restoration, enhancing its utility. Users can easily manage their projects with features like a file manager and batch processing capabilities. The software facilitates easy installation and use via web UI or command line, supporting a broad spectrum of AI-driven image editing tasks with detailed instructions for setup and application. Development is actively supported, with resources available to contribute to both the front and back-end components.",Revolutionize Your Image Editing with IOPaint: The Ultimate AI-Powered Tool,"Discover IOPaint, the cutting-edge, free, and open-source image editing tool powered by state-of-the-art AI technology. With support for CPU, GPU, and Apple Silicon, this tool offers an array of features including erase, inpainting, outpainting, and various plugins. From removing unwanted objects to enhancing image quality, IOPaint caters to all your image editing needs. The tool is easily accessible through a one-click installer for Windows or directly from its GitHub repository. Transform your images effortlessly with IOPaint's advanced AI models and user-friendly web interface.","Explore IOPaint, a free AI-based image editing tool for inpainting & outpainting. Supports CPU/GPU, features 1-click Windows installer, various AI models & plugins.",Image Generation Platform.,"Python





        30,661





        7,147


        Built by

          









        14 stars today",,https://github.com/Sanster/IOPaint/assets/3998421/264bc27c-0abd-4d8b-bb1e-0078ab264c4a; https://github.com/Sanster/IOPaint/assets/3998421/1de5c288-e0e1-4f32-926d-796df0655846; https://github.com/Sanster/IOPaint/assets/3998421/ffd4eda4-f7d4-4693-93d8-d2cd5aa7c6d6; https://github.com/Sanster/IOPaint/assets/3998421/c4af8aef-8c29-49e0-96eb-0aae2f768da2,16163,2017-05-14T15:41:56Z
2024-03-04,https://github.com/Sanster/IOPaint,https://raw.githubusercontent.com/intel/intel-npu-acceleration-library/main/README.md,"The IntelÂ® NPU Acceleration Library is a Python library aimed at enhancing application performance through the Intel Neural Processing Unit (NPU), specifically designed for high-speed computations on compatible hardware. It is in active development, aiming to incorporate features to significantly boost efficiency. The Intel NPU, embedded within Intel Core Ultra processors, features a unique architecture that accelerates AI operations through Neural Compute Engines and supports general computing tasks. Its performance is optimized by efficient data transfer mechanisms and software that utilizes compiler technology for AI workload optimization. The libraryâ€™s upcoming enhancements include various quantization support and mixed precision inference among others. To use, the library requires an available NPU and can be installed via pip. It supports operations like matrix multiplication and model compilation for the NPU, with examples provided for practical implementation.",Maximize Your Application's Performance with Intel NPU Acceleration Library,"Discover how the IntelÂ® NPU Acceleration Library can enhance your computing tasks by utilizing the advanced capabilities of Intel Neural Processing Units (NPUs). This Python library is tailored for developers seeking to boost their applications' performance on Intel Core Ultra processors, featuring support for complex AI operations. Currently under active development, the library promises exciting features aimed at significantly improving performance across various computing domains. Learn how to install, set up, and start leveraging the library for high-speed computations, and stay tuned for upcoming enhancements that will take your computing efficiency to the next level.","Learn about the Intel NPU Acceleration Library, a groundbreaking tool designed to improve application efficiency through Intel's Neural Processing Units. Explore its features, setup guide, and future enhancements.",Python Libraries Collection,"Python





        16,163





        1,613


        Built by

          









        35 stars today",,https://www.youtube.com/watch?v=QSzNoX0qplE,167,2021-11-15T14:16:40Z
2024-03-04,https://github.com/intel/intel-npu-acceleration-library,https://raw.githubusercontent.com/xaitax/SploitScan/main/README.md,"SploitScan is a dynamic cybersecurity tool designed to efficiently identify exploits for known vulnerabilities and assess exploitation probabilities. It aims to aid cybersecurity professionals in enhancing security measures and developing robust detection strategies for emerging threats. Key features include CVE information retrieval from the National Vulnerability Database, integration with the Exploit Prediction Scoring System (EPSS) for exploit likelihood scoring, aggregation of public exploits, display of CVEs listed in CISA's Known Exploited Vulnerabilities, a patching priority system, support for multiple CVE queries, and easy export options to JSON and CSV. With a user-friendly interface, SploitScan serves as a comprehensive tool for quick security assessments. It also supports various exploit databases like GitHub, ExploitDB, and VulnCheck (requiring an API key). Recent updates include enhancements in CVSS support, Docker support, and the introduction of a prioritization system for security patches, guiding users on which vulnerabilities to address first. Contributions from the cybersecurity community are encouraged, reflecting collaborative efforts in improving SploitScan.",Maximizing Cybersecurity with SploitScan: A Comprehensive Tool for Exploit Detection,"Discover SploitScan, a user-centric tool designed to revolutionize exploit detection and vulnerability assessment in the cybersecurity arena. With features like CVE Information Retrieval, EPSS Integration, and a Patching Priority System, SploitScan empowers professionals to prioritize and patch vulnerabilities effectively. Its integration with major exploit databases and a user-friendly interface makes it indispensable for enhancing security postures. Ideal for quick assessments and advanced security strategy development, SploitScan is your go-to for staying ahead of potential threats.","Explore SploitScan, the ultimate tool for cybersecurity professionals. Streamline exploit detection, access comprehensive CVE details, and prioritize patches with ease. Elevate your security strategy now.",Cybersecurity Tool,"Python





        167





        7


        Built by

          






        71 stars today",,,456,2024-02-20T20:33:18Z
2024-03-05,https://github.com/layerdiffusion/sd-forge-layerdiffuse,https://raw.githubusercontent.com/layerdiffusion/sd-forge-layerdiffuse/main/README.md,"The text outlines the development and features of ""sd-forge-layerdiffuse,"" an extension for SD WebUI through Forge, designed to create transparent images and layers using latent transparency. Currently, the extension supports basic image generation and layer functionality, but the img2img feature for transparent images is still under development. The extension is evolving, and changes are expected, making it vital for professional users to back up their files regularly. It includes a demonstration of the process, indicating the capability to generate transparent effects unachievable with standard background removal methods. Various models are released for specific purposes, such as converting SDXL models into transparent image generators or layer generating models conditioned on foregrounds or backgrounds. Some models are slated for future release to improve performance and capabilities. Sanity checks are recommended for users to ensure their setup yields consistent results, demonstrated through various example prompts and outcomes. The text also includes FAQs and conditions for generating specific images, emphasizing the flexibility and potential of ""sd-forge-layerdiffuse"" in content creation with transparent images.",Revolutionizing Image Generation with SD-Forge LayerDiffuse: Transparent Layers Unveiled,"Discover the future of image creation with SD-Forge LayerDiffuse, a cutting-edge extension designed for the SD WebUI platform. This amazing tool allows users to generate transparent images and layers with unprecedented clarity and detail. While still a work in progress, basic functionalities such as image and layer generation are operational, promising a significant advancement in transparent img2img technology. The dynamic nature of this codebase promises exciting updates, catering especially to professional content creation studios seeking precision and consistency in their projects. Stay tuned for more updates as this technology evolves to redefine the standards of image generation.","Explore SD-Forge LayerDiffuse for SD WebUI, an innovative extension for creating detailed transparent images and layers. Ideal for professionals, it promises precise, high-quality image generation. Learn more about its features and future updates.",Image Generation Platform.,"Python





        2,158





        211


        Built by

          





        289 stars today",,,2158,2024-03-01T06:41:32Z
2024-03-05,https://github.com/huchenlei/ComfyUI-layerdiffuse,https://raw.githubusercontent.com/huchenlei/ComfyUI-layerdiffuse/main/README.md,"ComfyUI-layerdiffuse is an implementation of LayerDiffuse tailored for the ComfyUI environment. Users can install it by downloading the repository to the `custom_nodes` folder in ComfyUI or cloning it via GIT from the same location. Python dependencies are installed with `pip install -r requirements.txt`, though version conflicts with `diffusers` may occur, suggesting the use of separate Python venvs. The implementation supports a range of workflows for generating and blending foreground (FG) and background (BG), including separating RGB images with alpha channels, blending given FG/BG, extracting FG or BG from blended images, and generating FG from BG. A notable feature is the `stop at` parameter in some workflows, which enhances denoising process control. Currently, it primarily supports SDXL, with ongoing tasks including various conditioning and extraction capabilities. The workflows demonstrate color variations in FG extraction, pending confirmation from the LayerDiffuse authors if these are expected behaviors.",Integrate LayerDiffuse with ComfyUI for Enhanced Image Manipulation,"Explore the power of LayerDiffuse and ComfyUI integration for advanced image manipulation workflows. This guide covers installation steps, including a direct GitHub clone or download, and setting up necessary Python dependencies with potential conflict resolutions. Dive into comprehensive workflows for generating foregrounds, blending, and extracting elements with ease, all supported currently by SDXL. Enhance your projects by leveraging these innovative techniques for more control and creative freedom in image processing.","This post provides a succinct guide on integrating LayerDiffuse with ComfyUI for advanced image manipulation, including installation, setting up Python venvs to avoid dependency conflicts, and exploring various workflows for creative image processing.",Custom Node Pack,"Python





        344





        29


        Built by

          






        83 stars today",,,344,2024-03-02T22:56:05Z
2024-03-05,https://github.com/yangjianxin1/Firefly,https://raw.githubusercontent.com/yangjianxin1/Firefly/master/README.md,"Firefly is an open-source project offering a one-stop tool for training large models efficiently. It provides support for pretraining, instruction fine-tuning (SFT), and DPO tasks across a wide range of large models such as Gemma, MiniCPM, Llama, and Bloom among others. The project highlights its three training methodologies, full parameter training, and efficient training techniques LoRA and QLoRA. Specifically, QLoRA is recommended for those with limited training resources, proven effective in Open LLM Leaderboard standings. The project includes support for most mainstream open-source large models and aligns its training with official chat model templates while also offering an assortment of instruction fine-tuning datasets and open-sourced model weights. Additionally, Firefly has demonstrated the effectiveness of its QLoRA training process on the Open LLM Leaderboard and has facilitated multiple language model innovations including LongQLoRA for context length extension, LLMPruner for model size reduction, and a Chinese version of LLaMA2 for efficient training. Model weights for various adaptations such as Firefly-mixtral-8x7b and Firefly-LLaMA2-Chinese among others are available. The project also emphasizes various related projects aiming at model training optimizations, and a list of technical blogs providing insights into large model training and optimization techniques. Firefly stands out for its comprehensive approach towards efficiently training and fine-tuning large models for a variety of applications.",Firefly: The One-Stop Training Tool for Large Language Models,"Discover Firefly, the open-source project revolutionizing the training of large language models such as Gemma, MiniCPM, and Llama. Supporting efficient strategies like QLoRA for instruction fine-tuning, Firefly enables effective model training with limited resources. Join the tech community and access a comprehensive array of mainstream large models, contributing to advancements in AI language training.","Learn how Firefly, an open-source project, simplifies the training of large language models with efficient techniques like QLoRA, supporting a wide range of models including Gemma and MiniCPM. Join the vibrant tech community today.",Deep Learning Platform,"Python





        3,889





        335


        Built by

          





        15 stars today",https://img.shields.io/badge/å¾®ä¿¡äº¤æµç¾¤-Firefly-brightgreen?logo=wechat)](./pics/wechat-group.jpeg; https://raw.githubusercontent.com/yangjianxin1/Firefly/master/pics/firefly_logo.png; https://raw.githubusercontent.com/yangjianxin1/Firefly/master/pics/gongzhonghao.png; https://raw.githubusercontent.com/yangjianxin1/Firefly/master/pics/task_distribution.png; https://raw.githubusercontent.com/yangjianxin1/Firefly/master/pics/gongzhonghao.jpeg,,3889,2023-04-02T14:55:59Z
2024-03-05,https://github.com/hpcaitech/ColossalAI,https://raw.githubusercontent.com/hpcaitech/ColossalAI/main/README.md,"Colossal-AI is a system designed to make training large AI models more efficient, cost-effective, and accessible. It offers a suite of parallel components to enable easy and scalable model training, supporting various parallelism strategies including Data, Pipeline, Tensor, and more. Colossal-AI also provides features for heterogeneous memory management and user-friendly configuration-based parallelism setup. Recent updates include cost reduction and enhancement solutions in various applications like Open-Sora for replication and Colossal-LLaMA-2 for domain-specific language model training. It showcases significant advancements in inference performance, training efficiency for massive models, AI-generated content acceleration, and biomedicine. The system is designed for both large-scale distributed training and efficient single-GPU training, with comprehensive support for a wide range of models and tasks. Installation is straightforward via PyPI or from the source, with Docker support available for easy environment setup. The community-driven project encourages contributions and offers extensive documentation, tutorials, and examples to facilitate adoption and innovation in AI model training.","Revolutionizing AI with Colossal-AI: Cheaper, Faster, More Accessible","Discover how Colossal-AI is transforming the AI landscape by making large AI models more affordable, quicker, and easily accessible. With its latest updates, Colossal-AI offers enhanced parallelism, reduced costs, and comprehensive support for existing and upcoming AI models. Dive into the world where advanced AI technology is now within reach for researchers and organizations worldwide, thanks to the innovative solutions provided by Colossal-AI.","Explore how Colossal-AI is making significant strides in AI by facilitating cheaper, faster, and more accessible large model training. Learn about its latest features, including parallelism enhancements and cost reductions.",Deep Learning Platform.,"Python





        36,541





        4,102


        Built by

          









        20 stars today",https://raw.githubusercontent.com/hpcaitech/public_assets/main/colossalai/img/colossal-ai_logo_vertical.png; https://img.shields.io/badge/å¾®ä¿¡-åŠ å…¥-green?logo=wechat&amp)](https://raw.githubusercontent.com/hpcaitech/public_assets/main/colossalai/img/WeChat.png; https://raw.githubusercontent.com/hpcaitech/public_assets/main/colossalai/img/JamesDemmel_Colossal-AI.png; https://raw.githubusercontent.com/hpcaitech/public_assets/main/applications/sora/open-sora-1.png; https://raw.githubusercontent.com/hpcaitech/public_assets/main/applications/sora/open-sora-2.png; https://raw.githubusercontent.com/hpcaitech/public_assets/main/applications/chat/ColossalChat%20YouTube.png; https://raw.githubusercontent.com/hpcaitech/public_assets/main/applications/chat/ColossalChat%20Speed.jpg; https://raw.githubusercontent.com/hpcaitech/public_assets/main/applications/chatgpt/ChatGPT%20scaling.png; https://raw.githubusercontent.com/hpcaitech/public_assets/main/applications/chatgpt/ChatGPT-1GPU.jpg; https://raw.githubusercontent.com/hpcaitech/public_assets/main/applications/chatgpt/LoRA%20data.jpg; https://raw.githubusercontent.com/hpcaitech/public_assets/main/colossalai/img/Stable%20Diffusion%20v2.png; https://raw.githubusercontent.com/hpcaitech/public_assets/main/colossalai/img/DreamBooth.png; https://raw.githubusercontent.com/hpcaitech/public_assets/main/colossalai/img/Stable%20Diffusion%20Inference.jpg; https://raw.githubusercontent.com/hpcaitech/public_assets/main/colossalai/img/FastFold.jpg; https://raw.githubusercontent.com/hpcaitech/public_assets/main/colossalai/img/data%20preprocessing%20with%20Intel.jpg; https://raw.githubusercontent.com/hpcaitech/public_assets/main/colossalai/img/xTrimoMultimer_Table.jpg; https://raw.githubusercontent.com/hpcaitech/public_assets/main/colossalai/img/llama2_pretraining.png; https://raw.githubusercontent.com/hpcaitech/public_assets/main/examples/images/LLaMA_pretraining.png; https://raw.githubusercontent.com/hpcaitech/public_assets/main/examples/images/MOE_training.png; https://raw.githubusercontent.com/hpcaitech/public_assets/main/colossalai/img/GPT3-v5.png; https://raw.githubusercontent.com/hpcaitech/public_assets/main/colossalai/img/GPT2.png; https://raw.githubusercontent.com/hpcaitech/public_assets/main/colossalai/img/(updated)GPT-2.png; https://raw.githubusercontent.com/hpcaitech/public_assets/main/colossalai/img/BERT.png; https://raw.githubusercontent.com/hpcaitech/public_assets/main/colossalai/img/OPT_update.png; https://raw.githubusercontent.com/hpcaitech/public_assets/main/colossalai/img/ViT.png; https://raw.githubusercontent.com/hpcaitech/public_assets/main/colossalai/img/GPT2-GPU1.png; https://raw.githubusercontent.com/hpcaitech/public_assets/main/colossalai/img/GPT2-NVME.png; https://raw.githubusercontent.com/hpcaitech/public_assets/main/colossalai/img/PaLM-GPU1.png; https://raw.githubusercontent.com/hpcaitech/public_assets/main/colossalai/img/SwiftInfer.jpg; https://raw.githubusercontent.com/hpcaitech/public_assets/main/colossalai/img/inference_GPT-3.jpg; https://raw.githubusercontent.com/hpcaitech/public_assets/main/colossalai/img/BLOOM%20serving.png,https://www.youtube.com/watch?v=KnXSfjqkKN0; https://www.youtube.com/watch?v=HcTiHzApHm0; https://www.youtube.com/watch?v=HcTiHzApHm0; https://www.youtube.com/watch?v=-qFBZFmOJfg,36541,2021-10-28T16:19:44Z
2024-03-05,https://github.com/StavC/ComPromptMized,https://raw.githubusercontent.com/StavC/ComPromptMized/master/README.md,"The paper presents Morris II, the first computer worm designed to target GenAI-powered applications within Generative AI (GenAI) ecosystems. The worm leverages adversarial self-replicating prompts to exploit GenAI models, compelling them to replicate malicious inputs, engage in harmful activities, and propagate these inputs to additional GenAI systems. Demonstrations were conducted against GenAI-powered email assistants, showing the worm's capability to spam and exfiltrate personal data under various conditions using text and images against three GenAI models. The performance of the worm, including its propagation rate and malicious activities, was evaluated to understand its impact on GenAI ecosystems. The research contributes to understanding and mitigating new forms of malware that could exploit interconnected GenAI applications.",Exploring ComPromptMized: The First Zero-click Worm in GenAI Ecosystems,"The breakthrough study of ComPromptMized unveils a pioneering zero-click worm, Morris II, targeting GenAI-powered applications, marking a digital leap in cyber-attacks within GenAI ecosystems. Demonstrating unparalleled capability, this worm manipulates GenAI services to propagate malicious activities, from data exfiltration to spam, testing against major GenAI models. Its unique method of self-replication and propagation through adversarial inputs highlights a significant vulnerability in interconnected GenAI applications, urging the need for advanced security measures. As the first of its kind, Morris II's exploration into GenAI-powered email assistants underpins the critical intersection of artificial intelligence and cybersecurity, warranting immediate attention from developers and cybersecurity experts.","Discover ComPromptMized, a groundbreaking study revealing Morris II, the first zero-click worm targeting GenAI ecosystems, capable of self-replicating malicious activities across GenAI-powered applications.",Cybersecurity Tool,"Python





        83





        8


        Built by

          





        29 stars today",https://raw.githubusercontent.com/StavC/ComPromptMized/master/Assets/Icon.png; https://raw.githubusercontent.com/StavC/ComPromptMized/master/Assets/InfoLeak.png; https://raw.githubusercontent.com/StavC/ComPromptMized/master/Assets/DJISpam.png; https://raw.githubusercontent.com/StavC/ComPromptMized/master/FlowSteering/assets/OriginalProcessedImages/America.png; https://raw.githubusercontent.com/StavC/ComPromptMized/master/FlowSteering/assets/PerturbatedImages/AmericaPerturbClassForward.png; https://raw.githubusercontent.com/StavC/ComPromptMized/master/FlowSteering/assets/OriginalProcessedImages/Cat.png; https://raw.githubusercontent.com/StavC/ComPromptMized/master/FlowSteering/assets/PerturbatedImages/CatPerturbClassForward.png; https://raw.githubusercontent.com/StavC/ComPromptMized/master/FlowSteering/assets/OriginalProcessedImages/Dji.png; https://raw.githubusercontent.com/StavC/ComPromptMized/master/FlowSteering/assets/PerturbatedImages/DjiPerturbClassForward.png; https://raw.githubusercontent.com/StavC/ComPromptMized/master/FlowSteering/assets/OriginalProcessedImages/Trump.png; https://raw.githubusercontent.com/StavC/ComPromptMized/master/FlowSteering/assets/PerturbatedImages/TrumpPerturbClassForward.png,https://www.youtube.com/watch?v=FL3qHH02Yd4,83,2024-02-26T23:21:05Z
2024-03-05,https://github.com/NanmiCoder/MediaCrawler,https://raw.githubusercontent.com/NanmiCoder/MediaCrawler/main/README.md,"This text provides a detailed overview of a repository that contains several social media crawler tools, including those for Xiaohongshu, Douyin, Kuaishou, Bilibili, and Weibo. These tools are capable of fetching a variety of data such as videos, images, comments, likes, and shares using Playwright to navigate webpages. The disclaimer emphasizes that the repository's content is for learning and reference only, forbidding commercial use and illegal activities. It absolves itself from legal liabilities arising from misuse. The document also outlines the functionalities provided by the crawlers, such as support for different login methods, keyword search, specified content fetching, data saving options, and the use of IP proxies. Installation and usage instructions are provided, including creating a Python virtual environment, installing dependencies, and running the crawler programs. The document highlights the importance of complying with legal restrictions, encourages contributions through pull requests, and includes a section for donations to support the project.",Maximizing Web Scraping Capabilities for Digital Content: A Guide to Advanced Techniques,"Discover the high efficiency of web scraping in capturing digital content across platforms like Xiaohongshu, Douyin, Kuaishou, Bilibili, and Weibo using Playwright. Learn the ethical use of scraping technology for research and study, while adhering to legal standards to avoid misuse. This post also introduces a community for crawler technology exchange, encouraging contributions and shared learning. Additionally, it outlines a step-by-step guide on setting up the environment, running the scraper, and storing data effectively. Remember, responsible use of scraping technology fosters innovation without infringing on others' rights.","Explore the art of web scraping with a focus on platforms like Xiaohongshu, Douyin, and others. Learn setup and execution tips while upholding ethical standards for data collection and usage.",Open Source Tool,"Python





        1,382





        320


        Built by

          








        23 stars today",https://raw.githubusercontent.com/NanmiCoder/MediaCrawler/main/static/images/wechat_pay.jpeg; https://raw.githubusercontent.com/NanmiCoder/MediaCrawler/main/static/images/zfb_pay.jpeg,,1382,2023-06-09T12:14:34Z
2024-03-05,https://github.com/apple/pfl-research,https://raw.githubusercontent.com/apple/pfl-research/main/README.md,"The `pfl` Python framework, designed by Apple, facilitates privacy-focused federated learning (FL) simulations for researchers, emphasizing efficient and confidential result dissemination. Not suitable for third-party FL deployments, it nonetheless offers insights beneficial for actual FL applications. It supports rapid simulations across distributed setups, adaptable API for innovative PFL concepts, scalable state-of-the-art algorithm simulations, compatibility with PyTorch and TensorFlow, and integration with diverse models (including beyond neural networks). Privacy features like differential privacy are also well-integrated. Installation is straightforward via PyPI, and resources like tutorial notebooks and benchmarks are available for immediate hands-on learning and research. Contributions to `pfl` are welcomed, with detailed guidelines provided on its website.",Introducing pfl: Revolutionizing Privacy in Federated Learning with Apple's Python Framework,"Discover 'pfl,' a cutting-edge Python framework by Apple designed for private federated learning (FL) simulations, aiming to enhance research dissemination and efficiency. This tool is exclusively crafted for researchers to conduct fast, scalable, and privacy-aware FL simulations, supporting both PyTorch and TensorFlow. Dive into flexible, powerful FL simulations with 'pfl' and contribute to open research by publishing impactful papers confidently. Whether you're experimenting with different models or integrating privacy features, 'pfl' offers the tools for groundbreaking FL advancements.","Explore 'pfl', an innovative Python framework by Apple for private federated learning simulations. Accelerate FL research with scalable, flexible simulations supporting PyTorch, TensorFlow, and robust privacy features.",Deep Learning Framework,"Python





        93





        11


        Built by

          









        21 stars today",,,93,2023-12-15T22:39:21Z
2024-03-05,https://github.com/langchain-ai/langchain,https://raw.githubusercontent.com/langchain-ai/langchain/master/README.md,"LangChain is a versatile framework aimed at building context-aware applications that leverage language models for reasoning. It offers both Python and JavaScript libraries, complete with various tools and integrations for easy creation and customization of applications. Key components include support for managing prompts, optimizing them, data retrieval, and defining agents' actions. The framework facilitates building retrieval-augmented generation systems, analyzing structured data, and creating chatbots, among other applications. LangChain includes off-the-shelf chains for quick deployment and a collection of templates and libraries like LangServe and LangGraph for REST API deployment and building stateful, multi-actor applications, respectively. LangSmith serves as a developer platform for testing, monitoring, and integrating LLM-based chains. Open-source with an MIT license, LangChain encourages community contributions to enhance its capabilities further. Installation can be done via pip or conda, and detailed documentation, use cases, and best practice guides are available online for developers.",Revolutionizing Reasoning Applications with LangChain: The Ultimate Guide,"Discover how LangChain, the advanced framework for creating context-aware reasoning applications, is transforming the development landscape. Integrating seamlessly with language models, LangChain enables applications that are not only context-aware but also capable of sophisticated reasoning. From quick installation methods via pip or conda to a comprehensive ecosystem comprising libraries, templates, and developer platforms, LangChain offers an unparalleled toolkit for developers. Explore how LangChain facilitates the creation of diverse applications, such as chatbots and retrieval augmented generation, through its modular components and pre-built chains. Embrace the future of application development with LangChainâ€™s innovative approach to utilizing language models.","Explore the capabilities of LangChain, a powerful framework designed for building context-aware reasoning applications. Discover its easy installation, diverse ecosystem, and how it revolutionizes app development with language models.",Collaborative AI Framework.,"Python





        78,287





        11,803


        Built by

          









        127 stars today",,,78287,2022-10-17T02:58:36Z
2024-03-05,https://github.com/microsoft/promptflow,https://raw.githubusercontent.com/microsoft/promptflow/main/README.md,"Prompt flow is a comprehensive toolset aimed at simplifying the development lifecycle of LLM-based AI applications, covering everything from initial idea generation, through prototyping, testing, and evaluation, to final deployment and monitoring. It facilitates prompt engineering, making it easier to develop high-quality LLM applications. Users can effortlessly create, debug, and iteratively improve their projects, ensuring they are of high quality and performant. The suite supports streamlined development for production and offers optional team collaboration features through its cloud version on Azure AI. In addition to facilitating easy setup and interaction with APIs like OpenAI, it provides a VS Code extension for an improved UI-based development experience. The project encourages community involvement through discussions, issue reporting, and contributions, aiming to continuously improve its offerings. It's licensed under MIT, welcoming contributions under a Contributor License Agreement with a focus on communal growth and adherence to a code of conduct.",Mastering Prompt Flow: Streamline Your AI Application Development,"Discover how Prompt Flow revolutionizes the development of LLM-based AI applications by making prompt engineering simpler and more efficient. Learn to create, debug, evaluate, and deploy your AI flows with ease, ensuring high quality and performance. Dive into the benefits of integrations with popular platforms and tools, and how collaborative features in the cloud version further enhance productivity. Whether you're working on your local setup or leveraging cloud platforms, Prompt Flow offers a comprehensive suite of tools to bring your AI application from concept to production seamlessly. Unlock the full potential of your AI projects with Prompt Flowâ€™s advanced features and community support.","Explore how Prompt Flow simplifies the creation, evaluation, and deployment of LLM-based AI applications. Learn about its comprehensive tools and features that support developers from ideation to production.",AI Coding Assistant,"Python





        7,508





        574


        Built by

          









        11 stars today",https://raw.githubusercontent.com/microsoft/promptflow/main/examples/tutorials/quick-start/media/vsc.png,,7508,2023-06-30T06:03:06Z
2024-03-05,https://github.com/odoo/odoo,https://raw.githubusercontent.com/odoo/odoo/master/README.md,"Odoo is a comprehensive suite of web-based, open-source business applications. It offers a variety of apps including Open Source CRM, Website Builder, eCommerce, Warehouse Management, Project Management, Billing & Accounting, Point of Sale, Human Resources, Marketing, and Manufacturing. These apps can operate independently or integrate seamlessly to function as a complete Open Source ERP system. The platform provides a range of resources to get started, including detailed setup instructions, an eLearning platform, and a business game named Scale-up to help users learn the software. Additionally, developers have access to tutorials to begin building with Odoo. The provided links offer further assistance, documentation, and access to nightly builds.",Maximizing Business Efficiency with Odoo: A Comprehensive Guide to Open Source Apps,"Discover the potential of Odoo, a suite of web-based, open-source business applications designed to enhance efficiency. From CRM and eCommerce to project management and accounting, Odoo offers a versatile range of apps that can operate independently or together as a fully integrated ERP system. Ideal for businesses seeking scalable solutions, Odooâ€™s diverse apps are seamlessly integrated, ensuring a cohesive and comprehensive business management platform. Learn how to get started with Odoo and leverage its full capabilities to drive your business forward.","Explore the benefits of Odoo, a suite of open-source business apps for CRM, eCommerce, project management, and more. Learn how Odoo can streamline operations and boost efficiency across your business.",Open Source ERP,"Python





        33,653





        21,853


        Built by

          









        32 stars today",,,33653,2014-05-13T15:38:58Z
2024-03-05,https://github.com/tiangolo/fastapi,https://raw.githubusercontent.com/aappleby/hancho/main/README.md,"Hancho is a streamlined build system inspired by Ninja's speed and simplicity and Bazel's syntax and extensibility. It is coded in under 500 lines of Python, requiring no separate installationâ€”users simply copy it into their source tree. Unlike Ninja, Hancho doesn't mandate a separate build rule for each output file, and akin to Bazel, it allows invoking build rules like function calls with keyword arguments. However, it uniquely allows build rules to execute arbitrary Python code. Aimed at small to medium projects, Hancho has seen recent updates, including improvements in formatting and the handling of unrecognized command line flags. It supports parallel job execution, verbose and quiet modes, dry runs, debugging, and forced rebuilds. A simple example provided demonstrates compiling and linking a ""Hello World"" program in C++.",Simplify Your Build Process with Hancho: The Easy-to-Integrate Build System,"Discover Hancho, the minimalist build system inspired by Ninja's speed and Bazel's syntax, designed for simplicity and extensibility. Requiring no installation and fitting comfortably in under 500 lines of Python, Hancho streamlines the build process for small to medium projects without the complexity. Unlike traditional systems, Hancho allows invoking build rules as functions and integrating custom Python code, offering flexibility and speed. Perfect for developers seeking an efficient and straightforward building solution, Hancho simplifies while it accelerates.","Explore Hancho, a compact build system blending Ninja's speed with Bazel's extensibility in under 500 lines of Python. Ideal for small to medium projects, it simplifies the build process without sacrificing functionality.",Software Development,"Python





        68,924





        5,759


        Built by

          








        55 stars today",https://raw.githubusercontent.com/aappleby/hancho/main/hancho_small.png,,235,2018-12-08T08:21:47Z
2024-03-06,https://github.com/vikhyat/moondream,https://raw.githubusercontent.com/vikhyat/moondream/main/README.md,"Moondream is an impressive, compact vision language model capable of running universally. The model's ability to understand and generate language based on visual input marks a significant advancement in AI. Moondream2, the latest version with 1.86 billion parameters, improves on its predecessor in various visual question answering benchmarks. It incorporates weights from renowned models SigLIP and Phi 1.5, enhancing its performance. The model can be used easily with transformers, requiring installations of several libraries and following specific Python code snippets to function optimally. However, it's updated regularly, suggesting users pin a specific version to ensure stability. Despite its capabilities, users should be cautious of its limitations like generating inaccurate or biased statements, and the potential for creating offensive content.",Introducing moondream: The Compact Vision Language Model Revolutionizing AI,"Discover moondream, a versatile vision language model with 1.86B parameters empowering AI across platforms with benchmarks surpassing its predecessors. This cutting-edge model integrates seamlessly with tools like transformers, featuring easy installation and user-friendly APIs for diverse applications. Its regular updates ensure optimal performance, though users should note potential limitations like bias and accuracy. Explore moondream for innovative AI solutions that run anywhere.","Explore the power of moondream, a cutting-edge vision language model designed for flexibility and efficiency in AI applications. Learn about its benchmarks, easy integration, and how to harness its capabilities for your AI projects.",Artificial Intelligence,"Python





        2,433





        200


        Built by

          









        90 stars today",https://raw.githubusercontent.com/vikhyat/moondream/main/assets/demo-1.jpg; https://raw.githubusercontent.com/vikhyat/moondream/main/assets/demo-2.jpg,,2433,2023-12-29T00:27:18Z
2024-03-06,https://github.com/Ryujinx/release-channel-master,https://raw.githubusercontent.com/Ryujinx/release-channel-master/master/README.md,"This text introduces a repository (repo) hosting the releases for the master build channel of Ryujinx, which is a software project. It includes a link to the releases page of the repo and a link to the main page of the Ryujinx project on GitHub. Essentially, it serves as a pointer for those interested in accessing the latest versions of the Ryujinx master build, directing users to where these releases can be found and providing a route to learn more about the Ryujinx project itself.",Exploring Ryujinx Master Build Releases: A Comprehensive Guide,"Discover what the Ryujinx master build channel has to offer by exploring its latest releases. The repository on GitHub is your ultimate source for downloading and staying updated with the most advanced versions of Ryujinx. Whether you're a developer or a gaming enthusiast, understanding these releases can enhance your emulation experience. Dive into the world of Ryujinx and unlock the full potential of your gaming adventures.","Get an in-depth look at the Ryujinx master build channel releases. Learn how to access, download, and utilize the latest versions for an improved gaming experience.",Software Development,"Python





        949





        76


        Built by

          





        13 stars today",,,949,2022-01-22T16:01:09Z
2024-03-06,https://github.com/gradio-app/gradio,https://raw.githubusercontent.com/gradio-app/gradio/main/README.md,"Gradio is an open-source Python library designed to easily create demos or web applications for machine learning models or arbitrary Python functions, without needing web development skills. Users can quickly share their applications via a built-in sharing feature, promoting user-friendly project dissemination. Gradio requires Python 3.8+ and can be installed with pip. It allows for the creation of interfaces with simple Python code enabling interactive demos. It supports various inputs and outputs, including text and sliders. Gradio offers key components for building machine learning applications such as `Interface`, `ChatInterface`, and `Blocks`, for diverse needs from simple function demonstrations to complex web apps. Additionally, Gradio integrates with other platforms and tools, forming a broad ecosystem for ML application development. It also emphasizes community engagement, bug reporting, and contributions while being under an Apache 2.0 license.",Easily Build and Share Machine Learning Web Apps with Gradio,"Discover how Gradio, an open-source Python package, empowers you to create and share ML model demos or web apps effortlessly, without web hosting or JavaScript knowledge. With Gradio, transform any Python function into a user-friendly interface, allowing for instantaneous sharing via built-in features. Perfect for machine learning enthusiasts and professionals looking to streamline their model demonstrations. Start building your first Gradio demo today with just a few lines of Python code!","Learn how to quickly build and share web applications for your machine learning models with Gradio - no web development experience required. Start creating beautiful, interactive demos in no time.",Python Libraries Collection,"Python





        26,938





        1,933


        Built by

          









        39 stars today",https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/gradio-guides/lcm-screenshot-3.gif; https://raw.githubusercontent.com/gradio-app/gradio/main/demo/hello_world_4/screenshot.gif,,26939,2018-12-19T08:24:04Z
2024-03-06,https://github.com/QwenLM/Qwen-Agent,https://raw.githubusercontent.com/QwenLM/Qwen-Agent/main/README.md,"Qwen-Agent is a development framework designed for applications utilizing large language models (LLMs) that focus on instruction following, tool usage, planning, and memory. With examples like Browser Assistant, Code Interpreter, and Custom Assistant, it showcases its versatility. To get started, users clone the repository, install dependencies, and can choose between Alibaba Cloud's DashScope or their own model service for back-end support. The framework illustrates adding custom tools to agents, like an AI painting service, and offers a detailed guide for creating a powerful agent that leverages these tools. Additionally, BrowserQwen, a Chrome extension which integrates these capabilities to assist with web page discussions, document understanding, and automated tasks, is introduced. Users must deploy a local database service and install this extension to utilize its features. The project is still evolving, warning that backward compatibility issues may arise and advising caution with the code interpreter due to the lack of a sandbox environment.",Harness the Power of Qwen-Agent for Advanced LLM Applications,"Qwen-Agent is a robust framework designed to empower developers in creating sophisticated LLM applications featuring instruction following, tool usage, planning, and memory. It supports the integration of example applications such as Browser Assistant, Code Interpreter, and Custom Assistant. By utilizing components like LLMs, prompts, and Agents, developers can easily customize and extend functionalities. The framework facilitates seamless interaction with Alibaba Cloudâ€™s DashScope or your own model services, enhancing the development of potent, tool-equipped agents. Moreover, Qwen-Agent showcases its flexibility and utility through the BrowserQwen Chrome extension for enriched browser interactions.","Explore the capabilities of Qwen-Agent for developing state-of-the-art LLM applications with features like instruction following, planning, and tool usage. Learn how to easily integrate with Alibaba Cloudâ€™s DashScope for enriched functionalities.",Collaborative AI Framework,"Python





        818





        82


        Built by

          









        10 stars today",https://qianwen-res.oss-cn-beijing.aliyuncs.com/assets/qwen_agent/logo-qwen-agent.png; https://raw.githubusercontent.com/QwenLM/Qwen-Agent/main/assets/screenshot-writing.png; https://raw.githubusercontent.com/QwenLM/Qwen-Agent/main/assets/screenshot-editor-movie.png; https://raw.githubusercontent.com/QwenLM/Qwen-Agent/main/assets/screenshot-multi-web-qa.png; https://raw.githubusercontent.com/QwenLM/Qwen-Agent/main/assets/screenshot-ci.png; https://raw.githubusercontent.com/QwenLM/Qwen-Agent/main/assets/screenshot-web-qa.png; https://raw.githubusercontent.com/QwenLM/Qwen-Agent/main/assets/screenshot-pdf-qa.png,,818,2023-09-22T02:24:56Z
2024-03-06,https://github.com/PKU-YuanGroup/Open-Sora-Plan,https://raw.githubusercontent.com/PKU-YuanGroup/Open-Sora-Plan/main/README.md,"The Open-Sora Plan, initiated by the Peking University Yuangroup and the AIGC lab, aims to recreate and build upon OpenAI's Sora project, emphasizing Video-VQVAE (VideoGPT) + DiT technologies for scalable purposes. Acknowledging limited resources, the project calls on the open-source community for contributions to complete its ambitious goals. The project is structured into primary stages, focusing on setting up the codebase and training models for improved resolution and duration, and extensions for conducting text2video experiments, enhancing video quality to 1080p, and adding more control conditions to the models. Recent updates include reorganization of codes, discussion openings, and training code availability. The project outlines a comprehensive repo structure, offers detailed installation instructions, and provides examples of dataset usage, training, and video reconstruction results. Contributors are warmly invited to aid in the project's development, which is significantly reliant on community participation and aimed at fostering advanced video generation research and applications.",Recreating Sora: A Collaborative Effort Towards Open-Sourced AI Solutions,"Join the innovative Open-Sora Plan spearheaded by the Peking University and Rabbit Exhibition AIGC Joint Lab as we aim to reconstruct Sora (OpenAI) using limited resources. This project focuses on reproducing Video-VQVAE and DiT technologies at scale and calls for the open-source community to contribute towards this goal. With a foundational infrastructure currently in place, we eagerly invite contributions to evolve this project further. Dive into this journey of continuous improvement and rapid iteration by supporting through pull requests.","Explore the Open-Sora Plan, an ambitious effort to recreate Sora (OpenAI) using Video-VQVAE and DiT at scale. Contribute to this open-source project and help advance AI technologies.",Collaborative AI Framework,"Python





        4,748





        405


        Built by

          









        2,133 stars today",https://raw.githubusercontent.com/PKU-YuanGroup/Open-Sora-Plan/main/assets/we_want_you.jpg; https://raw.githubusercontent.com/PKU-YuanGroup/Open-Sora-Plan/main/assets/framework.jpg; https://raw.githubusercontent.com/PKU-YuanGroup/Open-Sora-Plan/main/assets/rec_video_2.gif; https://raw.githubusercontent.com/PKU-YuanGroup/Open-Sora-Plan/main/assets/rec_video_0.gif; https://raw.githubusercontent.com/PKU-YuanGroup/Open-Sora-Plan/main/assets/rec_video_1.gif; https://raw.githubusercontent.com/PKU-YuanGroup/Open-Sora-Plan/main/assets/rec_video_3.gif; https://raw.githubusercontent.com/PKU-YuanGroup/Open-Sora-Plan/main/assets/loss.jpg,,4748,2024-02-20T14:01:03Z
2024-03-06,https://github.com/microsoft/Swin-Transformer,https://raw.githubusercontent.com/microsoft/Swin-Transformer/main/README.md,"The Swin Transformer repository is the official implementation of the ""Swin Transformer: Hierarchical Vision Transformer using Shifted Windows"" paper and its follow-ups. It introduces a novel architecture designed as a general-purpose backbone for computer vision tasks. The Swin Transformer achieves efficiency and effectiveness by computing representations through shifted windows, enhancing performance on benchmarks like COCO and ADE20K. It supports various tasks, including image classification, object detection, semantic segmentation, video action recognition, and self-supervised learning among others. Recent updates include integration with Nvidia's FasterTransformer for enhanced inference speed on specific GPUs, the release of models trained using feature distillation improving fine-tuning performance, and the integration of self-supervised pre-training approach SimMIM, showing its adaptability and progression towards more refined visual representation learning. Additionally, it offers pretrained models on ImageNet-1K and ImageNet-22K, demonstrating impressive results in both efficiency and accuracy across different scales of Swin Transformers.",Exploring the Swin Transformer: A Revolutionary Approach in Computer Vision,"Discover how the Swin Transformer is redefining computer vision with hierarchical vision transformers using shifted windows. Initially introduced for image classification, its capabilities now extend to object detection, instance segmentation, and beyond. The updates include significant speed improvements on GPUs, feature distillation enhancements, and new benchmarks in semantic segmentation. Dive into the Swin Transformer's journey from ICCV 2021 best paper award to setting new records in computer vision tasks.","Learn about the Swin Transformer, a groundbreaking technology in computer vision, offering advanced capabilities in image classification, object detection, and semantic segmentation. This blog post covers its latest updates, achievements, and application areas.",Computer Vision Platform,"Python





        12,580





        1,963


        Built by

          









        6 stars today",https://raw.githubusercontent.com/microsoft/Swin-Transformer/main/figures/teaser.png,,12580,2021-03-25T12:42:36Z
2024-03-06,https://github.com/PrometheusStealer/Prometheus,https://raw.githubusercontent.com/XPandora/PhysGaussian/main/README.md,"PhysGaussian introduces a method to integrate physics into 3D Gaussians for generating dynamic motion in visuals. Developed by researchers from the University of California, Los Angeles, Zhejiang University, and the University of Utah, this approach combines Newtonian dynamics with 3D Gaussian kernels, eliminating the need for traditional geometry embedding techniques. By employing a customized Material Point Method (MPM), PhysGaussian adds kinematic deformation and mechanical stress to these kernels, based on principles of continuum mechanics. This method allows seamless transition between physical simulation and visual rendering, adhering to the principle of ""what you see is what you simulate."" It demonstrates versatility in simulating a wide range of materials, such as elastic materials, plastic metals, and non-Newtonian fluids. The project, accepted by CVPR 2024, has released its code and offers a comprehensive guide for setup, simulation, and custom dynamics generation, including data preprocessing and configuration.",Exploring PhysGaussian: Innovative 3D Gaussians in Generative Dynamics,"Discover PhysGaussian, the cutting-edge method blending 3D Gaussians with physics for dynamic motion synthesis. By employing Material Point Methods, it introduces kinematic deformations and mechanical stresses to Gaussian kernels, aligning with continuum mechanics. This integration allows for high-quality, diverse material simulations without traditional geometric constraints, showcasing a wide range of applications from elastic to granular materials. The project opens new avenues in visual content creation, presenting a 'what you see is what you simulate' approach.","Delve into PhysGaussian, a novel technique integrating 3D Gaussians with physics for authentic motion synthesis, offering a seamless blend of physical dynamics and visual rendering for various materials.",Computer Vision Platform,"Python





        160





        121


        Built by

          






        27 stars today",https://raw.githubusercontent.com/XPandora/PhysGaussian/main/_resources/teaser-1.jpg,https://www.youtube.com/watch?v=V96GfcMUH2Q,704,
2024-03-06,https://github.com/XPandora/PhysGaussian,https://raw.githubusercontent.com/hpcaitech/Open-Sora/main/README.md,"Open-Sora is an open-source initiative aiming to replicate the Sora architecture, enhancing it with dynamic resolution abilities, support for various model structures, video compression methods, and parallel training optimizations. It leverages Colossal-AI for efficiencies in AI large model systems and supports multimodal model structures like adaLN-zero, cross attention, and token concat for video processing. The project uses datasets like MSR-VTT, guiding users through data preprocessing for video description tasks. Moreover, Open-Sora facilitates both training and inference phases, allowing customizations for specific needs and enabling video generation from text inputs. Acknowledgements are made to contributions from OpenAI, VideoGPT, Diffusion Transformers, Deepspeed Ulysses, and OpenDiT, from which Open-Sora has drawn significant insights and methodologies.",Revolutionizing Video AI with Open-Sora: A Comprehensive Guide,"Open-Sora, an open-source initiative powered by Colossal-AI, introduces a cutting-edge framework for creating high-performance video AI models, offering a replica of Sora's development pipeline. It uniquely supports dynamic resolution for training videos of any size, incorporates diverse model structures, and facilitates multiple video compression techniques. Moreover, Open-Sora enhances training through parallel optimizations and supports extensive datasets, including MSR-VTT and customized options. This project is a leap forward in efficient and versatile video AI model training, significantly reducing costs and expanding capabilities.","Discover Open-Sora, the open-source project revolutionizing video AI with a complete Sora reproduction solution, dynamic resolution support, and advanced parallel training optimizations.",Deep Learning Platform,"Python





        704





        18


        Built by

          






        19 stars today",https://img.shields.io/badge/å¾®ä¿¡-åŠ å…¥-green?logo=wechat&amp)](https://raw.githubusercontent.com/hpcaitech/public_assets/main/colossalai/img/WeChat.png; https://raw.githubusercontent.com/hpcaitech/public_assets/main/applications/sora/open-sora-1.png; https://raw.githubusercontent.com/hpcaitech/public_assets/main/applications/sora/open-sora-2.png,,826,2023-11-13T06:49:28Z
2024-03-06,https://github.com/mini-sora/minisora,https://raw.githubusercontent.com/anthropics/anthropic-sdk-python/main/README.md,"The Anthropic Python API library provides easy access to the Anthropic REST API for Python 3.7+ applications, supporting both synchronous and asynchronous operations using httpx. It offers type definitions for parameters and response fields, enabling clear and efficient code development. The library can be installed via pip. The documentation and full API details are available online, including examples for standard and asynchronous usage, streaming responses, and utilizing the Anthropic Bedrock API. It includes functionalities like token counting, error handling, retries, and timeout settings. The library is designed with best practices in mind, including logging, managing HTTP resources, and versioning, ensuring compatibility and ease of use. Users are encouraged to manage sensitive information securely and to contribute feedback for improvements. Python 3.7 or higher is required to use this library.",Easily Interact with Anthropic API via Python Library: A Beginner's Guide,"Exploring the Anthropic Python library unlocks seamless access to the Anthropic REST API for Python 3.7+ applications. It provides convenient synchronous and asynchronous clients, thorough documentation, and supports streaming responses, all with comprehensive type definitions. Enhance your Python projects with advanced API interaction capabilities, simplified error handling, and efficient token counting. Whether you're managing async tasks or counting tokens, this library is equipped to streamline your development process.","Discover how the Anthropic Python library facilitates easy access to the Anthropic REST API, offering synchronous and asynchronous clients, streaming responses, and simplified error handling for Python 3.7+ applications.",AI Python Client,"Python





        683





        117


        Built by

          









        232 stars today",,,689,2024-02-21T13:50:34Z
2024-03-06,https://github.com/anthropics/anthropic-sdk-python,https://raw.githubusercontent.com/AssemblyAI-Examples/Machine-Learning-From-Scratch/main/README.md,"The repository for ""Machine Learning From Scratch"" by AssemblyAI offers code from their YouTube course, featuring implementations of popular machine learning algorithms. This educational resource is designed for learners to understand and apply machine learning concepts through practical coding exercises. It's presented on AssemblyAI's YouTube channel, making it easily accessible for anyone interested in diving into the field of machine learning. The repository also acknowledges inspiration from a similar project by Python Engineer (Patrick Loeber), suggesting a community-based approach to learning and sharing knowledge in the domain of machine learning.",Learn Machine Learning with AssemblyAI's Comprehensive Course,"Dive into machine learning by exploring AssemblyAI's 'Machine Learning From Scratch' course available on YouTube. This valuable resource provides hands-on code implementations of popular ML algorithms, drawing inspiration from the notable work by Python Engineer, Patrick Loeber. Perfect for both beginners and seasoned programmers, it offers a deep dive into practical machine learning applications. Discover the ease of mastering ML algorithms through this detailed course. Start your journey into machine learning today by joining thousands of learners online.","Unlock the secrets of machine learning with AssemblyAI's 'Machine Learning From Scratch' course. Featuring hands-on code implementations and inspired by Python Engineer's work, this course is your gateway to mastering ML algorithms.",Machine Learning,"Python





        689





        79


        Built by

          









        25 stars today",,https://www.youtube.com/watch?v=p1hGz0w_OCo,519,2023-01-17T20:57:10Z
2024-03-06,https://github.com/AssemblyAI-Examples/Machine-Learning-From-Scratch,https://raw.githubusercontent.com/JoeanAmier/TikTokDownloader/master/README.md,"The text introduces TikTokDownloader, a fully open-source, free tool designed for various data collection purposes from TikTok and Douyin including video downloads, live videos, comment data, account details, and more, using the Requests module. It supports batch downloads, detailed data collection, and has features like auto-skip for already downloaded files and persistence in data collection. The software is available for Windows 10 and above users through an executable file on the project's GitHub releases page. The creator emphasizes that it's solely released on GitHub without any partnership or payment plans, warning users to beware of scams. It lists comprehensive functionalities such as downloading watermark-free videos/photosets, collecting detailed data, multi-account support, and more, alongside various modes of interaction like terminal, Web UI, and Web API. It also provides a quick start guide, information on handling cookies for accessing different features, and advises on updates, alongside a disclaimer emphasizing the user's responsibility in legal matters and absolving the authors of any liabilities. Lastly, it encourages support for the project through stars on GitHub and financial donations, providing social and contact information for further assistance or contribution.",Ultimate Guide to TikTokDownloader: Free Tool for Downloading and Collecting TikTok Data,"Discover TikTokDownloader, the go-to open-source tool for effortlessly downloading and collecting a wide range of data from TikTok and Douyin. Whether it's video, live streams, or detailed analytics you're after, TikTokDownloader has got you covered. This comprehensive guide provides everything you need to get started, including setup instructions and key features. With full Windows compatibility and no cost, start maximizing your TikTok content today without any hassle. Remember, this tool is solely available on GitHub and aims to enhance your TikTok experience securely.","Explore the capabilities of TikTokDownloader, a fully open-source tool designed for downloading and collecting diverse TikTok data, including videos, live streams, and analytics. Get started with our comprehensive guide.",Open Source Tool,"Python





        519





        178


        Built by

          






        21 stars today",https://github.com/JoeanAmier/TikTokDownloader/blob/master/static/images/TikTokDownloader.png; https://raw.githubusercontent.com/JoeanAmier/TikTokDownloader/master/docs/ç»ˆç«¯äº¤äº’æ¨¡å¼æˆªå›¾1.png; https://raw.githubusercontent.com/JoeanAmier/TikTokDownloader/master/docs/ç»ˆç«¯äº¤äº’æ¨¡å¼æˆªå›¾2.png; https://raw.githubusercontent.com/JoeanAmier/TikTokDownloader/master/docs/WebUIæ¨¡å¼æˆªå›¾1.png; https://raw.githubusercontent.com/JoeanAmier/TikTokDownloader/master/docs/WebUIæ¨¡å¼æˆªå›¾2.png; https://raw.githubusercontent.com/JoeanAmier/TikTokDownloader/master/docs/WebUIæ¨¡å¼æˆªå›¾3.png; https://raw.githubusercontent.com/JoeanAmier/TikTokDownloader/master/docs/WebAPIæ¨¡å¼æˆªå›¾.png; https://raw.githubusercontent.com/JoeanAmier/TikTokDownloader/master/docs/ç¨‹åºè¿è¡Œæ¼”ç¤º.png; https://raw.githubusercontent.com/JoeanAmier/TikTokDownloader/master/./docs/å¾®ä¿¡èµžåŠ©äºŒç»´ç .png; https://raw.githubusercontent.com/JoeanAmier/TikTokDownloader/master/./docs/æ”¯ä»˜å®èµžåŠ©äºŒç»´ç .png,,4502,2022-09-09T14:37:46Z
2024-03-06,https://github.com/JoeanAmier/TikTokDownloader,https://raw.githubusercontent.com/QwenLM/Qwen-VL/master/README.md,"The text introduces Qwen-VL-Plus and Qwen-VL-Max, upgraded models in the Qwen-VL family, supporting free access through various platforms and APIs. Qwen-VL-Plus enhances image recognition and text abilities, supporting high-definition images and extreme aspect ratios. Qwen-VL-Max improves visual reasoning and cognitive understanding, delivering optimal performance on complex tasks. Both models excel in image reasoning, detail recognition, and support for high-resolution images. They surpass other open-source models and compete with Gemini Ultra and GPT-4V in multimodal tasks, especially in Chinese question answering and text comprehension. The document includes a comparison table showcasing their superior performance across multiple benchmarks. It also mentions recent achievements, updates on Qwen-VL-Chat, and the introduction of efficient quantized models for reduced memory usage and faster inference. The evaluation section details their capabilities across standard benchmarks, TouchStone, and other multimodal benchmarks, proving their state-of-the-art performance. The document guides on requirements, quick start instructions, quantization, finetuning, demo setup, licenses, and citation for further reference.",Unveiling Qwen-VL: The Pinnacle of Multimodal AI Innovation,"Discover the groundbreaking advancements in multimodal AI with Qwen-VL and Qwen-VL-Max, the latest in the Qwen-VL series, setting new benchmarks in visual and linguistic tasks. These models excel in recognizing and understanding high-resolution images, delivering unparalleled performance across a wide array of complex challenges. With their state-of-the-art capabilities, Qwen-VL and Qwen-VL-Max not only surpass previous models but also rival the achievements of leading technologies like Gemini Ultra and GPT-4V in multimodal tasks.","Explore the latest breakthroughs in AI with Qwen-VL & Qwen-VL-Max, leading the charge in multimodal advancements. Discover their unmatched visual recognition & linguistic understanding abilities.",Collaborative AI Framework,"Python





        4,502





        697


        Built by

          





        45 stars today",https://raw.githubusercontent.com/QwenLM/Qwen-VL/master/assets/logo.jpg; https://raw.githubusercontent.com/QwenLM/Qwen-VL/master/assets/demo_vl.gif; https://raw.githubusercontent.com/QwenLM/Qwen-VL/master/assets/radar.png; https://raw.githubusercontent.com/QwenLM/Qwen-VL/master/eval_mm/mme/perception.jpg; https://raw.githubusercontent.com/QwenLM/Qwen-VL/master/eval_mm/mme/cognition.jpg; https://raw.githubusercontent.com/QwenLM/Qwen-VL/master/eval_mm/seed_bench/leaderboard.jpg; https://raw.githubusercontent.com/QwenLM/Qwen-VL/master/assets/demo_highfive.jpg; https://raw.githubusercontent.com/QwenLM/Qwen-VL/master/assets/demo_spotting_caption.jpg; https://raw.githubusercontent.com/QwenLM/Qwen-VL/master/assets/demo_highfive.jpg,,3077,2022-10-10T14:27:36Z
2024-03-06,https://github.com/QwenLM/Qwen-VL,https://raw.githubusercontent.com/budtmo/docker-android/master/README.md,"Docker-Android is a docker image designed for Android application development and testing, including native, web, and hybrid apps. It offers various advantages such as emulators with different device profiles (e.g., Samsung Galaxy S6, Nexus 4), VNC support for visual access inside the container, web-UI for log access, external emulator control via adb, cloud solution integration like Genymotion Cloud, and the ability to build projects and run different tests (Appium, Espresso). It includes images for Android versions 9.0 through 14.0 and devices ranging from phones like the Samsung Galaxy S10 to tablets like the Nexus 7. Requirements include Docker installation, virtualization support, and specific instructions for Windows and Ubuntu users. Docker-Android supports various use-cases including Android project building, UI testing with Appium, and cloud deployment. It allows custom configurations and is integrated with Genymotion for those needing resources like simulator maintenance. The project also has a ""Pro"" version offering additional features like proxy setup, language setting, headless mode, and more for sponsors.",Maximizing Android Development Efficiency with Docker-Android,"Discover the power of Docker-Android for all your Android development needs. From application development to testing, Docker-Android offers numerous advantages including emulator support for various device profiles, VNC support, and integration with cloud solutions like Genymotion Cloud. Enhance your development efficiency by leveraging Docker-Android's capabilities to build and test projects across different frameworks.","Learn how to streamline your Android app development and testing with Docker-Android. Emulator support, VNC, log sharing, and cloud integration - all in one solution.",Software Development,"Python





        3,077





        225


        Built by

          









        22 stars today",https://raw.githubusercontent.com/budtmo/docker-android/master/./images/logo_docker-android.png; https://raw.githubusercontent.com/budtmo/docker-android/master/./images/logo_genymotion_and_dockerandroid.png; https://raw.githubusercontent.com/budtmo/docker-android/master/./images/docker-android_users.png,,6941,2023-08-21T07:57:15Z
2024-03-06,https://github.com/triwinds/ns-emu-tools,https://raw.githubusercontent.com/mlc-ai/mlc-llm/main/README.md,"The Machine Learning Compilation for Large Language Models (MLC LLM) project focuses on facilitating the deployment of AI models, particularly large language models, directly onto a variety of devices through machine learning compilation techniques. It achieves high performance by leveraging compiler acceleration and supports a wide array of hardware platforms, including AMD, NVIDIA, and Apple GPUs, across different operating systems like Linux, Windows, macOS, and on web browsers via WebGPU and WASM. MLC LLM is scalable, demonstrated by its performance on various GPUs and its compatibility with different model architectures. Additionally, it offers prebuilt models and the ability to compile others not listed. For developers, MLC LLM provides a range of APIs for deployment across platforms and programming languages. Recent updates include scalable multi-GPU support, prebuilt packages for ROCm and CUDA, and the addition of various model supports. The project embraces open collaboration and encourages citations for academic and research use, highlighting its commitment to advancing the field of machine learning and AI model deployment.",Unlocking AI's Potential with MLC LLM's Universal Deployment Solution,"Discover how the Machine Learning Compilation for Large Language Models (MLC LLM) project is revolutionizing universal AI deployment. With compiler acceleration, MLC LLM enables the native deployment of large language models across various devices and platforms. It offers scalable solutions on diverse GPUs and supports a wide array of models and APIs for seamless integration. Dive into the future of accessible, high-performance AI with MLC LLM.","Explore MLC LLM's innovative approach to deploying large language models natively across devices and platforms. Learn about its scalable solutions, extensive model support, and universal APIs for seamless AI integration.",Deep Learning Platform.,"Python





        3,739





        131


        Built by

          








        22 stars today",,,16074,2022-10-22T13:46:50Z
2024-03-06,https://github.com/budtmo/docker-android,https://raw.githubusercontent.com/evalplus/evalplus/master/README.md,"EvalPlus is a comprehensive evaluation framework designed to rigorously assess Large Language Models (LLMs) for code generation (LLM4Code). Featuring significantly expanded versions of the HumanEval and MBPP benchmarksâ€”HumanEval+ and MBPP+â€”it offers 80x and 35x more tests, respectively. EvalPlus aims to provide more reliable LLM rankings through its extensive datasets, helping to highlight the robustness of code generated by various models. It also offers pre-generated LLM code samples for different models, facilitating research in LLM4Code without the need for costly benchmark reruns. To ensure thorough evaluation, EvalPlus supports running evaluations in a sandbox environment, such as Docker, and offers tools for code sanity checks and post-sanitation, improving the usability of LLM-generated code. The framework is accessible for installation via pip or directly from its GitHub repository, and detailed instructions are provided for setting up environments, generating, and evaluating code samples. Acknowledging the limitations of evaluating code over a minimal number of test cases, EvalPlus emphasizes the importance of its expanded datasets for a comprehensive assessment. The initiative's findings and methodology are detailed in a paper presented at NeurIPS'23, with supplementary materials available online, including pre-evaluated LLM code samples and tools to facilitate research and evaluation in the LLM4Code domain.",Unleashing the Power of EvalPlus: Revolutionizing LLM Code Evaluation,"Discover how EvalPlus is setting new benchmarks in the rigorous evaluation of language models for code generation (LLM4Code). With innovative datasets like HumanEval+ and MBPP+, EvalPlus provides an enhanced evaluation framework, ensuring more reliable LLM rankings and coding rigor. Dive into the significant benefits of using EvalPlus, from rigorous testing to pre-generated LLM samples, and why it's vital for advancing LLM4Code research.","Explore EvalPlus, a groundbreaking evaluation framework for LLM4Code, featuring HumanEval+ and MBPP+ for comprehensive testing. Learn how it ensures reliable LLM rankings and enhances coding rigor in our latest blog post.",Deep Learning Platform,"Python





        6,940





        1,047


        Built by

          









        28 stars today",https://raw.githubusercontent.com/evalplus/evalplus/master/./gallary/render.gif,,712,2016-12-22T13:02:48Z
2024-03-06,https://github.com/mlc-ai/mlc-llm,https://raw.githubusercontent.com/rohankishore/Youtility/main/README.md,"Youtility is a user-friendly YouTube video and playlist downloader built with PyQt6 and PyTube, free from intrusive ads. Unlike typical online download services that bombard users with misleading advertisements, Youtility offers a clean, straightforward approach to downloading YouTube content. It allows users to download single videos along with captions, entire playlists (with an audio-only option), and convert videos to Mp3 format. To get started, users can either download the executable from the Youtility GitHub releases page or run the program manually using Python. The project is open-source, with special thanks attributed to PyTube and zhiyiYo's PyQt-Fluent-Widgets for their contributions. The creator encourages support through Ko-Fi donations or GitHub Sponsorships.",Youtility: The Ultimate Ad-Free YouTube Downloader,"Discover Youtility, the ultimate solution for downloading YouTube videos and playlists without the hassle of ads or bloatware, made possible with PyQt6 and PyTube. This open-source downloader allows for effortless saving of single videos with captions, entire playlists, and even converting videos to MP3 format. Say goodbye to intrusive ads and hello to a smooth, user-friendly downloading experience with Youtility. Whether you're looking to download for offline viewing or simply want to save your favorite content ad-free, Youtility has got you covered.","Experience hassle-free YouTube downloads with Youtility, an ad-free, open-source video and playlist downloader. Get started with easy downloads and say goodbye to ads.",Open Source Tool,"Python





        16,074





        1,202


        Built by

          









        94 stars today",,,111,2023-04-29T01:59:25Z
2024-03-06,https://github.com/evalplus/evalplus,https://raw.githubusercontent.com/psf/black/main/README.md,"Black is described as an uncompromising Python code formatter, focusing on speed, determinism, and eliminating manual formatting concerns. It standardizes formatting across different projects, making code review more efficient by minimizing diffs. It is PEP 8 compliant and offers limited style configuration, prioritizing consistency and simplicity. Black supports Python 3.8+ and can also format Jupyter Notebooks with a specific installation. Users can start using Black with simple commands and further customize formatting with a `pyproject.toml` file. It's widely adopted by major open-source projects and companies. Testimonials highlight its impact on productivity and code quality. Black encourages contributions and adheres to a code of conduct aligning with the Python Communityâ€™s standards, with a touch of humor inspired by Monty Python's Flying Circus. The documentation, changelog, and a list of contributors are available online, emphasizing community involvement and the evolution of the tool.",Mastering Python Code Formatting with Black: The Uncompromising Formatter,"Discover how Black, the uncompromising Python code formatter, can revolutionize your coding workflow. By prioritizing speed, determinism, and freedom from formatting errors, Black ensures your code is consistently styled, making code review a breeze. Adopting Black means focusing more on content and less on styling, thus saving valuable time. Experience the ease of code formatting with Black and join the community of developers who trust in its reliability. Ready to streamline your Python projects? Explore Black today.","Learn how Black, the Python code formatter, simplifies and standardizes code styling, saving developers time and enhancing code review processes. Make your Python projects more efficient with Black.",Open Source Tool,"Python





        712





        63


        Built by

          









        4 stars today",https://raw.githubusercontent.com/psf/black/main/docs/_static/logo2-readme.png,https://www.youtube.com/watch?v=esZLCuWs_2Y,36992,2023-04-15T04:20:10Z
2024-03-06,https://github.com/rohankishore/Youtility,https://raw.githubusercontent.com/dagster-io/dagster/master/README.md,"As you've requested a summary without providing the specific text from the ""python_modules/dagster/README.md"", I will craft a general overview based on what such a file would typically contain. The README file for the Dagster module in Python is likely an introductory guide that explains what Dagster is, its purpose, and how to use it. Dagster is an open-source data orchestration framework for machine learning, analytics, and ETL pipelines. This file probably includes instructions on how to install Dagster, basic examples of creating and running pipelines, and links to further documentation. It might also cover contributions guidelines, license information, and how to get support or connect with the community. Depending on the specific version and updates of the Dagster module, detailed updates, and features of the current release could also be highlighted.",Ultimate Guide to Dagster Python Modules for Efficient Data Workflows,"Dive into the world of Dagster, the open-source library designed for building scalable data pipelines in Python. This quick guide covers the basics of installing and utilizing Dagster modules to enhance your data processing tasks. Discover how Dagster simplifies complex workflows, ensures data integrity, and accelerates development with its intuitive framework. Perfect for data engineers and scientists, learn how to leverage Dagster for your next project. Upgrade your data orchestration today with our insights on Python's Dagster modules.",Explore the capabilities of Dagster Python modules in our comprehensive guide. Learn to streamline your data workflows for better efficiency and reliability with our expert insights.,Data Ingestion Tool,"Python





        111





        7


        Built by

          





        12 stars today",,,9791,2024-03-02T19:02:26Z
2024-03-07,https://github.com/VAST-AI-Research/TripoSR,https://raw.githubusercontent.com/VAST-AI-Research/TripoSR/main/README.md,"TripoSR is a collaborative effort between Tripo AI and Stability AI, offering an advanced, open-source model for rapid 3D reconstruction from single images. Integrating principles from the Large Reconstruction Model, TripoSR highlights significant enhancements in speed and quality, delivering high-quality 3D models in under 0.5 seconds using NVIDIA A100 GPUs. It outperforms other open-source options in both qualitative and quantitative benchmarks across various datasets. The tool, which operates under the MIT license, comes with pre-trained models, source code, and an interactive demo, aiming to aid those in research, development, and creative fields. Installation involves Python 3.8 or greater, CUDA for GPU support, PyTorch, and other dependencies. Users can perform manual inferences or utilize a local Gradio app for interactive demonstrations. Troubleshooting tips address potential issues with CUDA compatibility and the torchmcubes library.",Exploring TripoSR: Revolutionizing 3D Reconstruction from Single Images,"TripoSR presents a groundbreaking collaboration between Tripo AI and Stability AI, setting a new standard in fast feedforward 3D reconstruction from single images. Utilizing the Large Reconstruction Model (LRM), it significantly enhances the speed and quality of 3D model generation, achieving high-quality outputs in under 0.5 seconds with an NVIDIA A100 GPU. TripoSR not only surpasses other open-source models in both qualitative and quantitative measures but also facilitates an engaging user experience with its interactive online demo and comprehensive technical report for detailed insights. This model, open-source under the MIT license, aims to empower the 3D generative AI community and content creators with cutting-edge tools and resources.","Discover TripoSR by Tripo AI and Stability AI, a cutting-edge open-source model for ultra-fast and high-quality 3D reconstruction from single images. Learn about its unique capabilities, performance benchmarks, and how it's pushing the envelope in 3D generative AI.",Image Generation Platform,"Python





        1,493





        170


        Built by

          









        175 stars today",https://raw.githubusercontent.com/VAST-AI-Research/TripoSR/main/figures/teaser800.gif; https://raw.githubusercontent.com/VAST-AI-Research/TripoSR/main/figures/comparison800.gif; https://raw.githubusercontent.com/VAST-AI-Research/TripoSR/main/figures/visual_comparisons.jpg; https://raw.githubusercontent.com/VAST-AI-Research/TripoSR/main/figures/scatter-comparison.png,,1493,2024-02-07T10:31:04Z
2024-03-07,https://github.com/iam-veeramalla/aws-devops-zero-to-hero,https://raw.githubusercontent.com/iam-veeramalla/aws-devops-zero-to-hero/main/README.md,"The ""AWS DevOps Zero to Hero"" playlist is designed to transform DevOps engineers into AWS experts in 30 days through a comprehensive program that includes practical projects, presentations, interview prep, and real-time examples. Starting with an introduction to AWS, the program covers a wide range of topics including IAM, EC2 instances, AWS networking with VPC, AWS security, and AWS Route 53. Participants will engage in hands-on projects, such as deploying web applications on EC2, configuring domains with Route 53, and setting up a secure VPC. Advanced topics include S3, AWS CLI, CloudFormation, CodeCommit, CodePipeline, CodeBuild, CodeDeploy, CloudWatch, Lambda, CloudFront, ECR, ECS, EKS, Systems Manager, Secrets Manager, and the use of Terraform for infrastructure creation. Key areas like AWS CloudTrail, Config, Elastic Load Balancer, cloud migration strategies, and AWS best practices are also covered. The program aims to equip individuals with the skills needed to manage AWS resources effectively, preparing them for AWS-related job roles with a project involving RDS on the final day.",Become an AWS DevOps Expert: Master AWS in 30 Days | Complete Guide,"Embark on a comprehensive journey to mastering AWS with our 30-day DevOps guide. From setting up your AWS account to deploying your first AWS project, this guide covers essential services like EC2, IAM, VPC, and more. With hands-on projects and real-time examples, you'll gain practical skills in AWS for DevOps applications. Discover advanced features, security best practices, and prepare for job interviews with our expert tips. Transform from zero to hero in AWS DevOps and propel your career forward.","Master AWS in 30 days with our DevOps guide. Learn EC2, IAM, VPC, and more through practical projects and real-time examples. Become an AWS DevOps expert and ace your job interviews with our comprehensive guide.",Software Development,"Python





        4,445





        5,401


        Built by

          






        16 stars today",,,4445,2023-06-19T06:13:08Z
2024-03-07,https://github.com/alibaba-damo-academy/FunASR,https://raw.githubusercontent.com/alibaba-damo-academy/FunASR/main/README.md,"FunASR is a toolkit designed to bridge the gap between academic research and industrial applications in the field of speech recognition. It facilitates the training and fine-tuning of industrial-grade speech recognition models, allowing researchers and developers to more easily conduct research and production in this area. This toolkit supports a range of features including ASR, Voice Activity Detection, Punctuation Restoration, Language Models, Speaker Verification, Diarization, and multi-talker ASR. It provides convenient scripts and tutorials for model inference and fine-tuning. FunASR has released numerous pre-trained models for academic and industrial use, which are accessible through the ModelScope and Huggingface platforms. Recently, it has added large-scale audio-text multimodal models and the Whisper-large-v3 model for multilingual speech recognition and translation. Furthermore, FunASR offers services for offline file transcription in multiple languages and real-time transcription, with support for ARM64 platform docker images. It encourages community engagement and offers guidance through documentation and community groups for users encountering issues.",Explore the Future of Speech Recognition with FunASR Toolkit,"Discover FunASR, the cutting-edge end-to-end speech recognition toolkit designed to bridge the gap between academic research and industrial application. This comprehensive toolkit supports a variety of features like ASR, Voice Activity Detection, and more, offering easy scripts for both inference and model fine-tuning. With a vast collection of pre-trained models available through Model Zoo, and new additions like multilingual speech recognition models, FunASR is set to revolutionize how we interact with technology using natural language.","Unveil the potential of FunASR Toolkit for transformative speech recognition applications, offering features like ASR, VAD, and access to a broad range of pre-trained models. Ideal for researchers and developers looking to advance the field.",Natural Language Processing,"Python





        2,654





        322


        Built by

          









        22 stars today",https://raw.githubusercontent.com/alibaba-damo-academy/FunASR/main/docs/images/funasr_logo.jpg; https://raw.githubusercontent.com/alibaba-damo-academy/FunASR/main/docs/images/dingding.jpg; https://raw.githubusercontent.com/alibaba-damo-academy/FunASR/main/docs/images/wechat.png; https://raw.githubusercontent.com/alibaba-damo-academy/FunASR/main/docs/images/alibaba.png; https://raw.githubusercontent.com/alibaba-damo-academy/FunASR/main/docs/images/nwpu.png; https://raw.githubusercontent.com/alibaba-damo-academy/FunASR/main/docs/images/China_Telecom.png; https://raw.githubusercontent.com/alibaba-damo-academy/FunASR/main/docs/images/RapidAI.png; https://raw.githubusercontent.com/alibaba-damo-academy/FunASR/main/docs/images/aihealthx.png; https://raw.githubusercontent.com/alibaba-damo-academy/FunASR/main/docs/images/XVERSE.png,,2654,2022-11-24T02:28:11Z
2024-03-07,https://github.com/openai/whisper,https://raw.githubusercontent.com/openai/whisper/main/README.md,"Whisper is an advanced speech recognition model developed by OpenAI, adept at handling multilingual recognition, translation, and identifying languages. This model, operating with a sequence-to-sequence framework built on Transformer architecture, is capable of multitasking and replaces traditional multi-stage speech processing pipelines, favoring a unified approach where tasks like speech transcription, translation, and language identification are managed through token sequence predictions. It is compatible with recent Python and PyTorch versions, requiring specific Python packages and the ffmpeg command-line tool for full functionality. Five model sizes are available, varying in parameters, memory requirements, and speed to accommodate different application needs. Performance differs across languages, with specialized English-only models offering improved accuracy in certain situations. Whisper can be easily accessed via command-line or through Python code, providing flexibility for developers. The toolkit and its models are open-source, licensed under the MIT License, promoting wide accessibility and community-driven enhancements.",Unlocking the Power of Whisper: Revolutionizing Speech Recognition,"Discover Whisper, OpenAI's groundbreaking speech recognition model, in our latest blog post. Learn how it's trained on diverse datasets to perform tasks like multilingual speech recognition, speech translation, and language identification. Explore its setup, model sizes, command-line usage, and Python integration for a comprehensive understanding. Whether you're handling English-only projects or need multilingual capabilities, Whisper offers various models to meet your needs. Dive into our discussion on its features, setup guidelines, and real-world applications today.","Explore OpenAI's Whisper: a versatile speech recognition model designed for multilingual speech processing, translation, and identification. Learn about its features, how to set it up, and leverage it for your projects.",Natural Language Processing,"Python





        57,207





        6,483


        Built by

          









        81 stars today",https://raw.githubusercontent.com/openai/whisper/main/approach.png,,57207,2022-09-16T20:02:54Z
2024-03-07,https://github.com/KimMeen/Time-LLM,https://raw.githubusercontent.com/KimMeen/Time-LLM/main/README.md,"Time-LLM is introduced as a novel framework for time series forecasting, as presented at ICLR'24. This approach leverages the capabilities of large language models (LLMs) by reprogramming them to understand and process time series data as though it were natural language. The core methodology involves transforming the input time series into textual prototype representations aligned with the LLM's processing abilities and enhancing these inputs with declarative prompts that encapsulate domain expertise and specific task directives. This enables the LLM to apply its pre-existing knowledge and reasoning capabilities to time series forecasting tasks effectively. The associated research has garnered attention, encouraging contributions and further research, as indicated by the provided links to datasets, demonstration scripts, and further literature exploring the intersection of LLMs with time series and spatio-temporal data analysis.",Revolutionizing Time Series Forecasting with Time-LLM: Unveiling the Power of LLM Reprogramming,"Discover how Time-LLM leverages the prowess of large language models (LLMs) to transform the realm of time series forecasting. This groundbreaking framework reprograms LLMs to interpret time series as a language task, fusing text prototype representations with expert knowledge for unprecedented forecasting accuracy. Its innovative approach maintains the original LLM structure, promising a new horizon in predictive analytics. Ideal for researchers and practitioners alike, Time-LLM opens up new pathways for robust time series analysis and forecasting.","Explore Time-LLM, a novel framework reprogramming LLMs for enhancing time series forecasting. Learn how it merges text prototypes with expert knowledge, maintaining LLM integrity for superior predictions.",Deep Learning Platform,"Python





        322





        45


        Built by

          









        17 stars today",https://raw.githubusercontent.com/KimMeen/Time-LLM/main/./figures/logo.png; https://raw.githubusercontent.com/KimMeen/Time-LLM/main/./figures/framework.png; https://raw.githubusercontent.com/KimMeen/Time-LLM/main/./figures/method-detailed-illustration.png,https://www.youtube.com/watch?v=L-hRexVa32k,322,2024-01-20T01:26:30Z
2024-03-07,https://github.com/traceloop/openllmetry,https://raw.githubusercontent.com/traceloop/openllmetry/main/README.md,"OpenLLMetry is an open-source project that enhances the observability of LLM (Large Language Model) applications through a set of extensions based on OpenTelemetry. Developed and maintained by Traceloop under the Apache 2.0 license, it allows seamless integration with existing observability tools like Datadog, Honeycomb, and others. The project includes standard OpenTelemetry instrumentations for LLM providers and Vector DBs, alongside a Traceloop SDK that simplifies the initial setup while ensuring compatibility with standard OpenTelemetry data formats. The documentation offers a straightforward guide for getting started, including SDK installation and usage. OpenLLMetry supports multiple destinations and instruments various services, from LLM providers like OpenAI and Anthropic to Vector DBs such as Chroma and Pinecone, along with frameworks like LangChain and Haystack. The project encourages community contributions and offers support through Slack, GitHub Discussions, and other channels, acknowledging the vital input from the community, including the naming suggestion by Patrick Debois.",Maximize Your LLM Application's Performance with OpenLLMetry: An Observability Toolkit,"OpenLLMetry offers an advanced set of extensions for monitoring and optimizing your LLM applications by integrating seamlessly with OpenTelemetry. This open-source toolkit, maintained by Traceloop under the Apache 2.0 license, is designed to enhance your existing observability stack, including Datadog and Honeycomb, among others. With easy SDK installation and support for a wide range of LLM providers and Vector DBs, OpenLLMetry ensures comprehensive observability. Whether you're looking to instrument OpenAI, Anthropic, or any major Vector DB, OpenLLMetry has got you covered. Get started today and elevate your LLM application's observability with OpenLLMetry.","Discover how OpenLLMetry can revolutionize observability for your LLM application with advanced monitoring, seamless OpenTelemetry integration, and support for major LLM providers. Maximize performance today.",Collaborative AI Framework,"Python





        891





        60


        Built by

          









        23 stars today",https://raw.githubusercontent.com/traceloop/openllmetry/main/img/logo-light.png; https://raw.githubusercontent.com/traceloop/openllmetry/main/img/logo-dark.png,,891,2023-09-02T14:42:59Z
2024-03-07,https://github.com/bclavie/RAGatouille,https://raw.githubusercontent.com/bclavie/RAGatouille/main/README.md,"RAGatouille is a tool designed for integrating state-of-the-art retrieval methods easily into any RAG pipeline, enhancing ease of use and modularity, and is supported by research. Its main goal is to simplify the integration of advanced retrieval models, like ColBERT, into RAG pipelines, bridging the gap between cutting-edge research and practical application. Despite the effectiveness of dense embeddings for retrieval tasks, recent research suggests that models like ColBERT perform better across various domains and languages, especially with limited data. However, such models are less known and harder to use. RAGatouille aims to make these advanced methods accessible and straightforward to implement, providing a solution that simplifies their use without requiring in-depth knowledge of the underlying literature. The tool includes features for training and fine-tuning ColBERT models, embedding and indexing documents for retrieval, and document retrieval, all designed to be highly customizable yet easy to deploy. RAGatouille supports Python 3.9 to 3.11, is available for download, and provides detailed documentation for users. It emphasizes modularity, allowing components to be used independently or in combination according to user needs.",Revolutionizing RAG Pipelines with RAGatouille: The Ultimate Guide,"Discover RAGatouille, a groundbreaking tool designed to seamlessly blend advanced retrieval methods into any RAG pipeline, ensuring modularity and ease-of-use. Dive into a world where the latest research meets practical application, optimizing every aspect of your RAG pipeline with state-of-the-art models. RAGatouille not only simplifies the use of complex models like ColBERT but also paves the way for enhancing performance across diverse domains. Don't miss the opportunity to elevate your RAG pipeline with RAGatouille - start by running 'pip install ragatouille'. Explore the potential of RAGatouille on GitHub and become a part of the future of retrieval methods today.","Explore RAGatouille, a cutting-edge framework for integrating state-of-the-art retrieval methods into RAG pipelines effortlessly. Enhance your projects with ease-of-use, backed by the latest research. Get started with 'pip install ragatouille'.",Open Source Tool,"Python





        1,747





        119


        Built by

          









        11 stars today",https://raw.githubusercontent.com/bclavie/RAGatouille/main/RAGatouille.png,,1747,2023-12-29T16:26:42Z
2024-03-07,https://github.com/facebookresearch/jepa,https://raw.githubusercontent.com/flowtyone/ComfyUI-Flowty-TripoSR/master/README.md,"ComfyUI-Flowty-TripoSR is a custom node integration enabling the use of TripoSR, a collaborative project by Tripo AI and Stability AI, within ComfyUI. TripoSR is an advanced, open-source model capable of fast 3D reconstruction from single images. This node is designed for experimental purposes, and contributions via PRs for enhancements are welcomed. Installation involves cloning the repo into `custom_nodes` of ComfyUI, installing dependencies, and placing the downloaded TripoSR model in the specified directory. The project acknowledges MrForExample for his contributions through the ComfyUI-3D-Pack, which facilitated 3D model display functionalities in ComfyUI. This initiative is part of a community project by flowt.ai, encouraging users to explore and contribute to its development.",Integrate 3D Reconstruction in ComfyUI with Flowty-TripoSR Node,"Discover how to elevate your ComfyUI experience by integrating the Flowty-TripoSR node, enabling state-of-the-art 3D reconstruction from single images. Thanks to the collaboration between Tripo AI and Stability AI, this open-source model, TripoSR, can now be seamlessly utilized within ComfyUI. Installation is straightforward: simply install ComfyUI, clone the Flowty-TripoSR repository into the custom_nodes directory, and you're a few steps away from transforming images into 3D models. Don't forget to download the TripoSR model and place it in the appropriate directory. This innovation not only advances ComfyUI's capabilities but also highlights the powerful collaboration within the open-source community.",Learn how to integrate TripoSR with ComfyUI using the new Flowty-TripoSR node for quick 3D model reconstruction from imagesâ€”enhance your projects with cutting-edge tech.,Custom Node Pack,"Python





        1,906





        163


        Built by

          









        165 stars today",https://raw.githubusercontent.com/flowtyone/ComfyUI-Flowty-TripoSR/master/workflow-sample.png; https://raw.githubusercontent.com/flowtyone/ComfyUI-Flowty-TripoSR/master/flowt.png,,150,2024-02-12T15:34:31Z
2024-03-07,https://github.com/flowtyone/ComfyUI-Flowty-TripoSR,https://raw.githubusercontent.com/tobymao/sqlglot/main/README.md,"SQLGlot is a versatile SQL tool that serves as a parser, transpiler, optimizer, and engine without any dependencies. It supports 21 different SQL dialects, including popular ones like DuckDB, Presto/Trino, Spark/Databricks, Snowflake, and BigQuery. SQLGlot can format SQL, translate between dialects, and customize parsing. It highlights syntax errors and dialect incompatibilities, although validation is not its primary goal. Contributions to SQLGlot are encouraged. It offers API documentation and a primer on expression trees. Installation is straightforward via PyPI or a local setup, with optional development requirements. SQLGlot uses semantic versioning. The community can engage through a Slack channel. Examples in the documentation illustrate various functionalities, including formatting, transpiling, parsing errors, unsupported errors, building and modifying SQL, SQL optimization, AST introspection, and custom dialects. SQLGlot can even execute SQL on Python dictionaries, useful for unit testing. It is used by several projects and can be further explored through its documentation and testing procedures. Benchmarks indicate its performance relative to other parsers, and while SQLGlot's main engine isn't aimed at speed, it proves useful across different tasks. Optional dependencies like dateutil extend functionality, particularly in expression simplification.",Unlock SQL Dialect Translation with SQLGlot: A Comprehensive Guide,"Discover SQLGlot, the versatile SQL parser, transpiler, optimizer, and engine with no dependencies. Effortlessly format SQL and translate between 21 different dialects like DuckDB, Presto/Trino, Spark/Databricks, Snowflake, and BigQuery. Dive into a world where customizing the parser, analyzing queries, and building SQL programmatically is made simple. With its robust performance and comprehensive test suite, SQLGlot stands out in the realm of SQL parsers. Learn more and contribute to its thriving community.","Explore SQLGlot, a no-dependency SQL parser and transpiler that supports 21 dialects. Learn how to effortlessly parse, optimize, and translate SQL, customize parsing, and contribute to its development. Perfect for developers and data engineers.",SQL Tool,"Python





        150





        17


        Built by

          





        34 stars today",,,5064,2024-03-05T10:37:31Z
2024-03-07,https://github.com/tobymao/sqlglot,https://raw.githubusercontent.com/assafelovic/gpt-researcher/master/README.md,"The GPT Researcher is an autonomous agent designed for conducting extensive online research on various topics, promising detailed, factual, and unbiased reports. This tool overcomes the limitations of current large language models (LLMs) such as outdated information and bias, by aggregating content from over 20 web sources to form objective conclusions. It runs both ""planner"" and ""execution"" agentsâ€”the planner formulates research questions, while the execution agents find related information, which is then aggregated into a research report. The system is notably efficient, completing tasks in around 3 minutes at a cost of approximately $0.1. It's built on GPT-3.5-turbo and GPT-4-turbo, optimizing costs by judicious use of resources. The GPT Researcher also includes a user-friendly web interface, support for scraping web sources with JavaScript, and the ability to export reports to PDF among other features. Contributions to the project are welcomed, and it is noted that while the tool aims to reduce bias and factual inaccuracies, users must manage and bear the costs of API usage.",Unleashing the Power of AI in Research: Discover GPT Researcher,"GPT Researcher revolutionizes online research by generating detailed, unbiased, and factual resources, utilizing the latest AI technologies for speed and efficiency. Embracing parallelized agent work, it outpaces traditional synchronous operations, offering a blend of accuracy and rapid insights for diverse tasks. Tailored for both individuals and organizations, it ensures access to reliable information, fostering informed decision-making. Its cost-effective and swift approach, completing tasks in about 3 minutes at minimal costs, positions it as a game-changer in research methodologies. Dive into the future of research with GPT Researcher and harness the full potential of AI-driven insights.","Discover how GPT Researcher employs AI to provide rapid, accurate, and unbiased online research. Learn about its features, including customization and efficient agent work, transforming data gathering for better decision-making.",AI Coding Assistant,"Python





        5,064





        500


        Built by

          









        15 stars today",https://cowriter-images.s3.amazonaws.com/architecture.png,,7377,2021-03-13T05:01:56Z
2024-03-08,https://github.com/google/maxtext,https://raw.githubusercontent.com/google/maxtext/main/README.md,"MaxText is an open-source, high performance, scalable, and simple Large Language Model (LLM) framework designed for use with Google Cloud TPUs. It achieves up to 60% model-flop utilization and easily scales from a single host to large clusters without requiring complex optimizations, leveraging the Jax and XLA compiler. Aimed at facilitating ambitious LLM projects in both research and production, MaxText is built for ease of use and modification, encouraging users to fork and adapt it to their specific requirements. It supports seamless installation and offers robust testing frameworks, detailed runtime performance results, and comparisons with alternative LLM frameworks. MaxText stands out by its pure Python implementation, emphasizing simplicity and performance, and it is comparably efficient to other leading implementations like Nvidia's Megatron-LM but focuses on encouraging direct codebase extension. Additionally, MaxText includes features for debugging and optimization, such as stack trace collection and ahead of time compilation (AOT), enhancing usability and efficiency. It also provides support for various open models, facilitating training and inference with ease.","MaxText: The High-Performance, Scalable Open-Source LLM for Ambitious Projects","MaxText, a high-performance, scalable, open-source LLM designed for Google Cloud TPUs, combines Jax and XLA compiler's power for simple, optimization-free scaling from single hosts to vast clusters. Aimed at both research and production, MaxText invites users to rapidly deploy it as-is or fork it for customized needs. Its superior model-flop utilization and inbuilt features make it ideal for ambitious LLM projects, providing a versatile, easily adaptable foundation.","Explore MaxText, an open-source LLM offering exceptional performance and scalability on Google Cloud TPUs. Perfect for ambitious LLM projects, it's designed for easy use and customization. Learn how MaxText paves the way for groundbreaking research and production applications.",Deep Learning Framework,"Python





        664





        96


        Built by

          








        11 stars today",,,664,2023-02-28T19:47:29Z
2024-03-08,https://github.com/abi/screenshot-to-code,https://raw.githubusercontent.com/abi/screenshot-to-code/main/README.md,"The ""screenshot-to-code"" application translates screenshots into code, supporting formats like HTML/Tailwind CSS, React, Bootstrap, and Vue by leveraging GPT-4 Vision or Claude 3 for code generation and DALL-E 3 for generating similar images. It recently added support for Claude 3 and the ability to clone live websites using a URL. Recent updates include video-to-app functionality, converting video or screen recordings into functioning apps, and enhanced support for Claude Sonnet 3, promising better speed and performance than GPT-4 Vision. The app requires an OpenAI API key with GPT-4 Vision access and offers detailed instructions for setup involving a React/Vite frontend and a FastAPI backend. Docker support is available for easier setup, and the app facilitates feedback and bug reporting through its GitHub issues page or Twitter. Examples on the GitHub page showcase its capabilities with various websites.",Revolutionize Web Development with the Screenshot-to-Code App,"Discover the groundbreaking app that turns screenshots into code, leveraging GPT-4 Vision or Claude 3 technologies. Whether it's HTML/Tailwind CSS, React, Bootstrap, or Vue, transform any screenshot or live website into functional code effortlessly. Newly supporting Claude 3, and enhanced with DALL-E 3 for image generation, this tool is a game-changer for developers and designers alike. Explore examples, follow updates on Twitter, and try the app with your OpenAI key today.","Transform screenshots into HTML, React, Bootstrap, or Vue code with an innovative app using GPT-4 Vision or Claude 3. Experience effortless coding and image generation with DALL-E 3. Try it now!",AI Coding Assistant,"TypeScript





        43,766





        5,117


        Built by

          









        350 stars today",https://www.buymeacoffee.com/assets/img/custom_images/orange_img.png,,43766,2023-11-14T17:53:32Z
2024-03-08,https://github.com/Azure/azure-sdk-for-python,https://raw.githubusercontent.com/Azure/azure-sdk-for-python/main/README.md,"The Azure SDK for Python repository is dedicated to the active development of the Azure SDK, tailored for Python developers. It serves as a hub for both existing Azure service consumers and those looking to integrate Azure services into their Python applications. Notably, support for Python 2.7 ceased on January 1, 2022. The SDK simplifies working with Azure services by offering separate libraries for each service, avoiding the need for a monolithic package. It requires Python 3.8 or later and organizes libraries into new releases and previous versions for both client and management purposes. New releases comply with the latest guidelines and core functionalities like retries and authentication, provided by the `azure-core` library. The documentation, including guidelines, version support policy, and a migration guide for transitioning from older versions, is available online. The project encourages community contributions and adheres to the Microsoft Open Source Code of Conduct. Security concerns should be reported to the Microsoft Security Response Center.",Ultimate Guide to Azure SDK for Python: Features & Getting Started,"Dive into the Azure SDK for Python for seamless cloud management and development. Keep up with the robust set of libraries available for various services, ensuring efficient cloud operations. Whether you're new or transitioning, there's comprehensive support and documentation to get you started. Note the shift from Python 2.7 support and explore the client and management libraries aimed at enhancing your Azure experience. Engage with the community and contribute to the ongoing development of this essential toolkit.","Explore the Azure SDK for Python: Discover new and previous versions of client and management libraries, get started with detailed documentation, and join the community. Ideal for developers and IT professionals.",AI Python Client,"Python





        4,153





        2,603


        Built by

          









        4 stars today",https://azure-sdk-impressions.azurewebsites.net/api/impressions/azure-sdk-for-python%2FREADME.png,,4153,2012-04-24T16:46:12Z
2024-03-08,https://github.com/google-deepmind/alphafold,https://raw.githubusercontent.com/google-deepmind/alphafold/main/README.md,"The text details the implementation and usage of AlphaFold v2, a deep learning algorithm by DeepMind for predicting protein structures with high accuracy. It highlights the main components: AlphaFold for individual proteins, and the work-in-progress AlphaFold-Multimer for protein complexes, alongside their documentation, technical notes, and a GitHub repository for installation and usage instructions. Requirements include a Linux machine, SSD storage for up to 3 TB of genetic database space, and a modern NVIDIA GPU. The AlphaFold system relies on several genetic databases and employs Docker for setup. It specifies detailed steps for installation, running predictions, and the expected outputs including the predicted protein structures. Additionally, it provides information on updating installations, citing the work, community contributions, and acknowledges third-party software and libraries used within AlphaFold. Lastly, it mentions the licensing for AlphaFold's code and model parameters, and how to contact the AlphaFold team.",Unlocking the Power of Protein Predictions with AlphaFold v2,"AlphaFold v2 has revolutionized the field of bioinformatics by providing a highly accurate inference pipeline for protein structure prediction. From its inception, AlphaFold has evolved to include the AlphaFold-Multimer, and the latest updates in v2.3.0 offer enhanced models and inference procedures. Its ability to predict protein structures with unprecedented accuracy has vast implications for drug discovery, understanding diseases, and synthetic biology. Reliable setup and execution require a Linux machine with significant storage and a modern NVIDIA GPU. For detailed steps on installation and execution, including using reduced databases for lower hardware requirements, see our complete guide.","Discover the revolutionary capabilities of AlphaFold v2 for protein structure prediction. Learn how to set up and run AlphaFold, including the AlphaFold-Multimer, with our concise guide on system requirements and execution steps.",Deep Learning Platform,"Python





        11,465





        2,041


        Built by

          








        12 stars today",https://raw.githubusercontent.com/google-deepmind/alphafold/main/imgs/header.jpg; https://raw.githubusercontent.com/google-deepmind/alphafold/main/imgs/casp14_predictions.gif,,11465,2021-06-17T14:06:06Z
2024-03-08,https://github.com/FlagOpen/FlagEmbedding,https://raw.githubusercontent.com/FlagOpen/FlagEmbedding/master/README.md,"FlagEmbedding is a project that enhances retrieval-augmented LLMs, featuring initiatives like Long-Context LLM, LM-Cocktail for fine-tuning, and various Dense Retrieval models. A key release, the BGE-M3, encompasses multi-linguality, multi-granularity, and multi-functionality in retrieval. It stands out for supporting all three retrieval methods and hitting new benchmarks in multi-lingual and cross-lingual evaluations. Another notable project is Activation Beacon, which extends LLM context length efficiently. LM-Cocktail merges multiple models to maintain general capabilities and facilitate new task modeling without fine-tuning. LLM Embedder caters to diverse retrieval needs of LLMs, while BGE Reranker and BGE Embedding address re-ranking and general embedding challenges, respectively. Collaborations are encouraged, with MIT License governing the project's open-source code.",Revolutionizing Language Models: FlagEmbedding's Multifaceted Approach,"FlagEmbedding stands at the forefront of developing sophisticated language models with its flagship projects including Long-Context LLMs, LM-Cocktail for fine-tuning, and groundbreaking retrieval models like BGE-M3. With projects spanning dense retrieval, rerankers, and benchmarks such as C-MTEB, FlagEmbedding is pushing the boundaries of multilingual and multi-functional embedding models. The recent release of BGE-M3 has set new standards in the field by excelling in multi-lingual, multi-granular, and multi-functional retrieval, making it an essential tool for researchers and developers alike.",Explore FlagEmbedding's innovative projects including BGE-M3 for advanced retrieval and LM-Cocktail for fine-tuning language models. Discover how it paves the way for future LLMs.,Natural Language Processing,"Python





        3,845





        248


        Built by

          









        22 stars today",,,3845,2023-08-02T02:08:11Z
2024-03-08,https://github.com/facebookresearch/llama,https://raw.githubusercontent.com/facebookresearch/llama/main/README.md,"The latest version of Llama, a significant development in large language models, has been made available to a wide audience including individuals, creators, researchers, and businesses to facilitate experimentation, innovation, and growth in a responsible manner. This release introduces pre-trained and fine-tuned Llama language models with parameters ranging from 7B to 70B, alongside the model weights and starting code. Users can access and run these models through a straightforward set-up process, with detailed examples available in the llama-recipes repository on GitHub. This initiative also includes steps for quick start and running inference, with support for different model-parallel values depending on the model. Furthermore, the release is backed by comprehensive documentation on updates, download issues resolution, and a guide on responsible use to mitigate potential risks associated with deploying the technology. Llama 2 aims to empower technology development while ensuring ethical AI advancements through its open licensing for both research and commercial use, guided by an Acceptable Use Policy.",Unleashing Llama 2: A Giant Leap in Language Model Technology,"Explore the latest advancements in language model technology with Llama 2, designed for innovators across all fields. This version offers pre-trained and finely-tuned language models ranging from 7B to 70B parameters, making it easier than ever to harness the power of AI. Access to the models is simplified, with detailed guidance for both downloading and running inferences. Embrace the future of AI research and application by diving into Llama 2, where possibilities are limitless. Ensure responsible usage with our detailed guidelines, and join a community pushing the boundaries of what's possible with AI.","Discover Llama 2, the groundbreaking language model accessible to all. With models from 7B to 70B parameters, Llama 2 is revolutionizing AI innovation and research. Learn how to start experimenting today.",Language Models,"Python





        50,782





        8,715


        Built by

          









        72 stars today",,,50782,2023-02-14T09:29:12Z
2024-03-08,https://github.com/taojy123/KeymouseGo,https://raw.githubusercontent.com/taojy123/KeymouseGo/master/README.md,"KeymouseGo is a software designed for recording and automating mouse and keyboard operations on Windows, Linux, and macOS platforms. This lightweight alternative to macro software enables users to easily record actions such as mouse clicks and keyboard inputs, and then automate them by playing back these actions as many times as needed. This can be particularly useful for repetitive tasks, allowing users to save time and effort by automating processes with previously recorded scripts. The software is developed using Python and supports customization through scripting, allowing for extended functionality beyond basic recording. Users can run scripts via a graphical interface or command line, adjust execution speed, set scripts to run multiple times, and even integrate custom extensions for advanced automation tasks. KeymouseGo is open-source, and thanks to its community and contributors, it continues to evolve with new features and improvements.",Automating Repetitive Tasks with KeymouseGo: A Comprehensive Guide,"Discover KeymouseGo, the revolutionary tool designed to record and playback mouse and keyboard actions, making repetitive tasks effortless. Whether for work or personal projects, KeymouseGo offers a simplified, green alternative to traditional automation software. It supports Windows, Linux, and macOS, making it incredibly versatile. With easy installation and use, anyone can automate their tasks, saving time and increasing productivity. Dive into the world of efficient computing with KeymouseGo!","Learn how to automate repetitive tasks easily with KeymouseGo. This guide covers installation, features, and usage on Windows, Linux, and macOS, making your work more efficient and productive.",Open Source Tool,"Python





        5,720





        876


        Built by

          









        25 stars today",https://raw.githubusercontent.com/taojy123/KeymouseGo/master/Preview.png; https://raw.githubusercontent.com/taojy123/KeymouseGo/master/jetbrains-variant-2.png,,5720,2015-01-31T04:16:37Z
2024-03-08,https://github.com/KurtBestor/Hitomi-Downloader,https://raw.githubusercontent.com/KurtBestor/Hitomi-Downloader/master/README.md,"The text introduces Hitomi-Downloader, a software designed for downloading multimedia from various online sources. It boasts a simple interface, supports download acceleration, can handle up to 24 threads per task, and offers a speed limit feature. Additionally, it supports user scripts, BitTorrent and Magnet links, as well as M3U8 and MPD format videos. Other features include a dark mode, portability, clipboard monitoring, and easy task organization. The downloader is compatible with a wide range of sites, including major ones like YouTube, Facebook, Instagram, and more specialized sites catering to different interests and media types, indicating a broad utility for users interested in content downloading.",Maximize Downloads with Hitomi Downloader: The Ultimate Guide,"Discover the power of Hitomi Downloader, your ultimate solution for fast and efficient downloading. With a simple interface, download acceleration, and support for numerous sites, it's the downloader you never knew you needed. From mainstream platforms like YouTube to niche sites, Hitomi Downloader simplifies your downloads with features like dark mode, BitTorrent support, and a clipboard monitor. Perfect for organizing tasks and multitasking, it's a must-have tool in your digital toolkit.","Explore Hitomi Downloader: A versatile tool offering download acceleration, multi-thread support, and compatibility with many sites, including YouTube, Pixiv, and more. Simplify your downloads today!",Open Source Tool,"Python





        19,003





        1,819


        Built by

          









        121 stars today",https://raw.githubusercontent.com/KurtBestor/Hitomi-Downloader/master/imgs/card_crop.png; https://raw.githubusercontent.com/KurtBestor/Hitomi-Downloader/master/imgs/how_to_download.gif,,19003,2017-11-26T09:23:06Z
2024-03-08,https://github.com/unslothai/unsloth,https://raw.githubusercontent.com/unslothai/unsloth/main/README.md,"Unsloth.ai offers tools for fine-tuning AI models like Mistral, Gemma, and Llama up to 5x faster using 70% less memory, making the process beginner-friendly and cost-efficient. Their free Colab notebooks enable users to finetune models effortlessly with significant performance enhancements, such as up to 3.9x faster speeds and up to 74% less memory usage across various models, including Gemma, Mistral, Llama-2, TinyLlama, CodeLlama, and others. The platform updates include the addition of conversational notebooks and support for Direct Preference Optimization (DPO). Unsloth.ai's collaboration with Hugging Face, evident in their blog and official documentation, highlights their integration into the broader AI community. They also offer detailed installation instructions for different environments, comprehensive documentation for model training, and extensive benchmarking data showcasing the platform's efficiency improvements in training times and memory usage across various settings, including single and multi-GPU setups.",Accelerate Your AI Project: How to Fine-tune Models Faster with Unsloth.ai,"Discover the power of Unsloth.ai, the beginner-friendly solution for accelerating Mistral, Gemma, Llama, and more with up to 70% less memory usage. By leveraging Unsloth.ai's optimized fine-tuning process on Colab, users enjoy a significant speed boost and efficiency, making AI model training more accessible than ever. Dive into using Unsloth.ai's free notebooks to supercharge your AI projects today!","Boost your AI model training with Unsloth.ai. Learn how to fine-tune AI models like Mistral, Gemma, and Llama 2-5x faster with 70% less memory on Colab. Start for free with beginner-friendly notebooks.",Deep Learning Platform,"Python





        3,905





        182


        Built by

          







        29 stars today",https://raw.githubusercontent.com/unslothai/unsloth/main/images/unsloth%20logo%20black%20text.png; https://raw.githubusercontent.com/unslothai/unsloth/main/images/start free finetune button.png; https://raw.githubusercontent.com/unslothai/unsloth/main/images/Discord button.png; https://raw.githubusercontent.com/unslothai/unsloth/main/images/buy me a coffee button.png; https://i.ibb.co/sJ7RhGG/image-41.png; https://raw.githubusercontent.com/unslothai/unsloth/main/images/made with unsloth.png; https://i.ibb.co/sJ7RhGG/image-41.png; https://i.ibb.co/sJ7RhGG/image-41.png,,3905,2023-11-29T16:50:09Z
2024-03-08,https://github.com/hiyouga/LLaMA-Factory,https://raw.githubusercontent.com/hiyouga/LLaMA-Factory/main/README.md,"LLaMA Factory is a comprehensive toolkit for fine-tuning and deploying various large language models, designed to facilitate easy customization and optimization of models for specific tasks. The toolkit supports a wide range of models, including LLaMA, Mistral, and BLOOM, among others, and provides integrated methods for pre-training, supervised fine-tuning, and more advanced techniques like reward modeling and PPO training. It also offers scalable resources, advanced algorithms, and practical tricks to enhance model performance and efficiency. The benchmarking section demonstrates the efficiency of LLaMA Factory's LoRA tuning compared to traditional methods, showing significant improvements in training speed and Rouge scores for text generation tasks. Recent updates have introduced new algorithms, support for more models, and various other enhancements. Users can train models on a single GPU or distribute the training process across multiple GPUs, customize training scripts, and evaluate model performance using supplied datasets or their own. Additionally, LLaMA Factory provides tools for integrating fine-tuned models into applications with ease, offering inference APIs, command-line interfaces, and web demonstrations.",LLaMA Factory: The Cutting-Edge Model Tuning Tools Simplified,"Discover the groundbreaking LLaMA Factory, a versatile tool for fine-tuning large language models with ease and efficiency. It supports a wide range of models and training approaches, enabling faster training and better performance with lesser resource consumption. From advanced algorithms to practical tricks, LLaMA Factory is your gateway to unlocking the full potential of AI language models.","Explore how LLaMA Factory simplifies the fine-tuning of large language models, offering faster training, advanced algorithms, and support for various models. Start optimizing your AI projects with LLaMA Factory today.",Collaborative AI Framework,"Python





        12,758





        1,576


        Built by

          









        72 stars today",https://raw.githubusercontent.com/hiyouga/LLaMA-Factory/main/assets/logo.png,,12758,2023-05-28T10:09:12Z
2024-03-08,https://github.com/JoeanAmier/XHS-Downloader,https://raw.githubusercontent.com/JoeanAmier/XHS-Downloader/master/README.md,"XHS-Downloader is a free, open-source tool for extracting links and downloading content without watermarks from å°çº¢ä¹¦ (Xiaohongshu). It allows users to gather content information, download links, and store data efficiently. The tool can automate downloads, manage file integrity, customize download formats, and organize content into folders. It supports both programmatic and command-line usage, with extensive features for working with å°çº¢ä¹¦ content. Additionally, a user script is available for those using the Tampermonkey browser extension, offering a convenient way to experience the project's functionality without installation. XHS-Downloader emphasizes legal and ethical use, providing a GNU General Public License v3.0, and disclaims any responsibility for misuse or legal implications. Users are encouraged to contribute through stars or donations and can contact the author for support or further inquiry.",Ultimate Guide to XHS-Downloader: Download Xiaohongshu Content with Ease,"Discover the power of XHS-Downloader, the ultimate tool for downloading content from Xiaohongshu without watermarks. This comprehensive guide covers everything from setting up and using the downloader to advanced features like custom download formats and API support. Whether you're downloading for personal use or exploring content curation, XHS-Downloader offers a robust solution free of charge, ensuring you stay ahead in content gathering without compromising on quality.","Learn how to use XHS-Downloader to effortlessly download and curate content from Xiaohongshu. This guide offers insights into its features, setup, and advanced functionalities for watermark-free downloads.",Document Conversion Tool,"Python





        2,866





        381


        Built by

          








        68 stars today",https://raw.githubusercontent.com/JoeanAmier/XHS-Downloader/master/static/XHS-Downloader.png; https://raw.githubusercontent.com/JoeanAmier/XHS-Downloader/master/static/screenshot/ç¨‹åºè¿è¡Œæˆªå›¾CN1.png; https://raw.githubusercontent.com/JoeanAmier/XHS-Downloader/master/static/screenshot/ç¨‹åºè¿è¡Œæˆªå›¾CN2.png; https://raw.githubusercontent.com/JoeanAmier/XHS-Downloader/master/static/screenshot/ç¨‹åºè¿è¡Œæˆªå›¾CN3.png; https://raw.githubusercontent.com/JoeanAmier/XHS-Downloader/master/static/screenshot/ç”¨æˆ·è„šæœ¬æˆªå›¾1.png; https://raw.githubusercontent.com/JoeanAmier/XHS-Downloader/master/static/screenshot/ç”¨æˆ·è„šæœ¬æˆªå›¾2.png; https://raw.githubusercontent.com/JoeanAmier/XHS-Downloader/master/static/screenshot/èŽ·å–Cookieç¤ºæ„å›¾.png; https://raw.githubusercontent.com/JoeanAmier/XHS-Downloader/master/./static/å¾®ä¿¡èµžåŠ©äºŒç»´ç .png; https://raw.githubusercontent.com/JoeanAmier/XHS-Downloader/master/./static/æ”¯ä»˜å®èµžåŠ©äºŒç»´ç .png,,2866,2023-08-16T11:03:36Z
2024-03-08,https://github.com/WZMIAOMIAO/deep-learning-for-image-processing,https://raw.githubusercontent.com/WZMIAOMIAO/deep-learning-for-image-processing/master/README.md,"This tutorial summarizes the author's research during their postgraduate studies, aiming to assist others in learning about deep learning applications in image processing. It will be shared through videos, covering the structure and innovation of networks, and their construction and training using PyTorch and TensorFlow (with Keras). Various models are addressed, including LeNet, AlexNet, VGGNet, GoogLeNet, ResNet, ResNeXt, MobileNet, ShuffleNet, EfficientNet, Vision Transformer, Swin Transformer, ConvNeXt, and MobileViT for image classification. There's also content on object detection with Faster R-CNN, SSD, YOLO series, FCOS; semantic segmentation with FCN, DeepLabV3, LR-ASPP, U-Net, U2Net; instance segmentation with Mask R-CNN; and keypoint detection with HRNet. The tutorial provides links to videos for detailed explanations and coding tutorials. The recommended environment includes Anaconda3, Python 3.6/3.7/3.8, PyCharm, PyTorch 1.10, torchvision 0.11.1, and TensorFlow 2.4.1. The creator encourages following their WeChat public account for learning summaries and discusses further on their CSDN blog and Bilibili channel.",Unlocking the Power of Deep Learning in Image Processing: A Comprehensive Tutorial,"Dive into the transformative world of image processing with our detailed tutorial on deep learning applications. From structure and innovation in neural networks to hands-on training using Pytorch and TensorFlow, we break down complex concepts into understandable bits. Enhance your skills with downloadable course materials and stay ahead with updates on the latest in deep learning technology. Whether you're a beginner or looking to refine your knowledge, this guide provides invaluable insights into the future of image analysis.","Explore the applications of deep learning in image processing with our expert guide. Learn about neural network structures, Pytorch and TensorFlow training, and access downloadable course materials for a comprehensive understanding.",Deep Learning Platform,"Python





        19,942





        7,623


        Built by

          






        49 stars today",,,19942,2019-11-14T15:02:27Z
2024-03-08,https://github.com/lm-sys/FastChat,https://raw.githubusercontent.com/lm-sys/FastChat/main/README.md,"FastChat is an open platform designed for training, serving, and evaluating large language model (LLM) based chatbots, featuring its application Chatbot Arena which has processed over 6 million chat requests for more than 50 LLMs. This platform provides training and evaluation code for cutting-edge models like Vicuna and MT-Bench, and supports a distributed multi-model serving system with a web UI and OpenAI-compatible RESTful APIs. Recent updates include the release of LMSYS-Chat-1M, a conversational dataset, Vicuna v1.5, and Chatbot Arena Conversations dataset. It offers detailed installation instructions, model weights guidance, inference options for various computing environments, and notes for fine-tuning. The platform also accommodates scalability, providing OpenAI-compatible RESTful APIs, evaluation benchmarks, and fine-tuning documentation. FastChat represents a significant resource for developers interested in deploying and evaluating AI chatbots with state-of-the-art LLM technologies.",FastChat: Revolutionizing LLM-Based Chatbots with Chatbot Arena,"Discover how FastChat is transforming the landscape of language model based chatbots through its innovative platform. Harnessing the power of over 50 LLMs, FastChat facilitates over 6 million chat interactions in the Chatbot Arena, offering an unparalleled resource with over 200K human votes influencing the LLM Elo leaderboard. Dive into the cutting-edge features including multi-model training, evaluation, and a distributed serving system designed for state-of-the-art models like Vicuna and MT-Bench. Stay informed with the latest releases, including LMSYS-Chat-1M, a comprehensive real-world LLM conversation dataset. FastChat sets a new standard for chatbot development and evaluation, making it a cornerstone for researchers and developers alike.","Explore FastChat, the ultimate platform for training, serving, and evaluating LLM-based chatbots. With over 6 million chat requests and 200K human votes, FastChat's Chatbot Arena is leading the way in advanced chatbot technology and LLM evaluation. Learn about the latest updates and how you can leverage its features for your projects.",Collaborative AI Framework,"Python





        32,265





        3,962


        Built by

          









        51 stars today",https://raw.githubusercontent.com/lm-sys/FastChat/main/assets/demo_narrow.gif; https://raw.githubusercontent.com/lm-sys/FastChat/main/assets/screenshot_cli.png; https://raw.githubusercontent.com/lm-sys/FastChat/main/assets/screenshot_gui.png,,32265,2023-03-19T00:18:02Z
2024-03-08,https://github.com/parthsarthi03/raptor,https://raw.githubusercontent.com/parthsarthi03/raptor/master/README.md,"RAPTOR introduces a novel approach for retrieval-augmented language models by creating a recursive tree structure from documents, improving efficiency and context-aware information retrieval beyond the capabilities of traditional models. This method is detailed in their paper, which is available for further reading. To use RAPTOR, Python 3.8 or higher is required. Users can clone the RAPTOR repository and install its dependencies. The setup involves setting up an OpenAI API key, initializing RAPTOR, adding documents to its tree, and querying it to answer specific questions. It also allows for the customization and extension with other models for summarization, question-answering, and embedding generation, by implementing specific classes for each requirement. Additionally, RAPTOR encourages open-source contribution and is licensed under the MIT License. Citations for using RAPTOR in research are also provided.",Exploring RAPTOR: Next-Level Information Retrieval,"RAPTOR revolutionizes retrieval-augmented language models by introducing a tree-structured approach, allowing for more efficient and context-aware searching through extensive texts, overcoming traditional models' limitations. This novel method shows promise in enhancing information retrieval's accuracy and speed. For those interested in digging deeper, the original paper provides comprehensive insights into RAPTOR's methodologies and implementations, paving the way for advanced research and applications in language models.","Discover how RAPTOR leverages a recursive tree structure to enhance retrieval-augmented language models, making information retrieval more efficient and context-aware across vast texts.",Natural Language Processing,"Python





        186





        22


        Built by

          





        14 stars today",https://raw.githubusercontent.com/parthsarthi03/raptor/master/raptor.jpg; https://raw.githubusercontent.com/parthsarthi03/raptor/master/raptor.jpg,,186,2024-02-27T01:33:26Z
2024-03-09,https://github.com/jiaweizzhao/GaLore,https://raw.githubusercontent.com/jiaweizzhao/GaLore/master/README.md,"GaLore introduces a memory-efficient algorithm for training large language models (LLMs) by employing Gradient Low-Rank Projection. This strategy maintains full-parameter learning while being more memory-efficient compared to traditional low-rank adaptation methods like LoRA. GaLore's design allows it to be easily integrated with existing optimizers with minimal code changes. The repository provides installation instructions, usage examples including how to configure GaLore with different optimizers, and benchmark scenarios for pre-training and fine-tuning models on datasets like C4 and GLUE tasks. The benchmarks highlight GaLore's capability to train large models on limited hardware, for instance, training a 7B parameter model on a single NVIDIA RTX 4090 GPU. Additionally, it offers per-layer weight updates for single GPU setups, aiming for future support for multi-GPU configurations. The citation for the GaLore method is also provided for referencing in academic work.",Unlocking Memory-Efficient LLM Training with GaLore Algorithm,"Discover the revolutionary GaLore algorithm for memory-efficient Large Language Models (LLM) training, enabling full-parameter learning without the high memory cost. GaLore stands out by allowing integration with existing optimizers in just two lines of code, offering a practical solution for optimizing memory usage during LLM training. Find out how to install, configure, and utilize this groundbreaking tool for both pre-training and fine-tuning tasks, making it a game changer for researchers and developers alike.","Explore the GaLore algorithm for efficient LLM training, a memory-saving strategy that facilitates full-parameter learning with ease of integration into any optimizer. A perfect tool for enhancing LLM training and optimization.",Deep Learning Platform,"Python





        446





        47


        Built by

          





        67 stars today",https://raw.githubusercontent.com/jiaweizzhao/GaLore/master/imgs/galore_code_box.png,,446,2024-03-07T01:34:59Z
2024-03-09,https://github.com/dortania/OpenCore-Legacy-Patcher,https://raw.githubusercontent.com/dortania/OpenCore-Legacy-Patcher/main/README.md,"The OpenCore Legacy Patcher is a Python-based initiative leveraging Acidanthera's OpenCorePkg and Lilu to enable macOS functionality on both supported and unsupported Macs. Aimed primarily at revitalizing older Macs (dating back to 2007) that Apple no longer supports, it facilitates the running of macOS Big Sur and later versions. The project features support for macOS Big Sur through Sonoma, enabling native system updates, graphics acceleration for Metal and non-Metal GPUs, and advanced security measures like System Integrity Protection and Secure Boot, among others. It also unlocks additional features like Sidecar and AirPlay even on supported Macs and offers enhanced power management for non-Apple storage devices. Clean installs and upgrades are possible, excluding systems already patched with other tools due to integrity concerns. While it's aimed at Big Sur and newer versions, for Mojave and Catalina, dosdude1's patchers are recommended. Offered as-is, the project is backed by a community on Discord for support and troubleshooting.",Revitalize Your Old Mac: How OpenCore Legacy Patcher Unlocks New macOS Features,"OpenCore Legacy Patcher offers a new lease of life for unsupported Macs, enabling them to run macOS Big Sur and newer versions with ease. This Python-based project leverages Acidanthera's OpenCorePkg and Lilu to not only support systems as old as 2007 but also unlock modern features like Sidecar and AirPlay. It supports clean installs and upgrades, ensuring no firmware patching is needed for a seamless experience. Whether you're looking to extend the life of your Mac or unlock new functionalities, OpenCore Legacy Patcher is your go-to solution.",Discover how OpenCore Legacy Patcher can rejuvenate unsupported Macs by enabling macOS Big Sur and newer installations while unlocking advanced features like Sidecar and AirPlay without any firmware patching required.,Open Source Tool,"Python





        10,404





        1,025


        Built by

          









        21 stars today",https://raw.githubusercontent.com/dortania/OpenCore-Legacy-Patcher/main/images/OC-Patcher.png,,10404,2020-11-24T01:54:56Z
2024-03-09,https://github.com/langgenius/dify,https://raw.githubusercontent.com/langgenius/dify/main/README.md,"Dify is an LLM (Large Language Model) application development platform that has successfully built over 100,000 applications. It provides an integrated solution combining Backend as a Service (BaaS) and LLM Operations (LLMOps), designed for creating generative AI-native applications. Dify features a built-in Retriever-Augmented Generation (RAG) engine, and offers the ability to deploy customized Assistant APIs and GPTs based on various LLMs. Users can experiment by leveraging Dify.AI Cloud, which comes with 200 free requests to OpenAI GPT-3.5. The platform stands out due to its API-oriented programming approach, open-source ecosystem strategy, and support for a wide array of LLMs. Dify includes features such as a Prompt IDE for visual application development, a RAG engine for enhancing queries, and an AI Agent framework for customization. It encourages continuous operations through monitoring and analysis for prompt, dataset, or model improvements. The community edition of Dify can be easily installed using Docker, with further options for Kubernetes deployment through a Helm chart. Dify encourages contributions, aims to extend its language support, and offers various channels for community and support, including direct meetings for feedback and technical discussions.",Revolutionize App Development: Leveraging Dify.AI for Next-Gen AI Applications,"Dify.AI is transforming the landscape of LLM application development, having successfully aided in the creation of over 100,000 applications. By integrating BaaS with LLMOps and offering a comprehensive tech stack essential for building AI-native applications, Dify distinctively supports deployment of personalized Assistants API and GPTs tailored to various LLMs. With features like a built-in RAG engine and support for a wide array of LLMs, Dify.AI Cloud now offers a seamless experience with 200 free requests to OpenAI GPT-3.5. Dive into the future of app development by exploring Dify's unique advantages over counterparts like LangChain and Assistants API, and leverage the power of visual orchestration, continuous operations, and diverse AI Agent tools.","Discover how Dify.AI is redefining application development with its LLM platform, offering over 100,000 apps with BaaS, LLMOps, a RAG engine, and support for various LLMs including OpenAI GPT. Start your journey with 200 free OpenAI GPT-3.5 requests.",Collaborative AI Framework,"Python





        16,922





        2,159


        Built by

          









        51 stars today",https://raw.githubusercontent.com/langgenius/dify/main/./images/describe.png; https://raw.githubusercontent.com/langgenius/dify/main/./images/demo.png; https://raw.githubusercontent.com/langgenius/dify/main/./images/models.png,,16922,2023-04-12T07:40:24Z
2024-03-09,https://github.com/d2l-ai/d2l-zh,https://raw.githubusercontent.com/d2l-ai/d2l-zh/master/README.md,"""Dive into Deep Learning"" (D2L.ai), an open-source project, aims to teach deep learning concepts, background knowledge, and code in an integrated manner. It strives to be a unified resource, freely accessible online, providing technical depth to enable readers to become applied deep learning scientists. The text includes executable code to show problem-solving in practice, allowing for experimentation and learning through modification and observation. It is designed for continuous iteration by the community to stay updated with the rapidly advancing deep learning field. The book is supplemented by forums for questions and experience exchange. It is recommended by academics and industry professionals alike and is used as a textbook or reference book in universities worldwide. The project encourages community contributions and provides links for further engagement.",Mastering Deep Learning: An In-Depth Guide with D2L.ai,"Dive into the world of Deep Learning with D2L.ai, an open-source project aimed at teaching both the theoretical concepts and practical application skills needed to become an adept Deep Learning Scientist. This unified resource is freely available online, offering deep technical knowledge, runnable code examples, and a dynamic community forum for peer support. It serves as a comprehensive guide to not just understanding the mathematical foundations of deep learning, but also how to implement and improve upon these methods in real-world scenarios. Ideal for both students and professionals, D2L.ai is continuously updated to keep pace with the rapidly evolving field.","Discover how to become a deep learning expert with D2L.ai's comprehensive guide, featuring in-depth technical knowledge, practical code examples, and a supportive community forum.",Deep Learning Platform,"Python





        54,824





        10,206


        Built by

          









        82 stars today",https://raw.githubusercontent.com/d2l-ai/d2l-zh/master/static/frontpage/_images/eq.jpg; https://raw.githubusercontent.com/d2l-ai/d2l-zh/master/static/frontpage/_images/figure.jpg; https://raw.githubusercontent.com/d2l-ai/d2l-zh/master/static/frontpage/_images/code.jpg; https://raw.githubusercontent.com/d2l-ai/d2l-zh/master/static/frontpage/_images/notebook.gif; https://d2l.ai/_images/map.png,,54824,2017-08-23T04:40:24Z
2024-03-09,https://github.com/weaviate/Verba,https://raw.githubusercontent.com/weaviate/Verba/main/README.md,"Verba: The Golden RAGtriever is an open-source application designed for streamlined Retrieval-Augmented Generation (RAG), offering a user-friendly interface for efficient data exploration and insight extraction. It supports local and cloud deployment, integrating with LLM providers such as OpenAI, Cohere, and HuggingFace. Installation is straightforward via pip, and the application boasts features like advanced query resolution, effortless data import, and accelerated queries through a semantic cache. Verba combines Weaviate's Generative Search technology and Large Language Models to understand and respond to queries contextually. The tool simplifies importing documents and features a robust project architecture, welcoming community contributions and open-source development. Deployment options include pip installation, Docker, or building from source, with comprehensive support for API key configuration for various services.",Exploring Verba: The Ultimate Tool for Retrieval-Augmented Generation,"Discover Verba: The Golden RAGtriever, a groundbreaking open-source application revolutionizing Retrieval-Augmented Generation (RAG) with an intuitive, user-friendly interface. Seamlessly integrate with leading LLM providers like OpenAI, Cohere, and HuggingFace. Simplify your data analysis and insight extraction process locally or through cloud services. Get started effortlessly with Verba by installing it via pip. Join the community of forward-thinking developers and harness the power of generative search with Verba today.","Unveil the power of Verba, the open-source application designed for streamlined Retrieval-Augmented Generation (RAG). Install easily via pip and transform data analysis with leading LLM integrations.",Collaborative AI Framework,"Python





        1,861





        204


        Built by

          









        29 stars today",https://github.com/weaviate/Verba/blob/dev/img/verba.gif; https://github.com/weaviate/Verba/blob/dev/img/verba_screen.png; https://github.com/weaviate/Verba/blob/dev/img/verba_import.png; https://github.com/weaviate/Verba/blob/dev/img/verba_status.png; https://github.com/weaviate/Verba/blob/dev/img/verba_data.gif,,1861,2023-07-28T16:53:42Z
2024-03-09,https://github.com/W01fh4cker/CVE-2024-27198-RCE,https://raw.githubusercontent.com/W01fh4cker/CVE-2024-27198-RCE/main/README.md,"The text discusses the exploitation of vulnerabilities in JetBrains TeamCity, using different cyberspace search engines like Fofa, ZoomEye, Hunter.how, and Shodan to locate instances using specific query syntaxes unique to each platform. It instructs users on setting up a Python 3.9 environment with necessary libraries and highlights problems encountered during exploitation, such as issues with yakit proxy leading to failed uploads of malicious plugins, errors in making post requests after webshell upload, and the workaround of retrieving X-TC-CSRF-Token through a 403 error. Additionally, it details creating a vulnerability recurrence environment using Docker to pull and run a vulnerable TeamCity server image. References are provided for further reading on relevant CVEs addressed in the JetBrains TeamCity updates.

",A Comprehensive Guide to Mapping Cyberspace: Exploiting JetBrains TeamCity Vulnerabilities,"Discover crucial techniques for exploiting JetBrains TeamCity vulnerabilities across different platforms, including Fofa, ZoomEye, Hunter.how, and Shodan. Learn to navigate the challenges of cyber defense mechanisms, from uploading malicious plugins to mitigating post-request errors. This guide also covers setting up a vulnerable environment using Docker for practical vulnerability replication. Unlock the potential of Python scripting to automate your cybersecurity testing. Enhance your ethical hacking skills by understanding and solving common problems in cyberspace mapping.","Unveil expert strategies for exploiting JetBrains TeamCity with our in-depth guide. Learn to use Fofa, ZoomEye, Hunter.how, and Shodan for effective cyberspace mapping and overcome cybersecurity challenges.",Cybersecurity Tool,"Python





        47





        15


        Built by

          





        6 stars today",https://raw.githubusercontent.com/W01fh4cker/blog_image/main/image-20240308230546869.png; https://raw.githubusercontent.com/W01fh4cker/blog_image/main/image-20240308230808193.png; https://raw.githubusercontent.com/W01fh4cker/blog_image/main/image-20240307232348600.png; https://raw.githubusercontent.com/W01fh4cker/blog_image/main/image-20240307232404056.png,,47,2024-03-06T03:15:03Z
2024-03-09,https://github.com/prometheusdevel/Prometheus,https://raw.githubusercontent.com/prometheusdevel/Prometheus/main/README.md,"Prometheus is a tool designed for educational and research purposes, emphasizing the creator's disclaimer against its misuse for illegal acts. It features a range of functionalities aimed at system infiltration and data extraction, including GUI building, startup execution, fake errors, binding executables, and various forms of session and data theft from popular platforms and services (e.g., Discord, Steam, Epic, browsers, cryptocurrency wallets). It offers additional VIP features, such as UAC Bypass, disabling Windows Defender, audio recording, and more malicious capabilities like keylogging and file encryption. To build the stub, users need Windows 7, Python 3.10, and an internet connection. The process involves downloading Prometheus, extracting the content, and using a builder script. The VIP version, accessible via purchase, includes more advanced features, catering to users seeking further capabilities beyond the free version.",Exploring Prometheus: A Comprehensive Guide to Its Features and Capabilities,"Discover the potential of Prometheus, a versatile tool equipped with a GUI Builder, capable of executing tasks on startup, and providing robust security features along with a detailed VIP version for enhanced functionalities. It offers a wide range of features from password and session stealing across various platforms to data encryption and more, catering to both educational and research purposes. Understand the prerequisites and the step-by-step guide to build and utilize Prometheus effectively, ensuring full awareness of its capabilities and disclaimer responsibilities. Perfect for those seeking an in-depth look at its features, VIP benefits, and user requirements.","A detailed guide exploring Prometheus' functionalities, including GUI building, security features, and VIP benefits. Learn the setup requirements and how to utilize this tool responsibly with our step-by-step guide.",Cybersecurity Tool,"Python





        134





        97


        Built by

          





        30 stars today",https://raw.githubusercontent.com/prometheusdevel/Prometheus/main/logo.png; https://github.com/prometheusdevel/Prometheus/blob/main/window.png; https://github.com/prometheusdevel/Prometheus/blob/main/msg.png; https://github.com/prometheusdevel/Prometheus/blob/main/virustotal.png,,134,2023-12-19T23:16:42Z
2024-03-09,https://github.com/TobikoData/sqlmesh,https://raw.githubusercontent.com/TobikoData/sqlmesh/main/README.md,"SQLMesh is a modern framework for data transformation and modeling, offering compatibility with dbt but aiming for ease of use, accuracy, and efficiency. It allows data professionals to run and deploy transformations using SQL or Python, enhancing the efficiency, reliability, and maintenance of dbt projects without being just an alternative. Key features include semantic understanding of SQL for error checking, simple SQL definitions without Jinja + YAML, self-documenting queries, efficient never-rebuild table logic, partition-based incremental models, a Terraform-like workflow, CI/CD integrations, automatic column lineage, and data contracts with unit tests. SQLMesh encourages community interaction through its Slack, GitHub, and email, welcoming contributions. Installation is straightforward via pypi.",Revolutionize Your Data Workflows with SQLMesh: The Ultimate dbt Alternative,"Discover SQLMesh, a cutting-edge data transformation framework offering backwards compatibility with dbt and superior efficiency. With its unique features like semantic understanding of SQL, compile-time error checking, and a CI/CD bot for seamless integrations, SQLMesh not only enhances your dbt projects but sets a new standard in data modeling and transformation. Dive deeper into its capabilities, including partition-based incremental models and automatic column level lineage, to streamline your data operations. Ideal for data practitioners seeking an intuitive yet powerful tool, SQLMesh promises to make your data projects more reliable and maintainable. Get started today and join the vibrant community to excel in your data journey.","Unlock the full potential of your data with SQLMesh, a next-gen framework offering seamless dbt compatibility, enhanced efficiency, and robust features for data modeling and transformation. Explore now.",Data Transformation Tool,"Python





        1,115





        74


        Built by

          









        16 stars today",,,1115,2022-09-23T16:28:39Z
2024-03-09,https://github.com/vanna-ai/vanna,https://raw.githubusercontent.com/vanna-ai/vanna/main/README.md,"Vanna is an open-source Python framework for SQL generation using the Retrieval-Augmented Generation (RAG) method, designed to be both powerful and user-friendly. With an MIT license, it allows users to train a RAG model with their data and then generate SQL queries by simply asking questions. This tool is particularly useful for users with complex datasets, offering high accuracy, security, privacy, and the capability to self-learn from successful queries. Vanna supports any SQL database and allows for various front-end interfaces, including Jupyter Notebook, Slack, web apps, Streamlit apps, or custom interfaces. It's easy to get started with examples and detailed documentation provided for installing and using the tool. Vanna is extendable, supporting connections to any database, language models (LLMs), and vector databases, making it adaptable to future advancements in LLM technology.",Harnessing Vanna: Revolutionize Your Data with Python's RAG Framework for SQL Generation,"Explore the cutting-edge Vanna, an open-source Python framework leveraging Retrieval-Augmented Generation (RAG) for advanced SQL generation and more. Designed for simplicity, Vanna transforms data queries into actionable SQL with easy steps, empowering users with minimal technical expertise. The framework supports diverse SQL databases and integrates seamlessly with various front-end interfaces, offering versatility in deploying data-driven applications. Get started with Vanna today to unlock sophisticated data querying capabilities in your projects.","Discover how Vanna, the MIT-licensed RAG framework for SQL generation, revolutionizes data analysis by transforming simple questions into actionable SQL queries. Learn about its easy training process, interface support, and secure, private data handling.",SQL Tool,"Python





        5,668





        328


        Built by

          









        36 stars today",https://raw.githubusercontent.com/vanna-ai/vanna/main/img/vanna-readme-diagram.png; https://raw.githubusercontent.com/vanna-ai/vanna/main/img/top-10-customers.png,,5668,2023-05-13T17:26:28Z
2024-03-09,https://github.com/UpstageAI/dataverse,https://raw.githubusercontent.com/UpstageAI/dataverse/main/README.md,"Dataverse is an open-source project aimed at enhancing the ETL (Extract, Transform, Load) pipeline process using Python, particularly for data scientists, analysts, and developers. It simplifies the workflow by integrating multiple preprocessing libraries and offering easy-to-use configurations for Spark, even for those with limited familiarity. Dataverse supports collaboration through uniform preprocessing codes and is designed to be block-based, configure-based, and extensible to accommodate custom features. To use this library, prerequisites include Python (versions 3.10 to 3.11), JDK (version 11), and PySpark, with installation available via PyPi. It includes a quick start guide with examples for custom functions, testing ETL processes, and scaling out with EMR. The project encourages contributions and is licensed under the Apache-2.0 license. Acknowledged by the Data-Centric LLM Team at Upstage, Dataverse focuses on advancing data handling for Large Language Models (LLM) and is cited for its innovative approach towards a streamlined data ecosystem.",Exploring Dataverse: A Revolution in Data Engineering with Python,"Discover how Dataverse revolutionizes the ETL pipeline in data engineering, making data processing seamless for developers and data scientists alike. With its simple, block-based approach, Dataverse integrates various libraries including HuggingFace datasets, simplifies Spark, and enhances collaboration across different expertise levels, all within the Python ecosystem. Its configuration-based setup invites users at any expertise level, supporting a broad range of custom features for diverse project demands. Dive into the future of data handling with Dataverse - the open-source project leading the way in data-centric innovation for Large Language Models (LLMs).","Learn how Dataverse transforms ETL pipelines with Python, offering a user-friendly, integrated approach to data engineering, Spark simplification, and collaborative features. Unlock the power of data with Dataverse.",Data Ingestion Tool,"Python





        156





        11


        Built by

          









        20 stars today",https://raw.githubusercontent.com/UpstageAI/dataverse/main/docs/images/dataverse_logo-color.png,,156,2023-08-21T15:50:11Z
2024-03-09,https://github.com/alibaba/data-juicer,https://raw.githubusercontent.com/alibaba/data-juicer/main/README.md,"Data-Juicer is an advanced multimodal data processing system designed for enhancing the quality and digestibility of data for large language models (LLMs). It integrates a comprehensive set of features including a systematic and reusable library of operators, data recipes, and toolkits, supported by detailed data analysis and visualization capabilities. The system is optimized for efficiency, using less memory and CPU resources, and offers flexibility in handling various data formats. Data-Juicer supports community involvement through contributing to data development, research, and an array of dedicated communication platforms. The tool has been utilized across various products and research initiatives, underlining its practical application and contribution to the field of artificial intelligence and machine learning. Data-Juicer is openly developed and encourages the community to contribute to its expansion and refinement.",Revolutionizing LLM Data Processing with Data-Juicer,"Discover how Data-Juicer, a multimodal data processing system, transforms raw data into high-quality, comprehensive data for Large Language Models (LLMs). With its active updates, including DJ-SORA, and a community-driven approach, Data-Juicer invites users to contribute to the future of LLM data development and research. Join our collaborative platform to enhance LLM data processing techniques and contribute to the advancement of machine learning technologies.","Learn about Data-Juicer, an all-encompassing, multimodal data processing system designed to upgrade data for LLMs. Explore its features, community contributions, and how you can join the movement towards superior data processing.",Data Transformation Tool,"Python





        1,260





        68


        Built by

          









        7 stars today",https://img.alicdn.com/imgextra/i3/O1CN017Eq5kf27AlA2NUKef_!!6000000007757-0-tps-1280-720.jpg; https://img.alicdn.com/imgextra/i3/O1CN01QbwHJa1EV5uZwmU9c_!!6000000000356-2-tps-400-400.png; https://img.alicdn.com/imgextra/i4/O1CN01kUiDtl1HVxN6G56vN_!!6000000000764-2-tps-43-19.png; https://img.alicdn.com/imgextra/i4/O1CN01kUiDtl1HVxN6G56vN_!!6000000000764-2-tps-43-19.png; https://img.alicdn.com/imgextra/i4/O1CN01kUiDtl1HVxN6G56vN_!!6000000000764-2-tps-43-19.png; https://img.alicdn.com/imgextra/i2/O1CN01IMPeD11xYRUYLmXKO_!!6000000006455-2-tps-3620-1604.png; https://img.alicdn.com/imgextra/i1/O1CN011E99C01ndLZ55iCUS_!!6000000005112-0-tps-2701-1050.jpg; https://img.alicdn.com/imgextra/i2/O1CN019WtUPP1uhebnDlPR8_!!6000000006069-2-tps-2530-1005.png; https://img.alicdn.com/imgextra/i4/O1CN01Sk0q2U1hdRxbnQXFg_!!6000000004300-0-tps-2438-709.jpg,,1260,2023-08-01T09:16:41Z
2024-03-10,https://github.com/OpenAccess-AI-Collective/axolotl,https://raw.githubusercontent.com/OpenAccess-AI-Collective/axolotl/main/README.md,"Axolotl is an advanced tool designed for efficiently fine-tuning multiple AI models, supporting various configurations and architectures. It facilitates training of diverse Huggingface models, including llama, pythia, falcon, and mpt, and allows for extensive customization through simple YAML or CLI commands. The tool can handle different dataset formats and is equipped to work with advanced features like xformer, flash attention, and rope scaling. It supports single and multiple GPU setups through FSDP or Deepspeed and can be run locally or in the cloud with Docker. Additionally, Axolotl integrates with wandb or mlflow for logging results and checkpoints. It offers a wide range of configurations for fine-tuning, including support for fp16/fp32, various fine-tuning techniques like lora, qlora, and gptq, amongst others, ensuring compatibility with a broad spectrum of AI models. Quickstart guides, detailed documentation, and advanced setup options ensure users can effectively harness the tool for their AI development projects.",Streamlining AI Model Training: Introducing Axolotl,"Axolotl revolutionizes AI model fine-tuning with multi-architecture support, allowing customization via yaml or CLI. With compatibility for various Huggingface models and integration for multiple GPUs, it simplifies processes with Docker and logs results efficiently. Its versatility extends to diverse dataset formats and optimization techniques, enhancing productivity and performance in AI development environments.","Discover how Axolotl streamlines AI model fine-tuning across multiple architectures, offering advanced features like multiple GPU support, diverse dataset compatibility, and efficient logging. Get started with Axolotl today.",Deep Learning Platform,"Python





        4,745





        521


        Built by

          









        32 stars today",https://raw.githubusercontent.com/OpenAccess-AI-Collective/axolotl/main/image/axolotl.png; https://raw.githubusercontent.com/OpenAccess-AI-Collective/axolotl/main/image/axolotl-badge-web.png; https://raw.githubusercontent.com/OpenAccess-AI-Collective/axolotl/main/image/axolotl-badge-web.png,,4745,2023-04-14T04:25:47Z
2024-03-10,https://github.com/Vahe1994/AQLM,https://raw.githubusercontent.com/Vahe1994/AQLM/main/README.md,"The AQLM project offers a PyTorch implementation for compressing large language models through Additive Quantization, significantly reducing model size without compromising performance. It supports models from the LLaMA, Mistral, and Mixtral families and provides Google Colab examples for basic operations, streaming, and fine-tuning. Prequantized models are offered with varying arrangements that balance size, performance, and compatibility across different hardware setups for optimal inference speed and efficiency. Installation requires an inference library, and the project comes with detailed instructions for quantization, including dependencies, data processing, and model fine-tuning guidelines. Quantization can take considerable time but can be sped up with multiple GPUs. The project also includes zero-shot benchmarking via LM Evaluation Harness and details for converting quantized models into Hugging Face compatible formats. Contributions are welcome, following specific guidelines on code formatting and submission.",Revolutionize Large Language Model Compression with AQLM,"Discover the groundbreaking method to compress large language models using the Additive Quantization approach. AQLM offers a practical solution for reducing model sizes significantly while maintaining performance, as demonstrated in the official PyTorch implementation. Learn how to implement AQLM across various platforms through concise Google Colab examples, covering basic generation to fine-tuning. Dive into the capabilities of prequantized models across the LLaMA, Mistral, and Mixtral families, and explore the optimized inference kernels for both GPU and CPU that promise accuracy and speedup. Join the forefront of AI technology compression by accessing the full implementation details and supportive resources.","Learn about AQLM's revolutionary approach to compressing large language models with additive quantization. Explore the official PyTorch implementation, example demos, model capabilities, and optimized inference kernels for efficient AI compression.",Deep Learning,"Python





        442





        55


        Built by

          









        18 stars today",,,442,2024-01-12T07:51:15Z
2024-03-10,https://github.com/hatchet-dev/hatchet,https://raw.githubusercontent.com/hatchet-dev/hatchet/main/README.md,"Hatchet is presented as a state-of-the-art, distributed, and fault-tolerant task queue designed to replace cumbersome legacy systems and simplify the management of durable workloads with emphasis on concurrency, fairness, and rate limiting. It enables function distributions across a set of workers with minimal configuration, boasting features like ultra-low latency, high throughput scheduling, and built-in strategies for queue management. Hatchet is resilient by design, offering customizable retry policies and integrated error handling to swiftly recover from failures. It also provides enhanced control and visibility through features like observability, durable execution, cron, one-time scheduling, spike protection, and incremental streaming. Hatchet targets various use cases, including fairness for Generative AI, batch processing for document indexing, workflow orchestration for multi-modal systems, and correctness for event-based processing. It supports SDKs for Python, Typescript, and Go, offering quickstart guides for easy integration. Hatchet distinguishes itself from alternatives like Celery and BullMQ by leveraging Postgres for full transactional enqueueing and offering built-in task observability, aiming for ease of use and reliability. Contributions are encouraged, with a community-supported model facilitated through Discord and GitHub.",Revolutionize Your Workflow with Hatchet: The Ultimate Task Queue Solution,"Discover how Hatchet revolutionizes distributed, fault-tolerant task queues, offering unmatched latency, throughput, and flexibility for managing workloads. With features like concurrency control, rate limiting, and enhanced observability, Hatchet simplifies complex tasks across various use cases from AI fairness to workflow orchestration. Its resilience and customizable retry policies ensure your operations swiftly recover from failures, while support for multiple SDKs ensures seamless integration into your technology stack. Dive into Hatchet's capabilities and learn how it stands out from traditional queueing solutions.","Explore Hatchet, the distributed task queue designed for ultra-low latency, high throughput, and fault tolerance. Learn how it simplifies workflows with features like concurrency control and enhanced observability.",Open Source Tool,"Python





        1,895





        53


        Built by

          







        314 stars today",,,1895,2023-12-15T17:50:29Z
2024-03-10,https://github.com/ml-explore/mlx-examples,https://raw.githubusercontent.com/ml-explore/mlx-examples/main/README.md,"The MLX Examples repo provides a range of examples utilizing the MLX framework, targeting learners and developers in machine learning. It offers a starting point with the MNIST example for newcomers. Advanced use cases involve text models like Transformer training, large-scale text generation through LLaMA, Mistral, Phi-2, and a mixture-of-experts model Mixtral 8x7B, among others. In the realm of image processing, it features ResNets for image classification, Stable Diffusion for image generation, and CVAE on MNIST. Audio models include speech recognition via OpenAI's Whisper. Multimodal and other models cover joint embeddings, semi-supervised learning, and real NVP for density estimation. The repo also integrates with Hugging Face, allowing for downloading of specific models. Contributors are acknowledged and encouraged, supported by a BibTex citation for academic use, highlighting the collaborative effort behind MLX Examples by Awni Hannun, Jagrit Digani, Angelos Katharopoulos, and Ronan Collobert.",Exploring the Versatile World of MLX Framework with Practical Examples,"Discover the power of the MLX framework through a collection of standalone examples for various machine learning models. Starting with the MNIST example, learners can quickly grasp how to leverage MLX for their projects. Dive into advanced text, image, audio, and multimodal models, including Transformer language models, Image classification with ResNets, and speech recognition with Whisper. Join the MLX Community on Hugging Face to access additional resources and contribute new models. Explore, contribute, and cite the MLX Examples to bolster your machine learning research and projects.","Unlock the full potential of the MLX framework with our comprehensive guide on standalone examples, covering text, image, audio, and multimodal models. Perfect for beginners and advanced users.",Machine Learning,"Python





        4,319





        607


        Built by

          









        13 stars today",,,4319,2023-11-28T23:37:49Z
2024-03-10,https://github.com/commaai/openpilot,https://raw.githubusercontent.com/commaai/openpilot/master/README.md,"Openpilot is an open-source driver assistance system developed by comma.ai, offering features like Adaptive Cruise Control (ACC), Automated Lane Centering (ALC), Forward Collision Warning (FCW), Lane Departure Warning (LDW), and a Driver Monitoring (DM) system that alerts distracted or sleeping drivers. It supports over 250 car models and requires a comma device like the comma 3/3X for operation, along with proper car harnessing and software installation. Openpilot's development is community-driven, supported by contributions on GitHub, where enthusiasts can join discussions, contribute to the codebase, or explore development tools. The system adheres to ISO26262 guidelines, undergoes rigorous safety testing, and regularly updates its safety models. User data is uploaded by default to improve the system but can be opted out of. Openpilot is released under the MIT license, emphasizing that users must comply with local laws and acknowledge the absence of warranty and the software's alpha status for research purposes only.",Exploring openpilot: The Future of Driver Assistance Technology,"Discover openpilot, an innovative open source driver assistance system revolutionizing the driving experience. Offering features like Adaptive Cruise Control, Automated Lane Centering, and a Driver Monitoring feature, openpilot brings advanced vehicle safety and convenience to a wide range of compatible cars. Its development by comma and the community highlights a commitment to cutting-edge automotive technologies. Learn how openpilot is setting the standard for open-source driving solutions and how you can start using it today.","Explore openpilot, an open source driver assistance system transforming road safety and convenience with features like Adaptive Cruise Control, Automated Lane Centering, and more. Learn how to enhance your driving experience with openpilot.",Open Source Tool,"Python





        46,894





        8,376


        Built by

          









        18 stars today",https://cdn-images-1.medium.com/max/1600/1*C87EjxGeMPrkTuVRVWVg4w.png,https://www.youtube.com/watch?v=NmBfgOanCyk; https://www.youtube.com/watch?v=VHKyqZ7t8Gw; https://www.youtube.com/watch?v=SUIZYzxtMQs,46894,2016-11-24T01:33:30Z
2024-03-10,https://github.com/llmware-ai/llmware,https://raw.githubusercontent.com/llmware-ai/llmware/main/README.md,"LLMWare is a versatile toolkit designed for building applications using large language models (LLMs), offering quick POC development to scalable enterprise solutions. It integrates over 50 models from Hugging Face, supporting applications like Retrieval Augmented Generation (RAG) and Multi-Step Orchestration of Agent Workflows. The framework caters to all skill levels, facilitating the integration of open-source specialized models for creating sophisticated, knowledge-based applications. Key features include a model catalog for easy access to a diverse model range, a library system for organizing large knowledge collections, and query functionalities for mixed-data interrogation. Additionally, it offers simple database options for scalability and supports various models, including the SLIM series for multi-step agent workflows and the DRAGON series for robust RAG applications. LLMWare is constantly updated, aiming to simplify the deployment of fine-tuned models and maintain privacy and security in cloud environments.",Harness the Power of LLMWare: Your One-Stop Toolkit for LLM Application Development,"Discover LLMWare, the integrated framework revolutionizing LLM application development with over 50+ models from Hugging Face. Ideal for both beginners and advanced AI developers, LLMWare facilitates the rapid creation of industrial-grade, knowledge-based enterprise applications. Its focus on easy integration of open source, specialized models ensures secure, seamless connection of enterprise knowledge. Explore the endless possibilities with LLMWare and join the community to transform your LLM application projects.","Explore LLMWare, the comprehensive toolkit for developing LLM applications, featuring over 50 models from Hugging Face, easy integration, and community support.",Collaborative AI Framework,"Python





        2,791





        232


        Built by

          









        34 stars today",,https://www.youtube.com/watch?v=cQfdaTcmBpY; https://www.youtube.com/watch?v=cQfdaTcmBpY; https://www.youtube.com/watch?v=ZJyQIZNJ45E; https://www.youtube.com/watch?v=JjgqOZ2v5oU; https://www.youtube.com/watch?v=Bncvggy6m5Q; https://www.youtube.com/watch?v=BI1RlaIJcsc; https://www.youtube.com/watch?v=8aV5p3tErP0; https://www.youtube.com/watch?v=Cf-07GBZT68; https://www.youtube.com/watch?v=h2FDjUyvsKE; https://www.youtube.com/watch?v=cQfdaTcmBpY; https://www.youtube.com/watch?v=JjgqOZ2v5oU; https://www.youtube.com/watch?v=d_u7VaKu6Qk; https://www.youtube.com/watch?v=Bncvggy6m5Q; https://www.youtube.com/watch?v=ZJyQIZNJ45E; https://www.youtube.com/watch?v=h2FDjUyvsKE; https://www.youtube.com/watch?v=qITahpVDuV0; https://www.youtube.com/watch?v=9wXJgld7Yow; https://www.youtube.com/watch?v=8aV5p3tErP0; https://www.youtube.com/watch?v=VHZSaBBG-Bo; https://www.youtube.com/watch?v=O0adUfrrxi8; https://www.youtube.com/watch?v=s0KWqYg5Buk; https://www.youtube.com/watch?v=0naqpH93eEU; https://www.youtube.com/watch?v=tAGz6yR14lw; https://www.youtube.com/watch?v=qiEmLnSRDUA,2791,2023-09-29T15:19:06Z
2024-03-11,https://github.com/Bing-su/adetailer,https://raw.githubusercontent.com/Bing-su/adetailer/main/README.md,"ADetailer is an extension designed for the stable diffusion webui, utilizing ultralytics for enhanced object detection, unlike Detection Detailer which uses mmdet. It simplifies the process of installing directly from the Extensions tab without the need to download a base model from huggingface. The installation process involves adding the extension's URL, installing it, and then restarting the webui. ADetailer offers various options for customization, including selecting models to determine detection specifics, adjusting detection confidence thresholds, and configuring mask preprocessing and inpainting settings. It also supports ControlNet Inpainting with different models for various inpainting controls. Advanced options for API requests and configuration adjustments are available, alongside instructional media and a description of the supported models, which include several YOLO models for detecting faces, hands, and people with high accuracy. Users can also add custom ultralytics YOLO models. The extension works by creating an image, detecting objects to create a mask, and then inpainting based on the mask and original image.",Enhance Your AI Art: A Comprehensive Guide to Installing and Using ADetailer for Stable Diffusion,"Discover the power of ADetailer, an essential extension for stable diffusion webui, aimed at refining your AI-generated art by emphasizing precision in object detection. Learn how to effortlessly install ADetailer using a straightforward URL from the Extensions tab and navigate through its extensive options and advanced features. This extension allows for detailed adjustments and enhancements, ensuring your AI artwork stands out. Whether you're looking to improve object detection or explore inpainting options, ADetailer offers comprehensive solutions catered to creators and developers alike. Elevate your stable diffusion projects today with ADetailer's innovative capabilities.","Learn how to install and utilize ADetailer, a powerful extension for stable diffusion webui that elevates your AI-generated art through precise object detection and inpainting options. Enhance your creations with advanced features and detailed adjustments.",Computer Vision Platform,"Python





        3,469





        268


        Built by

          









        6 stars today",https://i.imgur.com/g6GdRBT.png,https://www.youtube.com/watch?v=sF3POwPUWCE; https://www.youtube.com/watch?v=urNISRdbIEg,3469,2023-04-26T07:54:51Z
2024-03-11,https://github.com/TheAlgorithms/Python,https://raw.githubusercontent.com/TheAlgorithms/Python/master/README.md,"The Algorithms - Python is a GitHub repository showcasing various algorithms implemented in Python, aiming for educational purposes. The project encourages contributions, welcoming those interested to first read through their Contribution Guidelines. Despite being primarily for learning, the implementations may not be as efficient as those in the Python standard library, urging users to exercise discretion. Additionally, it offers community channels on Discord and Gitter for discussions, questions, and help. The project also provides a directory for easier navigation and an overview of the available algorithms. Support for Gitpod and code style enforcement using pre-commit and black is highlighted through badges.",Master Python Algorithms Easily: A Beginner's Guide,"Dive into the world of Python algorithms with 'The Algorithms - Python', a comprehensive resource for learning and mastering algorithms in Python. Ideal for education, these implementations are designed for understanding rather than efficiency, making it perfect for beginners and students. Before contributing, make sure to check out the Contribution Guidelines. Join our vibrant community on Discord and Gitter to ask questions and get help. Explore our directory for an organized overview of all available algorithms.","Discover 'The Algorithms - Python', your ultimate guide to learning and mastering Python algorithms for educational purposes. Join our community and start enhancing your coding skills today!",Python Learning Journey,"Python





        176,430





        43,044


        Built by

          









        29 stars today",,,176430,2016-07-16T09:44:01Z
2024-03-11,https://github.com/Yuukiy/JavSP,https://raw.githubusercontent.com/Yuukiy/JavSP/master/README.md,"Jav Scraper Package (JavSP) is a tool designed for automatically scraping and assembling adult video (AV) metadata from multiple websites. It identifies the unique codes from video filenames, generates metadata files compatible with media server software like Emby, Jellyfin, and Kodi, and organizes video files based on specified rules. However, the project currently lacks Docker support and a graphical user interface (UI), directing users interested in these features to [@tetato/JavSP-Docker](https://github.com/tetato/JavSP-Docker). Presently, the project only offers support in Chinese, with a possibility for adding more languages based on user votes. Key functionalities include AV code recognition, handling split video files, daily automated checks of site crawlers, multithreaded scraping, downloading high-resolution covers, AI-based unconventional cover cropping, auto-updates, and title/plot translation. Installation is straightforward with options for direct software download or building from source with Python 3.8. The project is open for contributions in various formsâ€”from code and documentation to testing and genre translationâ€”welcoming community engagement. JavSP is governed by GPL-3.0 and Anti 996 Licenses, emphasizing non-commercial use, compliance with local laws, and discouragement of promotion on restricted social platforms.",Maximize Your AV Collection: The Ultimate Jav Scraper Package Guide,"Discover the power of Jav Scraper Package (JavSP), the most comprehensive AV metadata scraper collecting data from multiple sites. Tailor-made for Emby, Jellyfin, Kodi users, this tool automates the extraction of movie filenames codes, categorizes files according to preset rules, and generates metadata files without needing Docker or a WebUI. While currently supporting only Chinese, the project is open for language expansion through community votes. Dive into the world of efficient AV collection management with JavSP, strictly for educational and technical exchange purposes.","Explore JavSP, the go-to AV metadata scraper for Emby, Jellyfin, Kodi users. Automate your AV collection organization with file categorization, metadata generation, and more. Strictly for non-commercial use.",Document Conversion Tool,"Python





        1,587





        146


        Built by

          









        25 stars today",,,1587,2021-01-03T07:42:23Z
2024-03-11,https://github.com/serengil/deepface,https://raw.githubusercontent.com/serengil/deepface/master/README.md,"Deepface is a comprehensive Python framework for face recognition and analysis, covering attributes such as age, gender, emotion, and race. It encapsulates several state-of-the-art models like VGG-Face, Google FaceNet, OpenFace, Facebook DeepFace, DeepID, ArcFace, and Dlib. These models have surpassed human-level accuracy in facial recognition tasks. Deepface simplifies the face recognition process into a single line of code for various functionalities, including verification, search, and analysis, without needing deep technical knowledge of the underlying processes. It supports multiple face recognition models, offering flexibility in choosing the most suitable one for specific applications. Additionally, Deepface provides a robust facial attribute analysis module for predicting age, gender, emotions, and race. It also wraps around various face detectors, allowing for easy swapping among them based on preference for accuracy or speed. Installation is straightforward, available via PyPI, Conda, or directly from the source. Deepface also features real-time analysis capabilities, a command-line interface, an API, and Docker support for deployment. Furthermore, it is open-source under the MIT license, with an emphasis on community contributions and support.",Unlocking the Power of Deepface: A Comprehensive Guide to Advanced Face Recognition,"Deepface is transforming the world of face recognition and facial attribute analysis with its lightweight Python framework. This comprehensive tool harnesses the capabilities of state-of-the-art models like VGG-Face, Google FaceNet, and more, to exceed human-level accuracy in facial recognition tasks. From simple installation steps to a wide range of functionalities including verification, find, analysis, and real-time video analysis, Deepface proves to be invaluable for developers and researchers. Moreover, it offers extensive documentation, command line interface, and Docker support, ensuring an accessible and versatile platform for all facial recognition needs.","Explore the capabilities of Deepface, a leading Python framework for face recognition and facial attribute analysis. Learn about its easy installation, versatile functionalities including verification and analysis, and how it leverages state-of-the-art models to offer superior accuracy.",Computer Vision Platform,"Python





        9,490





        1,743


        Built by

          









        17 stars today",https://raw.githubusercontent.com/serengil/deepface/master/icon/deepface-icon-labeled.png; https://raw.githubusercontent.com/serengil/deepface/master/icon/stock-1.jpg; https://raw.githubusercontent.com/serengil/deepface/master/icon/stock-6-v2.jpg; https://raw.githubusercontent.com/serengil/deepface/master/icon/embedding.jpg; https://raw.githubusercontent.com/serengil/deepface/master/icon/model-portfolio-v8.jpg; https://raw.githubusercontent.com/serengil/deepface/master/icon/stock-2.jpg; https://raw.githubusercontent.com/serengil/deepface/master/icon/detector-portfolio-v5.jpg; https://raw.githubusercontent.com/serengil/deepface/master/icon/detector-outputs-20240302.jpg; https://raw.githubusercontent.com/serengil/deepface/master/icon/retinaface-results.jpeg; https://raw.githubusercontent.com/serengil/deepface/master/icon/stock-3.jpg; https://raw.githubusercontent.com/serengil/deepface/master/icon/deepface-api.jpg; https://raw.githubusercontent.com/serengil/deepface/master/icon/deepface-dockerized-v2.jpg; https://raw.githubusercontent.com/serengil/deepface/master/icon/patreon.png,https://www.youtube.com/watch?v=WnUVYQP4h44; https://www.youtube.com/watch?v=KRCvkNCOphE; https://www.youtube.com/watch?v=Hrjp-EStM_s; https://www.youtube.com/watch?v=i_MOwvhbLdI; https://www.youtube.com/watch?v=i_MOwvhbLdI; https://www.youtube.com/watch?v=i_MOwvhbLdI; https://www.youtube.com/watch?v=GT2UeN85BdA; https://www.youtube.com/watch?v=GZ2p2hj2H5k; https://www.youtube.com/watch?v=-c9sSJcx6wI; https://www.youtube.com/watch?v=HeKCQ6U9XmI; https://www.youtube.com/watch?v=PKKTAr3ts2s,9490,2020-02-08T20:42:28Z
2024-03-11,https://github.com/vwxyzjn/cleanrl,https://raw.githubusercontent.com/vwxyzjn/cleanrl/master/README.md,"CleanRL is a Deep Reinforcement Learning (DRL) library known for its high-quality, single-file implementations of various DRL algorithms. It's distinguished by its research-friendly features, such as detailed single-file algorithms, benchmarks for over 7 algorithms and 34 games, Tensorboard logging, local reproducibility via seeding, video capture of gameplay, and experiment management with integrations like Weights and Biases, Docker, and AWS. CleanRL is designed with accessibility and simplicity in mind, ensuring that even complex DRL algorithms are understandable for those who prefer not reading through extensive library modules. Additionally, it supports online DRL algorithms exclusively and is migrating to Gymnasium from `openai/gym`. Despite its non-modular nature limiting reuse without modification, CleanRL excels in offering an easy-to-debug framework that's conducive to both learning and rapid prototyping of DRL algorithms. The project also participates in the Open RL Benchmark, promoting transparency in experimental DRL data. CleanRL encourages community engagement through Discord and GitHub, and appreciates contributions and support from various individual and organizational contributors.",Mastering Deep Reinforcement Learning with CleanRL: A Comprehensive Guide,"Discover CleanRL, the go-to library for implementing deep reinforcement learning algorithms seamlessly. With its single-file approach for algorithm variants, CleanRL offers an easy-to-understand, research-friendly platform for deep RL enthusiasts. It is designed to scale experiments on AWS and integrates smoothly with tools like Tensorboard and Weights and Biases for enhanced experiment management. Whether you're a beginner aiming to grasp algorithmic intricacies or a researcher prototyping new features, CleanRL's minimalistic codebase is tailored for efficient learning and development.",Explore CleanRL for a simplified yet powerful approach to deep reinforcement learning. Learn how its single-file implementations and cloud integration can accelerate your RL projects and research.,Deep Learning Platform,"Python





        4,185





        501


        Built by

          









        7 stars today",https://raw.githubusercontent.com/vwxyzjn/cleanrl/master/docs/static/o1.png; https://raw.githubusercontent.com/vwxyzjn/cleanrl/master/docs/static/o2.png; https://raw.githubusercontent.com/vwxyzjn/cleanrl/master/docs/static/o3.png,https://www.youtube.com/watch?v=dm4HdGujpPs,4185,2019-06-07T16:31:50Z
2024-03-11,https://github.com/paperless-ngx/paperless-ngx,https://raw.githubusercontent.com/paperless-ngx/paperless-ngx/main/README.md,"Paperless-ngx is a document management system aimed at reducing physical paper use by transforming documents into a searchable online archive. It's the successor to Paperless and Paperless-ng, encouraging community involvement in its development. A demo, supported by DigitalOcean, showcases its capabilities, emphasizing the need for caution with sensitive information due to the lack of encryption. It features a straightforward setup using docker compose, and offers detailed documentation for installation and migration from Paperless-ng. Community contributions are welcomed, including bug fixes, enhancements, and translations facilitated through Crowdin. It supports multiple languages and allows for feature suggestions and bug reporting via GitHub. The documentation advises running Paperless-ngx on a trusted local server to maintain security, highlighting its integration with affiliated projects for enhanced compatibility.",Transform Your Documents with Paperless-ngx: The Future of Document Management,"Explore Paperless-ngx, the innovative successor to Paperless and Paperless-ng projects, designed for efficient document management. With its easy-to-use features, this system turns your physical documents into a searchable online archive, minimizing paper usage while maximizing accessibility. Supported by DigitalOcean, it offers a demo for users to experience its capabilities firsthand. Join the community movement to enhance and support Paperless-ngx, contributing to a sustainable, paperless future.","Discover Paperless-ngx, the ultimate document management system turning physical papers into a secure, searchable online archive. Experience the future of minimalistic documentation.",Open Source Tool,"Python





        15,926





        803


        Built by

          









        19 stars today",https://github.com/paperless-ngx/paperless-ngx/raw/main/resources/logo/web/png/Black%20logo%20-%20no%20background.png; https://raw.githubusercontent.com/paperless-ngx/paperless-ngx/main/docs/assets/screenshots/documents-smallcards.png,,15926,2022-02-12T21:56:52Z
2024-03-11,https://github.com/blakeblackshear/frigate,https://raw.githubusercontent.com/blakeblackshear/frigate/master/README.md,"Frigate is a comprehensive, local NVR system integrated with AI for real-time object detection, tailored for use with Home Assistant. It employs OpenCV and Tensorflow for local, real-time IP camera monitoring. Utilizing a Google Coral Accelerator, which significantly enhances performance allowing for processing of 100+ FPS with minimal overhead, is optional but recommended. The system is designed for efficiency, operating on a need-to-detect basis while minimizing resource usage. It features tight Home Assistant integration, multiprocessing for real-time performance, low-overhead motion detection, MQTT communication for broader system integration, video recording with object-based retention, continuous recording, re-streaming, and low-latency live view via WebRTC & MSE. Visit https://docs.frigate.video for more information and support development via Github Sponsors.",Maximizing Home Security: The Power of Frigate NVR with Realtime Object Detection,"Discover the future of home security with Frigate, an advanced NVR system integrating real-time object detection for IP cameras, designed for seamless use with Home Assistant. Leverage the power of OpenCV and TensorFlow for local, efficient object detection, and enhance performance with an optional Google Coral Accelerator. Experience smart home integration, minimal resource usage, and high-performance security tailored to your needs. With support for 24/7 recording, low-latency live view, and easy integration into other systems, Frigate redefines home security.","Explore Frigate NVR: A cutting-edge home security system with real-time AI object detection for IP cameras. Optimized for Home Assistant, it offers high performance, smart integration, and optional Google Coral Accelerator support.",Cybersecurity Tool,"Python





        13,991





        1,289


        Built by

          









        13 stars today",https://raw.githubusercontent.com/blakeblackshear/frigate/master/docs/static/img/frigate.png; https://raw.githubusercontent.com/blakeblackshear/frigate/master/docs/static/img/media_browser.png; https://raw.githubusercontent.com/blakeblackshear/frigate/master/docs/static/img/notification.png; https://raw.githubusercontent.com/blakeblackshear/frigate/master/docs/static/img/home-ui.png; https://raw.githubusercontent.com/blakeblackshear/frigate/master/docs/static/img/camera-ui.png; https://raw.githubusercontent.com/blakeblackshear/frigate/master/docs/static/img/events-ui.png,,13992,2019-01-26T13:52:38Z
2024-03-11,https://github.com/Mikubill/sd-webui-controlnet,https://raw.githubusercontent.com/Mikubill/sd-webui-controlnet/main/README.md,"The ControlNet extension is designed for the Stable Diffusion web UI by AUTOMATIC1111, allowing users to integrate ControlNet's image generation capabilities directly within the web interface, enhancing the original model without the need for merging. To install, users follow steps including using the ""Extensions"" tab to install from a provided URL, restarting the WebUI, downloading and correctly placing model files from ControlNet 1.1 on HuggingFace, and ensuring the model files' compatibility. The extension supports various features such as perfect support for available models, high-resolution fixes, comprehensive mask support, and a ""Pixel-Perfect"" mode. It also introduces a user-friendly GUI, supports nearly all upscaling scripts, and introduces more control modes to balance between prompts and ControlNet's influence. Additionally, a new 'reference-only' preprocessor is introduced for direct image reference guidance. ControlNet 1.1 also supports multi-ControlNet inputs, customizable control weight/start/end for detailed control mechanism, and batch mode for bulk image generation. Additionally, the extension is accessible via API or scripts for automated tasks and adds specific command line arguments for advanced configurations. MacOS support is available with specific conditions, and an archived version of the extension is maintained for those requiring exact reproduction of past results.",Enhance Your Stable Diffusion Experience with ControlNet WebUI Extension,"Discover how the ControlNet WebUI extension revolutionizes image generation in Stable Diffusion by introducing on-the-fly integration of ControlNet and other SD controls for enhanced, precise image creation. From installation to leveraging advanced features like 'Pixel-Perfect' Mode and multi-ControlNet inputs, this guide covers everything you need to boost your creative workflow. Learn about downloading models, setting up, and optimizing your experience for unparalleled image generation capabilities.","Learn how to seamlessly integrate ControlNet with Stable Diffusion web UI for advanced image generation. Get step-by-step guidance on installation, model downloads, and leveraging new features for enhanced creativity.",Image Generation Platform,"Python





        15,405





        1,807


        Built by

          









        17 stars today",https://user-images.githubusercontent.com/19834515/236641759-6c44ddf6-c7ad-4bda-92be-e90a52911d75.png; https://raw.githubusercontent.com/Mikubill/sd-webui-controlnet/main/samples/cm1.png; https://raw.githubusercontent.com/Mikubill/sd-webui-controlnet/main/samples/cm2.png; https://raw.githubusercontent.com/Mikubill/sd-webui-controlnet/main/samples/cm3.png; https://raw.githubusercontent.com/Mikubill/sd-webui-controlnet/main/samples/cm4.png; https://raw.githubusercontent.com/Mikubill/sd-webui-controlnet/main/samples/ref.png; https://user-images.githubusercontent.com/19834515/235620638-17937171-8ac1-45bc-a3cb-3aebf605b4ef.png; https://user-images.githubusercontent.com/31246794/222947416-ec9e52a4-a1d0-48d8-bb81-736bf636145e.jpeg; https://user-images.githubusercontent.com/31246794/222947435-1164e7d8-d857-42f9-ab10-2d4a4b25f33a.png; https://user-images.githubusercontent.com/31246794/222947557-5520d5f8-88b4-474d-a576-5c9cd3acac3a.png; https://user-images.githubusercontent.com/31246794/222947416-ec9e52a4-a1d0-48d8-bb81-736bf636145e.jpeg; https://user-images.githubusercontent.com/31246794/222965711-7b884c9e-7095-45cb-a91c-e50d296ba3a2.png; https://user-images.githubusercontent.com/31246794/220448620-cd3ede92-8d3f-43d5-b771-32dd8417618f.png; https://user-images.githubusercontent.com/31246794/220448619-beed9bdb-f6bb-41c2-a7df-aa3ef1f653c5.png; https://user-images.githubusercontent.com/31246794/220448613-c99a9e04-0450-40fd-bc73-a9122cefaa2c.png,,15405,2023-02-12T16:26:27Z
2024-03-11,https://github.com/datacontract/cli,https://raw.githubusercontent.com/datacontract/cli/main/README.md,"The Data Contract CLI is a versatile open-source command-line tool designed for managing Data Contracts through YAML files. It facilitates various operations such as linting data contracts, connecting to different data sources, executing schema and quality tests, detecting changes, and exporting data models to multiple formats. Developed in Python, it can be utilized directly, integrated into CI/CD pipelines, or used as a Python library. Installation options include pip, pipx, and Docker, supporting various environments and preferences. The CLI efficiently tests data contracts against actual datasets located in storage options like S3 buckets, ensuring compliance with predefined schemas and quality specifications. Furthermore, it supports programmatic use within Python, integration with Data Mesh Manager for publishing test results, and offers comprehensive documentation for installation, usage, and development setup. Import and export functionalities allow conversion of data contracts to and from different formats, facilitating interoperability and flexible data management practices.",Master Data Contract CLI: Your Ultimate Guide to Seamless Data Management,"Discover how Data Contract CLI revolutionizes data management, offering seamless integration with data sources and rigorous data quality checks. This Python-based command-line tool ensures your data contracts are lint-free, connects to various data sources, and performs comprehensive schema and quality tests. Ideal for both standalone use and integration within CI/CD pipelines, Data Contract CLI simplifies executing, exporting, and validating data contracts, making quality control more accessible than ever.","Learn how Data Contract CLI streamlines data management through linting, integration with data sources, and executing schema and quality tests. Perfect for developers and data professionals seeking efficient data contract validation and execution.",Data Transformation Tool,"Python





        182





        21


        Built by

          









        3 stars today",https://raw.githubusercontent.com/datacontract/cli/main/datacontractcli.png,,182,2023-07-24T14:54:16Z
2024-03-11,https://github.com/RsaCtfTool/RsaCtfTool,https://raw.githubusercontent.com/RsaCtfTool/RsaCtfTool/master/README.md,"The RsaCtfTool is a comprehensive tool designed for decrypting data encrypted with weak RSA public keys and recovering the corresponding private keys. It integrates multiple integer factorization algorithms to enhance decryption capabilities. Primarily aimed at educational use, it underscores the importance of understanding the mathematical foundations of RSA, including number theory and integer factorization. The tool supports various attacks, including both factorization-dependent and independent methods, offering a broad spectrum of strategies for cracking RSA encryption. Users are encouraged to interact with the source code, understanding its workings and contributing improvements. It facilitates various operations such as public key creation, decryption of files, and private key recovery among others, emphasizing responsible use within legal and ethical boundaries. Installation instructions are provided for different operating systems including Ubuntu, Fedora, and MacOS. The community is invited to contribute to its development, adhering to the provided guidelines and code of conduct.",Unlocking RSA Encryption: Exploring the RsaCtfTool for Educational Use,"Discover the capabilities of the RsaCtfTool, a comprehensive utility for deciphering weak RSA public keys. This tool combines various algorithms to tackle integer factorization, enhancing decryption efforts. It's designed primarily for educational purposes, helping users understand RSA encryption's complexities through practical application. Despite its limitations, such as supporting only semiprime composite moduli, the RsaCtfTool remains a valuable resource for those keen on cryptography.","Explore the RsaCtfTool, a multifaceted utility aimed at decrypting weak RSA public keys through a suite of integer factorization algorithms. Ideal for educational purposes, it emphasizes the practical understanding of RSA encryption.",Cybersecurity Tool,"Python





        5,120





        872


        Built by

          









        5 stars today",,,5120,2015-03-07T17:29:33Z
2024-03-11,https://github.com/01-ai/Yi,https://raw.githubusercontent.com/01-ai/Yi/main/README.md,"This text introduces the Yi series, a next-generation open-source and bilingual Large Language Models (LLMs) developed by 01.AI, trained on a 3T multilingual corpus. The Yi models, including the Yi-34B-Chat and Yi-34B models, have shown exceptional performance, ranking highly on various AI evaluation leaderboards in both English and Chinese. These models are designed for diverse applications, suitable for personal, academic, and commercial use. Contributions from the Transformer and Llama communities have significantly facilitated Yi's development, emphasizing that these models are not derivatives of Llama but rather benefit from the shared architecture. The text outlines the availability of different Yi models for chat and base applications, instructions for quick start deployment through several methods like pip, docker, and conda-lock, along with options for fine-tuning, quantization, and deployment. Furthermore, it highlights the role of the Yi Learning Hub for educational resources and community engagement through GitHub discussions, Discord, and WeChat.",Revolutionizing Language Understanding: The Emergence of Yi's Bilingual LLMs,"Discover how the Yi series models are pioneering the next frontier in AI with unmatched bilingual language understanding and versatility in applications. These next-generation, open-source large language models, trained on a diverse multilingual corpus, not only clinch top positions on global leaderboards but also usher in a new era of AI accessibility and collaborative innovation. With a robust architecture inspired by Transformer and Llama, Yi models have set new standards in the realms of commonsense reasoning, reading comprehension, and more.","Explore how Yi series models are setting new benchmarks in bilingual language understanding by leveraging a 3T multilingual corpus and robust architecture, outperforming notable LLMs across diverse applications.",Language Models,"Python





        6,429





        384


        Built by

          









        38 stars today",,https://www.youtube.com/watch?v=NJ89T5mO25Y; https://www.youtube.com/watch?v=CVQvj4Wrh4w; https://www.youtube.com/watch?v=On3Zuv27V3k,6429,2023-11-03T16:08:37Z
2024-03-11,https://github.com/magic-research/piecewise-rectified-flow,https://raw.githubusercontent.com/magic-research/piecewise-rectified-flow/main/README.md,"PeRFlow, or Piecewise Rectified Flow, is introduced as a method to enhance the speed and efficiency of generating high-quality images using pre-trained diffusion models, specifically improving upon the limitations of Stable Diffusion models. By learning a piecewise linear probability flow, PeRFlow can generate images in significantly fewer steps - as little as 4, compared to traditional methods. This not only speeds up the generation process but also ensures the images are of high fidelity and diversity. Training PeRFlow is efficient, requiring only 4,000 iterations for fine-tuning, and it seamlessly integrates with existing SD-based workflows, supporting various enhancements such as classifier-free guidance for higher quality generation. PeRFlow's application extends to fast image and text-to-image generation, image enhancement, and efficient multiview generation, demonstrating its versatility as a plug-and-play accelerator module for a wide range of image generation tasks. The project has garnered contributions from several institutions and offers demos, training scripts, and model downloads to encourage further exploration and application in the field.",Exploring PeRFlow: A Revolution in Accelerating Diffusion Models for Spectacular Image Generation,"Discover the groundbreaking PeRFlow model, a piecewise rectified flow technique, enhancing the efficiency of pre-trained diffusion models for faster, high-quality image generation. PeRFlow, developed by a collaborative research team, demonstrates remarkable advancements in image synthesis, including fast generation, efficient training, and compatibility with existing SD workflows. Its application ranges from enriching text-to-image conversion to refining images and facilitating multiview generation, showcasing its versatility and potential to reshape the future of AI-driven image creation.","Unveil the potential of PeRFlow, a cutting-edge approach to accelerate diffusion models, enabling rapid, high-quality image generation. Explore how it revolutionizes AI-powered image synthesis across various applications.",Image Generation Platform,"Python





        197





        11


        Built by

          






        14 stars today",https://raw.githubusercontent.com/magic-research/piecewise-rectified-flow/main/assets/rocket-icon-png-21.png,,197,2024-02-16T16:13:34Z
